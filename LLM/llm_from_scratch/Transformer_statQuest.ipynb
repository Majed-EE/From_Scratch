{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8932d6c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f58bf898",
   "metadata": {},
   "outputs": [],
   "source": [
    "# step one\n",
    "# word embedddings\n",
    "\n",
    "text=\"Lets to go\"\n",
    "\n",
    "# super simple vocab lets, to, go as 1 2 3 for simplicity, it is from scratch after all  \n",
    "vocab=text.split(\" \")\n",
    "vocab=vocab+[\"<EOS>\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "001c6b19",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "b00cfa0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Lets': 0, 'to': 1, 'go': 2, '<EOS>': 3}\n",
      "torch.Size([1, 3])\n",
      "torch.Size([4, 1])\n"
     ]
    }
   ],
   "source": [
    "WtoVec={key:i for i,key in enumerate(vocab)}\n",
    "print(WtoVec)\n",
    "# input connected to activation functions \n",
    "# encode \n",
    "encode = lambda c: WtoVec[c] #if type(c)==str # encoder: take a string, output a list of integers \n",
    "def vect(k):\n",
    "    b=torch.zeros(1,4)\n",
    "    b[0][k]=1\n",
    "    return b\n",
    "\n",
    "WtoVec[\"Lets\"]\n",
    "# decode \n",
    "\n",
    "ex1=torch.tensor([0,1,3]).reshape(1,3) # lets go \n",
    "ex2=torch.tensor([0,1,3]).reshape(1,3) # To go\n",
    "vocab_size=len(vocab)\n",
    "n_embd=4\n",
    "\n",
    "# C  = torch.randn((vocab_size, n_embd),            generator=g)\n",
    "\n",
    "\n",
    "print(ex1.shape)\n",
    "\n",
    "\n",
    "\n",
    "weights_1=torch.randn(4,1)\n",
    "print(weights_1.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "c3543e13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 0., 0., 0.],\n",
      "        [0., 1., 0., 0.],\n",
      "        [0., 0., 1., 0.],\n",
      "        [0., 0., 0., 1.]])\n",
      "tensor([ 0.7055, -1.4745])\n"
     ]
    }
   ],
   "source": [
    "input_vec=torch.zeros(4,4)\n",
    "for i,key in enumerate(WtoVec):\n",
    "    input_vec[i]=vect(WtoVec[key])\n",
    "print(input_vec)\n",
    "C=torch.randn(4,4)\n",
    "key=\"Lets\"\n",
    "embd=C[torch.tensor(WtoVec[key])]\n",
    "print(embd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "aac80a45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# two activation function\n",
    "\n",
    "def activation1(vect):\n",
    "    return torch.sum(vect,dim=1,keepdim=True)\n",
    "def activation2(vect):\n",
    "    return torch.sum(vect,dim=1,keepdim=True)\n",
    "\n",
    "    \n",
    "# word embedding done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "617bc7f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# my house is beautiful "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "932500a0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b7d0fb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# position encoding help the transformer to track order\n",
    "position_encoding= lambda pos,word: np.cos(2 * np.pi * pos * word+0.5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3538f78e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add the word and positional embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "a916600d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# self attention-> correctly accociate word with meaning\n",
    "# self attention calculates the similarity between the first word, and all the words in the sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "7d5a240c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# muptiply the values the resultant numbers to get two new numbers- querry\n",
    "# create keys for all the words\n",
    "# use query and keys to calculate the similarity between itself(querry) and other words(keys).\n",
    "# similarity between querry and keys is dot product\n",
    "# Querry dot key is the similarity\n",
    "# we want to have the word which is more influence to have more say in the encoding of the the word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a5d68f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to properly encode lets we will create two more values called values- directly multiply it with the position+source embeding\n",
    "# we scale the vlaue lets by 1.0 and create value for go and scale it by 0? \n",
    "# add the scaled value together-> combine separate encodings for both input words, lets and go to create self attention values for lets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1d54a78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# weights we use to create self attention values for lets and go are the same \n",
    "# we also use same weight for all words to calculate self attention keys and value "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69e68e9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we calculate the queries keys and values for each word at the same time.\n",
    "# the new self attention values for each word contain input from all of the other words, \n",
    "# and this heps give each word context- helps us to tell how each word is related to other\n",
    "\n",
    "# if we think of this unit with it's weights for calculating Queries, Keys and Values, as self- Attention cell\n",
    "# we can create a stach of self-attention cells., each with it's own sets of weights. that we appply to the poistion encoded values for each word, \n",
    "# to caputre different relationships among the words "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4e01458",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to encode we take position encoded values and add them to self attention values- bypass is called residual connections and they make \n",
    "# it easier to train complex NN\n",
    "# this allws self-attention layer to establish relationships amoung the input words without having to also preserve the word embedding and\n",
    "# position encoding information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "052cce2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# summary of attention encoder-\n",
    "# -word embedding, positional encoding, self attention and residual connections\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b21514be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eb77add",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# start with <eos> usually or <sos>\n",
    "# plug in and create embeddings \n",
    "# add positional encodings\n",
    "# we create querry keys and values for each token and calculate self attention just like before\n",
    "# the sets of weights we used to calculate the decoders self attnetion query keys and values are different \n",
    "# from the sets we used in the Encoder.\n",
    "# consolidate the maths and create residual blocks\n",
    "# while decoding we also need to keep track of the relationshiop bweten the input sentence and the output.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27b67da6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# we create queries in the decoder and find similartiy with each of the keys in the encoder and run the softmax function\n",
    "# the sets of Weights that we use to calculate the Queries, keys and Valuse for encoder, Decoder Attention are different from \n",
    "# the sets of weights we use for selfAttnetion.\n",
    "# create residual connections\n",
    "# we run the final 2 values (after query key and values upgrade and adding residual connections) \n",
    "# we pass it to fully connected neural network \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45379991",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "440f5f8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sequence to sequence encoder decoder --> long short term memory and wrod to vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3088ce89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vocabulary contains a mix of words and sumbols we refer to the individual elemets in a vocabulary as tokens "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4a209d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Weigths and biases in the LSTM cells and embedding layer is the same for all the words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee9e49ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The last long and short term memories (the cell and hidden states) from both layers of the LSTM cells in the \n",
    "# Encoder are called the context vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d3e650b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The decoder is lstm like the encoder such that context vector of encoder is passed \n",
    "# Through the input of the decoder starting from <EOS> \n",
    "# Usually output values of the top layer of lstm cells is passed through fully connected layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b7e75bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Attnetion in neural network\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd6c642a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# attention is all you neeed paper\n",
    "# approaches in sequence nodeling a nd transduction problems such as language modeling and machine translation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63ba402c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# communication phase and compute phase\n",
    "# \n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "518c847d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node:\n",
    "    def __init__(self):\n",
    "        \n",
    "        # the vector stores at this node\n",
    "        self.data=np.random.randn(20) \n",
    "        \n",
    "        # weights governing how this node interacts with other nodes\n",
    "        self.wkey= np.random.randn(20,20)\n",
    "        self.wquery= np.random.randn(20,20)\n",
    "        self.wvalue= np.random.randn(20,20)\n",
    "        \n",
    "        \n",
    "    def key(self):\n",
    "        # what do i have ?\n",
    "        return self.wkey@self.data # why self@data\n",
    "    \n",
    "    def query(self):\n",
    "        # what am i looking for ?\n",
    "        return self.wquery@self.data # why self@data\n",
    "    def value(self):\n",
    "        # what do i publicly reveal or broadcast to others ?\n",
    "        return self.wvalue@self.data # why self@data\n",
    "          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8dfab755",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Graph:\n",
    "    def __init__(self):\n",
    "        # make 10 nodes\n",
    "        self.nodes=[Node() for _ in range(10)]\n",
    "        \n",
    "        # make 40 edges\n",
    "        randi=lambda: np.random.randint(len(self.nodes))\n",
    "        self.edges=[[randi(),randi()] for _ in range(40)] # does it include self node aswell\n",
    "        \n",
    "    def run(self):\n",
    "        updates=[]\n",
    "        for i, n in enumerate (self.nodes):\n",
    "            \n",
    "            # what is this node lookinf for?\n",
    "            q=n.query()\n",
    "            \n",
    "            # find all the edges that are input to this node\n",
    "            inputs=[self.nodes[ifrom] for (ifrom,ito) in self.edges if ito==i]\n",
    "            \n",
    "            if len(inputs)==0:\n",
    "                continue # ignore\n",
    "            # gather their keys, i.e. what they hold\n",
    "            keys=[m.keys() for m in inputs]\n",
    "            \n",
    "            # calculate the compatibilities\n",
    "            \n",
    "            scores= [k.dot(q) for k in keys]\n",
    "            \n",
    "            # softmax them so they sum to 1\n",
    "            scores=[k.dot(q) for k in keys]\n",
    "            # softmax them so they sum to 1\n",
    "            scores=np.exp(scores)\n",
    "            scores= scores/np.sum(scores)\n",
    "            # gahter the appropriate values with a weighted sum\n",
    "            values= [m.value() for m in inputs]\n",
    "            update=sum([s*v for s,v in zip(scores,values)])\n",
    "            updates.append(update)\n",
    "            \n",
    "            \n",
    "            \n",
    "        for n,u in zip(self.nodes, updates):\n",
    "            n.data=n.data+u # residual connection\n",
    "            \n",
    "                \n",
    "            \n",
    "            \n",
    "            \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a476f3a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f68da8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## collecting information at the same node and seeking information at the same node and that is a head but how?\n",
    "# self attention cross attention and multihead attention\n",
    "# self attentiuon and cross attention only differes where the keys and values are coming from"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c919f784",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CasualSelfAttnetion(nn.Module):\n",
    "    def __init__(self,config):\n",
    "        super().__init__()\n",
    "        assert config.n_embd%config.n_head==0\n",
    "        # key query value projections for all heads, but in a batch\n",
    "        self.c_attn=nn.Linear(config.en_embd,3*config.n_embd)\n",
    "        # output projection\n",
    "        self.c_proj=nn.Linear(config.n_embd,3*config.n_embd)\n",
    "        # output projection\n",
    "        self.c_proj=nn.Linear(config.n_embd, config.n_embd)\n",
    "        # regularization\n",
    "        self.attn_droupout=nn.Droupout(config.dropout)\n",
    "        self.resid_droupout=nn.Droupout(config.dropout)\n",
    "        # casually mask to ensure that attention is onlyu applied to the left in the input sequence\n",
    "        self.register_buffer(\"bias\",torchtril(torch.ones(config.block_size),config.block_sieze)).view(1,1,config.block_size, config.block_size) ## somehting is missing\n",
    "        \n",
    "        self.n_head=config.n_head\n",
    "        self.n_embd=config.n_embd\n",
    "    \n",
    "    def forward(self,x):\n",
    "        B,T,C=x.size() # batch size, sequence length, embedding dimensionality (n_embd)\n",
    "        \n",
    "        # calculate query, key, value for all heads in bathc and move head forward to be the batch dim\n",
    "        q,k,v=self.c_attn(x).split(self.n_embd,dim=2)\n",
    "        k=k.view(B,T,self.n_head,C//self.n_head).transpose(1,2) # (B, nh, Tm hs)\n",
    "        q=q.view(B,T,self.n_head,C//self.n_head).transpose(1,2) # (B, nh, Tm hs)\n",
    "        v=v.view(B,T,self.n_head,C//self.n_head).transpose(1,2) # (B, nh, Tm hs)\n",
    "        \n",
    "        \n",
    "        # casual self-attentionl; self-attend; (B,nh,T,hs) x (B,nh,T,hs) --> n(B,nh,T,T)\n",
    "        att=(q@k.tranpose(-2,-1))*(1.0/math.sqrt(k.size(-1)))\n",
    "        att=att.masked_Fill(self.bias[:,:,:T,:T]==0,float(\"--inf\"))\n",
    "        att.F.softmax(att,dim=1)\n",
    "        att=self.attn_dropout(att)\n",
    "        y=att@v # (B,nh,T,T) x(B,nh,T,hs)-->(B,nh,T,hs)\n",
    "        y=y.transpose(1,2).contiguous().view(B,T,C) # re-assemble all head outputs side by sie      \n",
    "        \n",
    "        # output projection\n",
    "        y=self.resid_dropout(self.c_proj(y))\n",
    "        return y\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c6deb9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    \n",
    "    def __init__(self,config):\n",
    "        super().__init__()\n",
    "        self.c_fc=nn.Linear(config.n_embd,4*config.n_embd)\n",
    "        self.c_proj=nn.Linear(4*config.n_embd,config.n_embd)\n",
    "        self.droupput=nn.Droupout(config.dropout)\n",
    "        \n",
    "        \n",
    "        def forward(self,x):\n",
    "            x=self.c_fc(x)\n",
    "            x=new_gelu(x) # similar to relu non linearity?\n",
    "            x=self.c_proj(x)\n",
    "            x=self.dropout(x)\n",
    "            return x\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9f02089",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Block(nn.Module):\n",
    "    def __init__(self,config):\n",
    "        super().__init__()\n",
    "        self.ln1=nn.LayerNorm(config.n_embd)\n",
    "        self.attn=CasualSelfAttnetion(config)\n",
    "        self.ln_2=nn.LayerNorm(config.nn_embd)\n",
    "        self.mlp=MLP(config)\n",
    "    def forward(self,x):\n",
    "        x=x+self.attn(self.ln_1(x)) # commuinicate phase\n",
    "        x=x+self.mlp(self.ln_2(x)) # compute phase\n",
    "        # there is no criss cross in batch normalization\n",
    "        return x\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f58df0e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GPT(nn.Module):\n",
    "    def __init__(self,config):\n",
    "        super().__init__()\n",
    "        assert config.vocab_Size is not None\n",
    "        assert config.block_size is not None\n",
    "        self.config=config\n",
    "        \n",
    "        \n",
    "        self.transformer = nn.ModuleDict(dict(\n",
    "            wte=nn.Embedding(config.vocab_size,config.n_embd), # is it word embedding\n",
    "            wpe=nn.Embedding(config.block_Size,config.n_embd), # is it positional embedding\n",
    "            drop= nn.Dropout(config.dropout),\n",
    "            h=nn.ModuleList([Block(config) for _ in range(config.n_layer)]), # what is the use of this\n",
    "            ln_f=nn.LayerNorm(config.n_embd), # what is the use of this\n",
    "\n",
    "        ))\n",
    "        self.lm_head=nn.Linera(config.nembd,config.vocab_size,bias=False)\n",
    "        \n",
    "    def forward(self, idc,tagets=None):\n",
    "        device=idx.device\n",
    "        b,t=idx.size()\n",
    "        assert t<=self.config.block_size, f\"cannot forward sequence of length{t}, block size is only\" # add misssing\n",
    "        pos=torch.arange(0,t,dtype=torcdh.long, device=device).unsqueeze(0)# this is what?\n",
    "        \n",
    "        \n",
    "        \n",
    "        # forward the GPT model itself\n",
    "        tok_emb=self.transformer.rte(idx) # token embeddings of shape (b,t,n_embd)\n",
    "        pos_emb=self.transformer.wpe(pos) # position embeddings of shape(1,t,n_embd)\n",
    "        x= self.transformer.drop(tok_emb+pos_emb)\n",
    "        for block in slef.transfoemer.h:\n",
    "            x=block(x)\n",
    "        x=self.transformer.ln_f(x)\n",
    "        logits=self.lm_heads(x)\n",
    "        \n",
    "        \n",
    "        # if we are given some desired targets also calculate the loss\n",
    "        loss=None\n",
    "        if targets is not None:\n",
    "            loss=f.cross_entropy(logits.view(-1,logtits.size(-1),targets.view(-1),ignore_index=-1))\n",
    "            \n",
    "        return logits,loss\n",
    "        \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
