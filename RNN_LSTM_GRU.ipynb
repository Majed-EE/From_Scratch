{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f02a06d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e7146913",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "device= \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "571f1bee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# i) learn how to model sequence-to-sequence learning problems using Recurrent Neural Networks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "48df5c9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ii) compare different cells such as vanilla RNN, LSTM and GRU.\n",
    "\n",
    "# The goal of this assignment is fourfold: \n",
    "# (i) learn how to model sequence to sequence learning problems using Recurrent Neural Networks\n",
    "# (ii) compare different cells such as vanilla RNN, LSTM and GRU\n",
    "# (iii) understand how attention networks overcome the limitations of vanilla seq2seq models\n",
    "# (iv) visualise the interactions between different components in a RNN based model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2d7f482e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1000, 50]) torch.Size([1000, 50])\n"
     ]
    }
   ],
   "source": [
    "# Generate sine wave data\n",
    "def generate_data(seq_length, num_samples):\n",
    "    X = []\n",
    "    y = []\n",
    "    for i in range(num_samples):\n",
    "        x = np.linspace(i * 2 * np.pi, (i + 1) * 2 * np.pi, seq_length + 1)\n",
    "#         print(x.shape)\n",
    "        sine_wave = np.sin(x)\n",
    "        X.append(sine_wave[:-1])  # input sequence\n",
    "        y.append(sine_wave[1:])   # target sequence\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "seq_length = 50\n",
    "num_samples = 1000 # is this the batch size?\n",
    "X, y = generate_data(seq_length, num_samples)\n",
    "\n",
    "# Convert to PyTorch tensors\n",
    "X = torch.tensor(X, dtype=torch.float32)\n",
    "y = torch.tensor(y, dtype=torch.float32)\n",
    "\n",
    "print(X.shape, y.shape)  # Output: (1000, 50), (1000, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "79582ac1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.0000, 0.1253, 0.2487, 0.3681, 0.4818, 0.5878, 0.6845, 0.7705, 0.8443,\n",
      "        0.9048])\n",
      "tensor([0.1253, 0.2487, 0.3681, 0.4818, 0.5878, 0.6845, 0.7705, 0.8443, 0.9048,\n",
      "        0.9511])\n"
     ]
    }
   ],
   "source": [
    "x_rnn=X.clone()\n",
    "y_rnn=y.clone()\n",
    "print(X[0,:10])\n",
    "\n",
    "print(y[0,:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cb6bcefb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([50])\n",
      "torch.Size([1000, 50])\n"
     ]
    }
   ],
   "source": [
    "print(X[0].shape)\n",
    "print(X.unsqueeze(2).squeeze(2).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cdc0093a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x2c348e83670>]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot results\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(X[0].numpy(), label='True')\n",
    "plt.plot(y[0].numpy(), label='True')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "01263750",
   "metadata": {},
   "outputs": [],
   "source": [
    "# vanella flavour\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "\n",
    "    \n",
    "# Define model hyperparameters\n",
    "\n",
    "# vocab_size = 50    # Size of the character vocabulary\n",
    "# embedding_dim = 64 # Dimension of character embeddings\n",
    "hidden_dim = 128   # Dimension of RNN hidden state\n",
    "output_dim = 1    # Dimension of the output\n",
    "input_size=1 # number of expected features in x\n",
    "\n",
    "class SimpleRNN(nn.Module):\n",
    "    def __init__(self,input_size, hidden_dim, output_dim):\n",
    "        super(SimpleRNN,self).__init__()\n",
    "#         self.embedding=nn.Embedding(vocab_size,embedding_dim)\n",
    "        self.rnn=nn.RNN(input_size, hidden_size=hidden_dim)\n",
    "        self.fc=nn.Linear(hidden_dim,output_dim)\n",
    "        \n",
    "     \n",
    "    def forward(self,x):\n",
    "        encoder_output, hidden_state=self.rnn(x)\n",
    "        print(\"hidden state is \")\n",
    "        print(hidden_state.shape)\n",
    "        print(\"encoder output\")\n",
    "        print(encoder_output.shape)\n",
    "        output=self.fc(encoder_output)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fa84e6f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SimpleRNN(\n",
      "  (rnn): RNN(1, 128)\n",
      "  (fc): Linear(in_features=128, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model = SimpleRNN(input_size, hidden_dim, output_dim)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "96b560c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([50, 1000, 128])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # X= 1000,50\n",
    "# j=torch.randn(2,3)\n",
    "# print(j)\n",
    "# j[-1]\n",
    "temp=torch.randn(1000,128)\n",
    "out=[]\n",
    "for x in range(50):\n",
    "    out.append(temp)\n",
    "# print(len)\n",
    "out=torch.stack(out)\n",
    "out.transpose(0,1)\n",
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "458fc8bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hidden state is \n",
      "torch.Size([1, 50, 128])\n",
      "encoder output\n",
      "torch.Size([1000, 50, 128])\n",
      "prediction (after passing through linear layer) shape is \n",
      "torch.Size([1000, 50, 1])\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    predictions = model(X.unsqueeze(2)) # x 1000,50,1--> input size, hidden size, output size\n",
    "    # why are we adding dimensions- Understood- this has only one input feature\n",
    "    print(\"prediction (after passing through linear layer) shape is \")\n",
    "    print(predictions.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2195015d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hidden state is \n",
      "torch.Size([1, 50, 128])\n",
      "encoder output\n",
      "torch.Size([1000, 50, 128])\n",
      "hidden state is \n",
      "torch.Size([1, 50, 128])\n",
      "encoder output\n",
      "torch.Size([1000, 50, 128])\n",
      "hidden state is \n",
      "torch.Size([1, 50, 128])\n",
      "encoder output\n",
      "torch.Size([1000, 50, 128])\n",
      "hidden state is \n",
      "torch.Size([1, 50, 128])\n",
      "encoder output\n",
      "torch.Size([1000, 50, 128])\n",
      "hidden state is \n",
      "torch.Size([1, 50, 128])\n",
      "encoder output\n",
      "torch.Size([1000, 50, 128])\n",
      "hidden state is \n",
      "torch.Size([1, 50, 128])\n",
      "encoder output\n",
      "torch.Size([1000, 50, 128])\n",
      "hidden state is \n",
      "torch.Size([1, 50, 128])\n",
      "encoder output\n",
      "torch.Size([1000, 50, 128])\n",
      "hidden state is \n",
      "torch.Size([1, 50, 128])\n",
      "encoder output\n",
      "torch.Size([1000, 50, 128])\n",
      "hidden state is \n",
      "torch.Size([1, 50, 128])\n",
      "encoder output\n",
      "torch.Size([1000, 50, 128])\n",
      "hidden state is \n",
      "torch.Size([1, 50, 128])\n",
      "encoder output\n",
      "torch.Size([1000, 50, 128])\n",
      "Epoch [10/100], Loss: 0.1644\n",
      "hidden state is \n",
      "torch.Size([1, 50, 128])\n",
      "encoder output\n",
      "torch.Size([1000, 50, 128])\n",
      "hidden state is \n",
      "torch.Size([1, 50, 128])\n",
      "encoder output\n",
      "torch.Size([1000, 50, 128])\n",
      "hidden state is \n",
      "torch.Size([1, 50, 128])\n",
      "encoder output\n",
      "torch.Size([1000, 50, 128])\n",
      "hidden state is \n",
      "torch.Size([1, 50, 128])\n",
      "encoder output\n",
      "torch.Size([1000, 50, 128])\n",
      "hidden state is \n",
      "torch.Size([1, 50, 128])\n",
      "encoder output\n",
      "torch.Size([1000, 50, 128])\n",
      "hidden state is \n",
      "torch.Size([1, 50, 128])\n",
      "encoder output\n",
      "torch.Size([1000, 50, 128])\n",
      "hidden state is \n",
      "torch.Size([1, 50, 128])\n",
      "encoder output\n",
      "torch.Size([1000, 50, 128])\n",
      "hidden state is \n",
      "torch.Size([1, 50, 128])\n",
      "encoder output\n",
      "torch.Size([1000, 50, 128])\n",
      "hidden state is \n",
      "torch.Size([1, 50, 128])\n",
      "encoder output\n",
      "torch.Size([1000, 50, 128])\n",
      "hidden state is \n",
      "torch.Size([1, 50, 128])\n",
      "encoder output\n",
      "torch.Size([1000, 50, 128])\n",
      "Epoch [20/100], Loss: 0.0293\n",
      "hidden state is \n",
      "torch.Size([1, 50, 128])\n",
      "encoder output\n",
      "torch.Size([1000, 50, 128])\n",
      "hidden state is \n",
      "torch.Size([1, 50, 128])\n",
      "encoder output\n",
      "torch.Size([1000, 50, 128])\n",
      "hidden state is \n",
      "torch.Size([1, 50, 128])\n",
      "encoder output\n",
      "torch.Size([1000, 50, 128])\n",
      "hidden state is \n",
      "torch.Size([1, 50, 128])\n",
      "encoder output\n",
      "torch.Size([1000, 50, 128])\n",
      "hidden state is \n",
      "torch.Size([1, 50, 128])\n",
      "encoder output\n",
      "torch.Size([1000, 50, 128])\n",
      "hidden state is \n",
      "torch.Size([1, 50, 128])\n",
      "encoder output\n",
      "torch.Size([1000, 50, 128])\n",
      "hidden state is \n",
      "torch.Size([1, 50, 128])\n",
      "encoder output\n",
      "torch.Size([1000, 50, 128])\n",
      "hidden state is \n",
      "torch.Size([1, 50, 128])\n",
      "encoder output\n",
      "torch.Size([1000, 50, 128])\n",
      "hidden state is \n",
      "torch.Size([1, 50, 128])\n",
      "encoder output\n",
      "torch.Size([1000, 50, 128])\n",
      "hidden state is \n",
      "torch.Size([1, 50, 128])\n",
      "encoder output\n",
      "torch.Size([1000, 50, 128])\n",
      "Epoch [30/100], Loss: 0.0124\n",
      "hidden state is \n",
      "torch.Size([1, 50, 128])\n",
      "encoder output\n",
      "torch.Size([1000, 50, 128])\n",
      "hidden state is \n",
      "torch.Size([1, 50, 128])\n",
      "encoder output\n",
      "torch.Size([1000, 50, 128])\n",
      "hidden state is \n",
      "torch.Size([1, 50, 128])\n",
      "encoder output\n",
      "torch.Size([1000, 50, 128])\n",
      "hidden state is \n",
      "torch.Size([1, 50, 128])\n",
      "encoder output\n",
      "torch.Size([1000, 50, 128])\n",
      "hidden state is \n",
      "torch.Size([1, 50, 128])\n",
      "encoder output\n",
      "torch.Size([1000, 50, 128])\n",
      "hidden state is \n",
      "torch.Size([1, 50, 128])\n",
      "encoder output\n",
      "torch.Size([1000, 50, 128])\n",
      "hidden state is \n",
      "torch.Size([1, 50, 128])\n",
      "encoder output\n",
      "torch.Size([1000, 50, 128])\n",
      "hidden state is \n",
      "torch.Size([1, 50, 128])\n",
      "encoder output\n",
      "torch.Size([1000, 50, 128])\n",
      "hidden state is \n",
      "torch.Size([1, 50, 128])\n",
      "encoder output\n",
      "torch.Size([1000, 50, 128])\n",
      "hidden state is \n",
      "torch.Size([1, 50, 128])\n",
      "encoder output\n",
      "torch.Size([1000, 50, 128])\n",
      "Epoch [40/100], Loss: 0.0122\n",
      "hidden state is \n",
      "torch.Size([1, 50, 128])\n",
      "encoder output\n",
      "torch.Size([1000, 50, 128])\n",
      "hidden state is \n",
      "torch.Size([1, 50, 128])\n",
      "encoder output\n",
      "torch.Size([1000, 50, 128])\n",
      "hidden state is \n",
      "torch.Size([1, 50, 128])\n",
      "encoder output\n",
      "torch.Size([1000, 50, 128])\n",
      "hidden state is \n",
      "torch.Size([1, 50, 128])\n",
      "encoder output\n",
      "torch.Size([1000, 50, 128])\n",
      "hidden state is \n",
      "torch.Size([1, 50, 128])\n",
      "encoder output\n",
      "torch.Size([1000, 50, 128])\n",
      "hidden state is \n",
      "torch.Size([1, 50, 128])\n",
      "encoder output\n",
      "torch.Size([1000, 50, 128])\n",
      "hidden state is \n",
      "torch.Size([1, 50, 128])\n",
      "encoder output\n",
      "torch.Size([1000, 50, 128])\n",
      "hidden state is \n",
      "torch.Size([1, 50, 128])\n",
      "encoder output\n",
      "torch.Size([1000, 50, 128])\n",
      "hidden state is \n",
      "torch.Size([1, 50, 128])\n",
      "encoder output\n",
      "torch.Size([1000, 50, 128])\n",
      "hidden state is \n",
      "torch.Size([1, 50, 128])\n",
      "encoder output\n",
      "torch.Size([1000, 50, 128])\n",
      "Epoch [50/100], Loss: 0.0104\n",
      "hidden state is \n",
      "torch.Size([1, 50, 128])\n",
      "encoder output\n",
      "torch.Size([1000, 50, 128])\n",
      "hidden state is \n",
      "torch.Size([1, 50, 128])\n",
      "encoder output\n",
      "torch.Size([1000, 50, 128])\n",
      "hidden state is \n",
      "torch.Size([1, 50, 128])\n",
      "encoder output\n",
      "torch.Size([1000, 50, 128])\n",
      "hidden state is \n",
      "torch.Size([1, 50, 128])\n",
      "encoder output\n",
      "torch.Size([1000, 50, 128])\n",
      "hidden state is \n",
      "torch.Size([1, 50, 128])\n",
      "encoder output\n",
      "torch.Size([1000, 50, 128])\n",
      "hidden state is \n",
      "torch.Size([1, 50, 128])\n",
      "encoder output\n",
      "torch.Size([1000, 50, 128])\n",
      "hidden state is \n",
      "torch.Size([1, 50, 128])\n",
      "encoder output\n",
      "torch.Size([1000, 50, 128])\n",
      "hidden state is \n",
      "torch.Size([1, 50, 128])\n",
      "encoder output\n",
      "torch.Size([1000, 50, 128])\n",
      "hidden state is \n",
      "torch.Size([1, 50, 128])\n",
      "encoder output\n",
      "torch.Size([1000, 50, 128])\n",
      "hidden state is \n",
      "torch.Size([1, 50, 128])\n",
      "encoder output\n",
      "torch.Size([1000, 50, 128])\n",
      "Epoch [60/100], Loss: 0.0089\n",
      "hidden state is \n",
      "torch.Size([1, 50, 128])\n",
      "encoder output\n",
      "torch.Size([1000, 50, 128])\n",
      "hidden state is \n",
      "torch.Size([1, 50, 128])\n",
      "encoder output\n",
      "torch.Size([1000, 50, 128])\n",
      "hidden state is \n",
      "torch.Size([1, 50, 128])\n",
      "encoder output\n",
      "torch.Size([1000, 50, 128])\n",
      "hidden state is \n",
      "torch.Size([1, 50, 128])\n",
      "encoder output\n",
      "torch.Size([1000, 50, 128])\n",
      "hidden state is \n",
      "torch.Size([1, 50, 128])\n",
      "encoder output\n",
      "torch.Size([1000, 50, 128])\n",
      "hidden state is \n",
      "torch.Size([1, 50, 128])\n",
      "encoder output\n",
      "torch.Size([1000, 50, 128])\n",
      "hidden state is \n",
      "torch.Size([1, 50, 128])\n",
      "encoder output\n",
      "torch.Size([1000, 50, 128])\n",
      "hidden state is \n",
      "torch.Size([1, 50, 128])\n",
      "encoder output\n",
      "torch.Size([1000, 50, 128])\n",
      "hidden state is \n",
      "torch.Size([1, 50, 128])\n",
      "encoder output\n",
      "torch.Size([1000, 50, 128])\n",
      "hidden state is \n",
      "torch.Size([1, 50, 128])\n",
      "encoder output\n",
      "torch.Size([1000, 50, 128])\n",
      "Epoch [70/100], Loss: 0.0090\n",
      "hidden state is \n",
      "torch.Size([1, 50, 128])\n",
      "encoder output\n",
      "torch.Size([1000, 50, 128])\n",
      "hidden state is \n",
      "torch.Size([1, 50, 128])\n",
      "encoder output\n",
      "torch.Size([1000, 50, 128])\n",
      "hidden state is \n",
      "torch.Size([1, 50, 128])\n",
      "encoder output\n",
      "torch.Size([1000, 50, 128])\n",
      "hidden state is \n",
      "torch.Size([1, 50, 128])\n",
      "encoder output\n",
      "torch.Size([1000, 50, 128])\n",
      "hidden state is \n",
      "torch.Size([1, 50, 128])\n",
      "encoder output\n",
      "torch.Size([1000, 50, 128])\n",
      "hidden state is \n",
      "torch.Size([1, 50, 128])\n",
      "encoder output\n",
      "torch.Size([1000, 50, 128])\n",
      "hidden state is \n",
      "torch.Size([1, 50, 128])\n",
      "encoder output\n",
      "torch.Size([1000, 50, 128])\n",
      "hidden state is \n",
      "torch.Size([1, 50, 128])\n",
      "encoder output\n",
      "torch.Size([1000, 50, 128])\n",
      "hidden state is \n",
      "torch.Size([1, 50, 128])\n",
      "encoder output\n",
      "torch.Size([1000, 50, 128])\n",
      "hidden state is \n",
      "torch.Size([1, 50, 128])\n",
      "encoder output\n",
      "torch.Size([1000, 50, 128])\n",
      "Epoch [80/100], Loss: 0.0089\n",
      "hidden state is \n",
      "torch.Size([1, 50, 128])\n",
      "encoder output\n",
      "torch.Size([1000, 50, 128])\n",
      "hidden state is \n",
      "torch.Size([1, 50, 128])\n",
      "encoder output\n",
      "torch.Size([1000, 50, 128])\n",
      "hidden state is \n",
      "torch.Size([1, 50, 128])\n",
      "encoder output\n",
      "torch.Size([1000, 50, 128])\n",
      "hidden state is \n",
      "torch.Size([1, 50, 128])\n",
      "encoder output\n",
      "torch.Size([1000, 50, 128])\n",
      "hidden state is \n",
      "torch.Size([1, 50, 128])\n",
      "encoder output\n",
      "torch.Size([1000, 50, 128])\n",
      "hidden state is \n",
      "torch.Size([1, 50, 128])\n",
      "encoder output\n",
      "torch.Size([1000, 50, 128])\n",
      "hidden state is \n",
      "torch.Size([1, 50, 128])\n",
      "encoder output\n",
      "torch.Size([1000, 50, 128])\n",
      "hidden state is \n",
      "torch.Size([1, 50, 128])\n",
      "encoder output\n",
      "torch.Size([1000, 50, 128])\n",
      "hidden state is \n",
      "torch.Size([1, 50, 128])\n",
      "encoder output\n",
      "torch.Size([1000, 50, 128])\n",
      "hidden state is \n",
      "torch.Size([1, 50, 128])\n",
      "encoder output\n",
      "torch.Size([1000, 50, 128])\n",
      "Epoch [90/100], Loss: 0.0088\n",
      "hidden state is \n",
      "torch.Size([1, 50, 128])\n",
      "encoder output\n",
      "torch.Size([1000, 50, 128])\n",
      "hidden state is \n",
      "torch.Size([1, 50, 128])\n",
      "encoder output\n",
      "torch.Size([1000, 50, 128])\n",
      "hidden state is \n",
      "torch.Size([1, 50, 128])\n",
      "encoder output\n",
      "torch.Size([1000, 50, 128])\n",
      "hidden state is \n",
      "torch.Size([1, 50, 128])\n",
      "encoder output\n",
      "torch.Size([1000, 50, 128])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hidden state is \n",
      "torch.Size([1, 50, 128])\n",
      "encoder output\n",
      "torch.Size([1000, 50, 128])\n",
      "hidden state is \n",
      "torch.Size([1, 50, 128])\n",
      "encoder output\n",
      "torch.Size([1000, 50, 128])\n",
      "hidden state is \n",
      "torch.Size([1, 50, 128])\n",
      "encoder output\n",
      "torch.Size([1000, 50, 128])\n",
      "hidden state is \n",
      "torch.Size([1, 50, 128])\n",
      "encoder output\n",
      "torch.Size([1000, 50, 128])\n",
      "hidden state is \n",
      "torch.Size([1, 50, 128])\n",
      "encoder output\n",
      "torch.Size([1000, 50, 128])\n",
      "hidden state is \n",
      "torch.Size([1, 50, 128])\n",
      "encoder output\n",
      "torch.Size([1000, 50, 128])\n",
      "Epoch [100/100], Loss: 0.0087\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 100\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    outputs = model(X.unsqueeze(2))  # Add a dimension for input size\n",
    "    loss = criterion(outputs, y.unsqueeze(2))\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step() # what does optimizer.step do- okay update the weight\n",
    "    \n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "923faeb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-1.3496, -0.3068],\n",
      "        [-0.0726,  0.3495]])\n",
      "tensor([[[-1.3496, -0.3068]],\n",
      "\n",
      "        [[-0.0726,  0.3495]]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 1, 2])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k=torch.randn(2,2)\n",
    "print(k)\n",
    "j=k.unsqueeze(1)\n",
    "# print(k.shape)\n",
    "print(j)\n",
    "j.shape # 2,3,4,1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ac0c92ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\syedm\\AppData\\Local\\Temp\\ipykernel_31316\\2686005245.py:52: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x_rnn = torch.tensor(x_rnn, dtype=torch.float32).unsqueeze(2)  # (batch_size, timesteps, input_size)\n",
      "C:\\Users\\syedm\\AppData\\Local\\Temp\\ipykernel_31316\\2686005245.py:54: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_rnn = torch.tensor(y_rnn, dtype=torch.float32).unsqueeze(2)  # (batch_size, output_size)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape is torch.Size([1000, 50, 1])\n",
      "y shape is torch.Size([1000, 50, 1])\n",
      "hidden state shape of gru is torch.Size([1, 50, 128])\n",
      "output of gru is torch.Size([1000, 50, 128])\n",
      "shape of model outout torch.Size([50, 1])\n"
     ]
    }
   ],
   "source": [
    "# vanilla GRU\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Generate sine wave data\n",
    "def generate_sine_wave(timesteps, steps_per_cycle=50, num_cycles=10):\n",
    "    x = np.linspace(0, num_cycles * 2 * np.pi, steps_per_cycle * num_cycles)\n",
    "    y = np.sin(x)\n",
    "    return y\n",
    "\n",
    "# Prepare the dataset for the GRU model\n",
    "def prepare_dataset(data, timesteps):\n",
    "    X, y = [], []\n",
    "    for i in range(len(data) - timesteps):\n",
    "        X.append(data[i:i + timesteps])\n",
    "        y.append(data[i + timesteps])\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "# Define the GRU-based model\n",
    "class GRUModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(GRUModel, self).__init__()\n",
    "        self.gru = nn.GRU(input_size, hidden_size)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out, hidden = self.gru(x)\n",
    "        print(f\"hidden state shape of gru is {hidden.shape}\")\n",
    "        print(f\"output of gru is {out.shape}\")\n",
    "        out = self.fc(out[-1])\n",
    "        return out\n",
    "\n",
    "# Parameters\n",
    "timesteps = 50\n",
    "steps_per_cycle = 50\n",
    "num_cycles = 10\n",
    "hidden_size = 64\n",
    "output_size = 1\n",
    "learning_rate = 0.001\n",
    "num_epochs = 200\n",
    "input_shape=1\n",
    "output_shape=1\n",
    "hidden_shape=128\n",
    "# Generate and prepare the data\n",
    "y = generate_sine_wave(timesteps, steps_per_cycle, num_cycles)\n",
    "X, y = prepare_dataset(y, timesteps)\n",
    "\n",
    "# Convert to PyTorch tensors\n",
    "x_rnn = torch.tensor(x_rnn, dtype=torch.float32).unsqueeze(2)  # (batch_size, timesteps, input_size) \n",
    "# add the output dimension\n",
    "y_rnn = torch.tensor(y_rnn, dtype=torch.float32).unsqueeze(2)  # (batch_size, output_size)\n",
    "\n",
    "print(f\"X shape is {x_rnn.shape}\")\n",
    "print(f\"y shape is {y_rnn.shape}\")\n",
    "model=GRUModel(input_shape,hidden_shape,output_shape)\n",
    "\n",
    "k=model(x_rnn)\n",
    "print(f\"shape of model outout {k.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2e69e66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the model, loss function, and optimizer\n",
    "model = GRUModel(input_size=1, hidden_size=hidden_size, output_size=output_size)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    outputs = model(X.transpose(0, 1))  # (timesteps, batch_size, input_size)\n",
    "    loss = criterion(outputs, y)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if (epoch + 1) % 20 == 0:\n",
    "        print(f'Epoch [{epoch + 1}/{num_epochs}], Loss: {loss.item():.4f}')\n",
    "\n",
    "# Predict and plot the results\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    predictions = model(X.transpose(0, 1)).numpy()\n",
    "\n",
    "plt.plot(y.numpy(), label='True Sine Wave')\n",
    "plt.plot(predictions, label='Predicted Sine Wave')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6135b20c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleLSTM(nn.Module):\n",
    "    def __init__(self,input_dim,hidden_dim, layer_dim,output_dim):\n",
    "        super(SimpleLSTM, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.layer_dim = layer_dim # what is layer dim\n",
    "        self.lstm = nn.LSTM(input_dim, hidden_dim, layer_dim, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, x, h0=None, c0=None):\n",
    "        # If hidden and cell states are not provided, initialize them as zeros\n",
    "        if h0 is None or c0 is None:\n",
    "            h0 = torch.zeros(self.layer_dim, x.size(0), self.hidden_dim).to(x.device)\n",
    "            c0 = torch.zeros(self.layer_dim, x.size(0), self.hidden_dim).to(x.device)\n",
    "        \n",
    "        # Forward pass through LSTM\n",
    "        out, (hn, cn) = self.lstm(x, (h0, c0))\n",
    "        out = self.fc(out[:, -1, :])  # Selecting the last output\n",
    "        return out, hn, cn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3713e294",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Initialize model, loss, and optimizer\n",
    "model = SimpleLSTM(input_dim=1, hidden_dim=100, layer_dim=1, output_dim=1)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3450edf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/100], Loss: 0.2368\n",
      "Epoch [20/100], Loss: 0.0177\n",
      "Epoch [30/100], Loss: 0.0065\n",
      "Epoch [40/100], Loss: 0.0007\n",
      "Epoch [50/100], Loss: 0.0003\n",
      "Epoch [60/100], Loss: 0.0001\n",
      "Epoch [70/100], Loss: 0.0000\n",
      "Epoch [80/100], Loss: 0.0000\n",
      "Epoch [90/100], Loss: 0.0000\n",
      "Epoch [100/100], Loss: 0.0000\n"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "num_epochs = 100\n",
    "h0, c0 = None, None  # Initialize hidden and cell states\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # Forward pass\n",
    "    outputs, h0, c0 = model(X, h0, c0)\n",
    "\n",
    "    # Compute loss\n",
    "    loss = criterion(outputs, y)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    # Detach hidden and cell states to prevent backpropagation through the entire sequence\n",
    "    h0 = h0.detach()\n",
    "    c0 = c0.detach()\n",
    "\n",
    "    if (epoch+1) % 10 == 0:\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "7121aa9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# import torch.nn as nn\n",
    "\n",
    "# # Define model hyperparameters\n",
    "\n",
    "# vocab_size = 50    # Size of the character vocabulary\n",
    "# embedding_dim = 64 # Dimension of character embeddings\n",
    "# hidden_dim = 128   # Dimension of RNN hidden state\n",
    "# output_dim = 10    # Dimension of the output\n",
    "\n",
    "# # Create the model instance\n",
    "\n",
    "\n",
    "# # Print the model architecture\n",
    "# print(model)\n",
    "\n",
    "# # Example input sequence (batch of sequences of character indices)\n",
    "# example_input = torch.tensor([[1, 2, 3, 4], [4, 3, 2, 1]])  # Batch size = 2, sequence length = 4\n",
    "# output = model(example_input)\n",
    "\n",
    "# print(\"Output shape:\", output.shape)  # Output shape: [batch_size, output_dim]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2ac49fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a7be7b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "######### encoder decoder model ########### attempt 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f02afd94",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "f64246fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.6.0+cpu\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(torch.__version__)\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "945ef3f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['heart.csv', 'hin_test.csv']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "csv_list=[x for x in os.listdir('.') if x.endswith(\".csv\")]\n",
    "print(csv_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "5a230219",
   "metadata": {},
   "outputs": [],
   "source": [
    "######## pre prossing dataset #########\n",
    "import csv\n",
    "csv\n",
    "with open(csv_list[1], 'r',encoding='utf-8') as file:\n",
    "  reader = csv.reader(file) # gets every row--> what do to to get every line? is it necessary?\n",
    "  next(reader)  # Skip the header row if it exists\n",
    "  pairs=[row for row in reader]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "606dbbef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>thermax</th>\n",
       "      <th>थरमैक्स</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sikhaaega</td>\n",
       "      <td>सिखाएगा</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>learn</td>\n",
       "      <td>लर्न</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>twitters</td>\n",
       "      <td>ट्विटर्स</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tirunelveli</td>\n",
       "      <td>तिरुनेलवेली</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>independence</td>\n",
       "      <td>इंडिपेंडेंस</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>jivan</td>\n",
       "      <td>जीवन</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>reddy</td>\n",
       "      <td>रेड्डी</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>pehni</td>\n",
       "      <td>पहनी</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>tanu</td>\n",
       "      <td>तनु</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>deepika</td>\n",
       "      <td>दीपिका</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          thermax      थरमैक्स\n",
       "0       sikhaaega      सिखाएगा\n",
       "1           learn         लर्न\n",
       "2        twitters     ट्विटर्स\n",
       "3     tirunelveli  तिरुनेलवेली\n",
       "4    independence  इंडिपेंडेंस\n",
       "..            ...          ...\n",
       "495         jivan         जीवन\n",
       "496         reddy       रेड्डी\n",
       "497         pehni         पहनी\n",
       "498          tanu          तनु\n",
       "499       deepika       दीपिका\n",
       "\n",
       "[500 rows x 2 columns]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# do the above with pandas\n",
    "\n",
    "import pandas as pd\n",
    "csv_data=pd.read_csv(csv_list[1])\n",
    "csv_data.iloc[0:500,:] # english\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "34e3914e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['sikhaaega', 'सिखाएगा'], ['learn', 'लर्न'], ['twitters', 'ट्विटर्स'], ['tirunelveli', 'तिरुनेलवेली'], ['independence', 'इंडिपेंडेंस'], ['speshiyon', 'स्पेशियों'], ['shurooh', 'शुरूः'], ['kolhapur', 'कोल्हापुर'], ['ajhar', 'अजहर'], ['karaar', 'क़रार']]\n",
      "4095\n"
     ]
    }
   ],
   "source": [
    "print(pairs[:10])\n",
    "print(len(pairs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "4a193ba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Path to text file\n",
    "# file_path = 'eng_ita_v2.txt'\n",
    "\n",
    "# # Process the data\n",
    "# pairs = read_data(file_path)\n",
    "# len(pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "a87d5972",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating the vocabulary\n",
    "def tokenize(sentence):\n",
    "#     print(sentence)\n",
    "    return sentence.lower().split()\n",
    "\n",
    "\n",
    "## tokenize and build vocabularies\n",
    "\n",
    "def build_vocab(pairs):\n",
    "    eng_vocab=set()\n",
    "    hin_vocab=set()\n",
    "#     i=0\n",
    "    for eng,hin in pairs:\n",
    "        eng_vocab.update(tokenize(eng)) # |= update\n",
    "        hin_vocab.update(tokenize(hin))\n",
    "    return eng_vocab,hin_vocab\n",
    "\n",
    "english_vocab,hindi_vocab= build_vocab(pairs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "9fb3664d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4070\n",
      "3373\n"
     ]
    }
   ],
   "source": [
    "# # Creating word to integer mapping\n",
    "# eng_word2int = {word: i for i, word in enumerate(english_vocab)}\n",
    "# hin_word2int = {word: i for i, word in enumerate(hindi_vocab)}\n",
    "\n",
    "# # Creating integer to word mapping\n",
    "# eng_int2word = {i: word for word, i in eng_word2int.items()} # dict.itam()- iterate over dict and returns item and key pair\n",
    "# hin_int2word = {i: word for word, i in hin_word2int.items()}\n",
    "\n",
    "\n",
    "print(len(english_vocab))\n",
    "print(len(hindi_vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b1100bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "english_vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "fa19348d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Special tokens\n",
    "PAD_TOKEN = \"<PAD>\"\n",
    "EOS_TOKEN = \"<EOS>\"\n",
    "SOS_TOKEN = \"<SOS>\"\n",
    "UNK_TOKEN = \"<UNK>\"\n",
    "# Update the function to create mappings to include the special tokens\n",
    "def create_mappings(vocab):\n",
    "    vocab = [PAD_TOKEN, SOS_TOKEN, EOS_TOKEN, UNK_TOKEN] + sorted(vocab)\n",
    "    word2int = {word: i for i, word in enumerate(vocab)}\n",
    "    int2word = {i: word for word, i in word2int.items()}\n",
    "    return word2int, int2word\n",
    "\n",
    "# Update the vocabularies\n",
    "eng_word2int, eng_int2word = create_mappings(english_vocab)\n",
    "hin_word2int, hin_int2word = create_mappings(hindi_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "04670b55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eng_word2int[\"<PAD>\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "b9326aed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "English text encoded: [2022 1508]\n",
      "Decoded English: learn independence\n"
     ]
    }
   ],
   "source": [
    "eng_example = \"learn independence\"\n",
    "# hind_sentence=pairs[0][1]\n",
    "# print(tokenize(eng_example))\n",
    "# Encoding\n",
    "eng_encoded = np.array([eng_word2int[word] for word in tokenize(eng_example)], dtype=np.int32)\n",
    "# tokenize lower case and split the test based on spaces\n",
    "# ita_encoded = np.array([ita_word2int[word] for word in tokenize(ita_example)], dtype=np.int32)\n",
    "\n",
    "print('English text encoded:', eng_encoded)\n",
    "# print('Italian text encoded:', ita_encoded)\n",
    "\n",
    "# Decoding\n",
    "print('Decoded English:', ' '.join([eng_int2word[i] for i in eng_encoded]))\n",
    "# print('Decoded Italian:', ' '.join([ita_int2word[i] for i in ita_encoded]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "af45b3e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TranslationDataset(Dataset):\n",
    "    def __init__(self, pairs, eng_word2int, hin_word2int):\n",
    "        self.pairs = pairs\n",
    "        self.eng_word2int = eng_word2int\n",
    "        self.hin_word2int = hin_word2int\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.pairs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        eng, hin = self.pairs[idx]\n",
    "        eng_tensor = torch.tensor([self.eng_word2int[word] for word in tokenize(eng)]\n",
    "                                  + [self.eng_word2int[EOS_TOKEN]], dtype=torch.long)\n",
    "        hin_tensor = torch.tensor([self.hin_word2int[word] for word in tokenize(hin)]\n",
    "                                  + [self.hin_word2int[EOS_TOKEN]], dtype=torch.long)\n",
    "        return eng_tensor, hin_tensor\n",
    "\n",
    "# Custom collate function to handle padding # what does it do ?-> fill the extra space to complete the sentence\n",
    "def collate_fn(batch):\n",
    "    eng_batch, hin_batch = zip(*batch)\n",
    "    eng_batch_padded = pad_sequence(eng_batch, batch_first=True, padding_value=eng_word2int[PAD_TOKEN])\n",
    "    hin_batch_padded = pad_sequence(hin_batch, batch_first=True, padding_value=hin_word2int[PAD_TOKEN])\n",
    "    return eng_batch_padded, hin_batch_padded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "2855e1eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Translation samples:  4095\n",
      "Translation batches:  63\n"
     ]
    }
   ],
   "source": [
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "# Create the dataset and DataLoader\n",
    "translation_dataset = TranslationDataset(pairs, eng_word2int, hin_word2int)\n",
    "batch_size = 64\n",
    "translation_dataloader = DataLoader(translation_dataset, batch_size=batch_size,\n",
    "                                    shuffle=True,  drop_last=True, collate_fn=collate_fn) \n",
    "# The dataset will transform the sentence pairs into sequences of integers (tokenized form) \n",
    "# so they can be used as input to a machine learning model.\n",
    "\n",
    "# is it specially for translation, how does it know about word2vec \n",
    "print(\"Translation samples: \", len(translation_dataset)) ## does what\n",
    "print(\"Translation batches: \", len(translation_dataloader)) ## does what"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "a96c255d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63.984375\n",
      "tensor([[ 3,  2,  5,  2],\n",
      "        [ 1,  2,  3, -1]])\n",
      "torch.Size([2, 4])\n"
     ]
    }
   ],
   "source": [
    "print(len(pairs)/64)\n",
    "k=torch.tensor([[1,2,3,-1],[3,2,5,2]])\n",
    "z=torch.flip(k,[0])\n",
    "print(z)\n",
    "print(z.shape)\n",
    "# Example: iterating over the DataLoader\n",
    "# for eng, hin in translation_dataloader:\n",
    "#     print(\"English batch:\", eng)\n",
    "#     print(\"Hindi batch:\", hin)\n",
    "#     break # remove this to iterate over the whole dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "5b9ae837",
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoder/decoder RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "b0968344",
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoder \n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_size, hidden_size, num_layers=1):\n",
    "        super().__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_size)\n",
    "        self.lstm = nn.LSTM(embed_size, hidden_size, num_layers=num_layers,\n",
    "                            batch_first=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Reversing the sequence of indices\n",
    "        x = torch.flip(x, [1]) # flip column wise row seq --> [1,2,3,4] --> [4,3,2,1]\n",
    "        print(f\"x shape {x.size()}\")\n",
    "        embedded = self.embedding(x)\n",
    "        print(f\"embedded size {embedded.shape} \")\n",
    "        outputs, (hidden, cell) = self.lstm(embedded)\n",
    "        print(f\"outsize {outputs.shape}\")\n",
    "        return outputs, hidden, cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "83055192",
   "metadata": {},
   "outputs": [],
   "source": [
    "# decoder \n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_size, hidden_size, num_layers=1):\n",
    "        super().__init__()\n",
    "#         self.hidden_size = hidden_size\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_size)\n",
    "        self.lstm = nn.LSTM(embed_size, hidden_size, num_layers=num_layers,\n",
    "                            batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, vocab_size)\n",
    "\n",
    "    def forward(self, x, hidden, cell):\n",
    "        out = self.embedding(x)\n",
    "        out, (hidden, cell) = self.lstm(out, (hidden, cell))\n",
    "        out = self.fc(out).reshape(out.size(0), -1)\n",
    "        return out, hidden, cell\n",
    "# lstm output is out, h_n (hidden), c_n. (cell)\n",
    "    \n",
    "#output-> shape --> (N,L,D∗H_{out}) when batch_first=True\n",
    "# h_n -> (D∗num_layers,N,H_{out})\n",
    "# c_n -> (D∗num_layers,N,H_{out})"
   ]
  },
  {
   "attachments": {
    "dim_lstm.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "id": "d2b3ca8a",
   "metadata": {},
   "source": [
    "![dim_lstm.png](attachment:dim_lstm.png) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "1d42f0f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# what is the total number of computations done by the network-\n",
    "# A)\n",
    "# embd_size=m\n",
    "# hiden_state=k\n",
    "# lenght of input and out sequence T\n",
    "# lenght of vocab V (same for both source and target)\n",
    "\n",
    "\n",
    "\n",
    "# B)\n",
    "# total number of parameters in the network\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "10fa441d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "eng_vocab_size = len(eng_word2int)\n",
    "hin_vocab_size = len(hin_word2int)\n",
    "embed_size = 256\n",
    "hidden_size = 512\n",
    "num_layers = 1\n",
    "\n",
    "# Initialize the models\n",
    "encoder_lstm = Encoder(eng_vocab_size, embed_size, hidden_size, num_layers).to(device)\n",
    "decoder_lstm = Decoder(hin_vocab_size, embed_size, hidden_size, num_layers).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "ec970e48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoder summary\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "=================================================================\n",
       "Layer (type:depth-idx)                   Param #\n",
       "=================================================================\n",
       "Encoder                                  --\n",
       "├─Embedding: 1-1                         1,042,944\n",
       "├─LSTM: 1-2                              3,153,920\n",
       "=================================================================\n",
       "Total params: 4,196,864\n",
       "Trainable params: 4,196,864\n",
       "Non-trainable params: 0\n",
       "================================================================="
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import torchinfo\n",
    "from torchinfo import summary\n",
    "print(\"Encoder summary\")\n",
    "summary(encoder) # do a test pass through of an example input size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "d0313a9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dencoder summary\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "=================================================================\n",
       "Layer (type:depth-idx)                   Param #\n",
       "=================================================================\n",
       "Decoder                                  --\n",
       "├─Embedding: 1-1                         864,512\n",
       "├─LSTM: 1-2                              5,251,072\n",
       "├─Linear: 1-3                            3,461,425\n",
       "=================================================================\n",
       "Total params: 9,577,009\n",
       "Trainable params: 9,577,009\n",
       "Non-trainable params: 0\n",
       "================================================================="
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Dencoder summary\")\n",
    "summary(decoder) # do a test pass through of an example input size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7c7c181",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "ee2020db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate(encoder, decoder, sentence, eng_word2int, ita_int2word, max_length=15):\n",
    "    encoder.eval()\n",
    "    decoder.eval()\n",
    "    with torch.inference_mode():\n",
    "        # Tokenize and encode the sentence\n",
    "        input_tensor = torch.tensor([eng_word2int[word] for word in tokenize(sentence)]\n",
    "                                    + [eng_word2int[EOS_TOKEN]], dtype=torch.long)\n",
    "#         print(f\"shape of input tensor is {input_tensor.shape}\")\n",
    "        input_tensor = input_tensor.view(1, -1).to(DEVICE)  # batch_first=True\n",
    "\n",
    "        # Pass the input through the encoder\n",
    "        _, encoder_hidden, encoder_cell = encoder(input_tensor)\n",
    "#         print(f\"encoder hidden shape, cell shape {encoder_hidden.shape, encoder_cell.shape}\")\n",
    "        # encoder output\n",
    "\n",
    "        # Initialize the decoder input with the SOS token\n",
    "        decoder_input = torch.tensor([[eng_word2int[SOS_TOKEN]]], dtype=torch.long)  # SOS\n",
    "#         print(f\"decoder input first {decoder_input}\")\n",
    "        # Initialize the hidden state of the decoder with the encoder's hidden state\n",
    "        decoder_hidden, decoder_cell = encoder_hidden, encoder_cell\n",
    "\n",
    "        # Decoding the sentence\n",
    "        decoded_words = []\n",
    "        last_word = torch.tensor([[eng_word2int[SOS_TOKEN]]]).to(DEVICE)\n",
    "        print(f\"last word {last_word}\")\n",
    "        for di in range(max_length):\n",
    "            logits, decoder_hidden, decoder_cell = decoder(last_word, decoder_hidden, decoder_cell)\n",
    "#             print(f\"logits shape is (should be equal to hidni vocab 3373ish) {logits.shape}\")\n",
    "            next_token = logits.argmax(dim=1) # greedy #\n",
    "#             print(f\"next token index is (expecting it to be scalar) {next_token}\")\n",
    "            last_word = torch.tensor([[next_token]]).to(DEVICE)\n",
    "            if next_token.item() == hin_word2int[EOS_TOKEN]:\n",
    "                break\n",
    "            else:\n",
    "                decoded_words.append(ita_int2word.get(next_token.item()))\n",
    "\n",
    "        return ' '.join(decoded_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "8539321e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of input tensor is torch.Size([3])\n",
      "x shape torch.Size([1, 3])\n",
      "embedded size torch.Size([1, 3, 256]) \n",
      "outsize torch.Size([1, 3, 512])\n",
      "encoder hidden shape, cell shape (torch.Size([1, 1, 512]), torch.Size([1, 1, 512]))\n",
      "decoder input first tensor([[1]])\n",
      "last word tensor([[1]])\n",
      "logits shape is (should be equal to hidni vocab 3373ish) torch.Size([1, 3377])\n",
      "next token index is (expecting it to be scalar) tensor([1489])\n",
      "logits shape is (should be equal to hidni vocab 3373ish) torch.Size([1, 3377])\n",
      "next token index is (expecting it to be scalar) tensor([2627])\n",
      "logits shape is (should be equal to hidni vocab 3373ish) torch.Size([1, 3377])\n",
      "next token index is (expecting it to be scalar) tensor([932])\n",
      "logits shape is (should be equal to hidni vocab 3373ish) torch.Size([1, 3377])\n",
      "next token index is (expecting it to be scalar) tensor([1142])\n",
      "logits shape is (should be equal to hidni vocab 3373ish) torch.Size([1, 3377])\n",
      "next token index is (expecting it to be scalar) tensor([62])\n",
      "logits shape is (should be equal to hidni vocab 3373ish) torch.Size([1, 3377])\n",
      "next token index is (expecting it to be scalar) tensor([1142])\n",
      "logits shape is (should be equal to hidni vocab 3373ish) torch.Size([1, 3377])\n",
      "next token index is (expecting it to be scalar) tensor([62])\n",
      "logits shape is (should be equal to hidni vocab 3373ish) torch.Size([1, 3377])\n",
      "next token index is (expecting it to be scalar) tensor([62])\n",
      "logits shape is (should be equal to hidni vocab 3373ish) torch.Size([1, 3377])\n",
      "next token index is (expecting it to be scalar) tensor([62])\n",
      "logits shape is (should be equal to hidni vocab 3373ish) torch.Size([1, 3377])\n",
      "next token index is (expecting it to be scalar) tensor([2315])\n",
      "logits shape is (should be equal to hidni vocab 3373ish) torch.Size([1, 3377])\n",
      "next token index is (expecting it to be scalar) tensor([3088])\n",
      "logits shape is (should be equal to hidni vocab 3373ish) torch.Size([1, 3377])\n",
      "next token index is (expecting it to be scalar) tensor([2392])\n",
      "logits shape is (should be equal to hidni vocab 3373ish) torch.Size([1, 3377])\n",
      "next token index is (expecting it to be scalar) tensor([1981])\n",
      "logits shape is (should be equal to hidni vocab 3373ish) torch.Size([1, 3377])\n",
      "next token index is (expecting it to be scalar) tensor([2084])\n",
      "logits shape is (should be equal to hidni vocab 3373ish) torch.Size([1, 3377])\n",
      "next token index is (expecting it to be scalar) tensor([29])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'नाऊ रोवे छींके टोरेंट अनम टोरेंट अनम अनम अनम मानवटरहित साभार मेजबान बम्लेश्वरी बेंडर अचीवमेंट'"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eng_example = \"learn independence\"\n",
    "translate(encoder_lstm,decoder_lstm,eng_example, eng_word2int, hin_int2word)\n",
    "# eng_word2int, eng_int2word = create_mappings(english_vocab)\n",
    "# hin_word2int, hin_int2word = create_mappings(hindi_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "7bec3244",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: '<PAD>',\n",
       " 1: '<SOS>',\n",
       " 2: '<EOS>',\n",
       " 3: '<UNK>',\n",
       " 4: 'अंक',\n",
       " 5: 'अंकोर',\n",
       " 6: 'अंडमान',\n",
       " 7: 'अंडरवुड',\n",
       " 8: 'अंतडियां',\n",
       " 9: 'अंतर्मुख',\n",
       " 10: 'अंदरखाने',\n",
       " 11: 'अंदाजी',\n",
       " 12: 'अंधभक्तो',\n",
       " 13: 'अंधापन',\n",
       " 14: 'अंबानी',\n",
       " 15: 'अंशांकन',\n",
       " 16: 'अकापुल्को',\n",
       " 17: 'अकोला',\n",
       " 18: 'अक्रोन',\n",
       " 19: 'अखुआपाड़ा',\n",
       " 20: 'अगरतला',\n",
       " 21: 'अगवाई',\n",
       " 22: 'अगस्टाइन',\n",
       " 23: 'अगस्ता',\n",
       " 24: 'अग्नियां',\n",
       " 25: 'अग्र',\n",
       " 26: 'अग्रवाल',\n",
       " 27: 'अग्रहरि',\n",
       " 28: 'अचंभा',\n",
       " 29: 'अचीवमेंट',\n",
       " 30: 'अच्छी',\n",
       " 31: 'अच्युत',\n",
       " 32: 'अछनेरा',\n",
       " 33: 'अजस्र',\n",
       " 34: 'अजहर',\n",
       " 35: 'अजित',\n",
       " 36: 'अज्ञात',\n",
       " 37: 'अटकता',\n",
       " 38: 'अटके',\n",
       " 39: 'अटलांटिक',\n",
       " 40: 'अटवाल',\n",
       " 41: 'अट्टरा',\n",
       " 42: 'अट्टहास',\n",
       " 43: 'अट्रैक्ट',\n",
       " 44: 'अड़ंगा',\n",
       " 45: 'अड़चने',\n",
       " 46: 'अतहर',\n",
       " 47: 'अतुल',\n",
       " 48: 'अते',\n",
       " 49: 'अत्री',\n",
       " 50: 'अथक',\n",
       " 51: 'अदाणी',\n",
       " 52: 'अद्र्घ',\n",
       " 53: 'अद्वैत',\n",
       " 54: 'अद्वैतवाद',\n",
       " 55: 'अधिकरन',\n",
       " 56: 'अधिकरियों',\n",
       " 57: 'अधिकारियां',\n",
       " 58: 'अधिवक्तागण',\n",
       " 59: 'अधिवास',\n",
       " 60: 'अधीक',\n",
       " 61: 'अनगढ़',\n",
       " 62: 'अनम',\n",
       " 63: 'अनशिदा',\n",
       " 64: 'अनहोनी',\n",
       " 65: 'अनाधिकारिक',\n",
       " 66: 'अनावश्यक',\n",
       " 67: 'अनिष्टता',\n",
       " 68: 'अनुचित',\n",
       " 69: 'अनुपमा',\n",
       " 70: 'अनुप्रयोगों',\n",
       " 71: 'अनुमार',\n",
       " 72: 'अनुरीत',\n",
       " 73: 'अनुसारका',\n",
       " 74: 'अनोंदिता',\n",
       " 75: 'अन्त्यन्त',\n",
       " 76: 'अन्याय',\n",
       " 77: 'अन्योन्याश्रितता',\n",
       " 78: 'अन्वाहार्य',\n",
       " 79: 'अपनानी',\n",
       " 80: 'अपर',\n",
       " 81: 'अपरिवर्तनशील',\n",
       " 82: 'अपरिहार्य',\n",
       " 83: 'अपवर्तित',\n",
       " 84: 'अपारदर्शी',\n",
       " 85: 'अफसराें',\n",
       " 86: 'अब्दुन्नासिर',\n",
       " 87: 'अभिमत',\n",
       " 88: 'अभियुक्तोंके',\n",
       " 89: 'अमझेरा',\n",
       " 90: 'अमरगढ़',\n",
       " 91: 'अमरपाल',\n",
       " 92: 'अमरोही',\n",
       " 93: 'अमानत',\n",
       " 94: 'अमानती',\n",
       " 95: 'अमारा',\n",
       " 96: 'अमारिलो',\n",
       " 97: 'अमावस्या',\n",
       " 98: 'अमित',\n",
       " 99: 'अमिताव',\n",
       " 100: 'अम्बानी',\n",
       " 101: 'अम्बिकाओं',\n",
       " 102: 'अम्बिकापुर',\n",
       " 103: 'अयोध्यानाथ',\n",
       " 104: 'अरदास',\n",
       " 105: 'अरबपतियों',\n",
       " 106: 'अरुणाई',\n",
       " 107: 'अरुणाचल',\n",
       " 108: 'अरेना',\n",
       " 109: 'अरेलानो',\n",
       " 110: 'अर्जेंट',\n",
       " 111: 'अर्थ',\n",
       " 112: 'अर्थव्यवस्थताओं',\n",
       " 113: 'अर्थव्यवस्थाः',\n",
       " 114: 'अर्थशास्त्रीयों',\n",
       " 115: 'अर्थों',\n",
       " 116: 'अर्धविश्वास',\n",
       " 117: 'अर्बनडेल',\n",
       " 118: 'अर्यमा',\n",
       " 119: 'अलंकार',\n",
       " 120: 'अलगअलग',\n",
       " 121: 'अलयमनी',\n",
       " 122: 'अलाइव',\n",
       " 123: 'अलायंस',\n",
       " 124: 'अली',\n",
       " 125: 'अलीम',\n",
       " 126: 'अल्बा',\n",
       " 127: 'अल्वधि',\n",
       " 128: 'अवरु',\n",
       " 129: 'अवरोधक',\n",
       " 130: 'अवर्णता',\n",
       " 131: 'अवशिष्ट',\n",
       " 132: 'अवस्थाएं',\n",
       " 133: 'अवस्थी',\n",
       " 134: 'अवि',\n",
       " 135: 'अवैज्ञानिक',\n",
       " 136: 'अव्यवसायी',\n",
       " 137: 'अशक्तता',\n",
       " 138: 'अशरफी',\n",
       " 139: 'अशरीरी',\n",
       " 140: 'असम',\n",
       " 141: 'असमान्य',\n",
       " 142: 'असाही',\n",
       " 143: 'असुरक्षित',\n",
       " 144: 'अस्मिताओं',\n",
       " 145: 'अस्वभाविक',\n",
       " 146: 'अहमदाबादः',\n",
       " 147: 'अहितकारी',\n",
       " 148: 'आंत्रित',\n",
       " 149: 'आंध्रा',\n",
       " 150: 'आंबियंस',\n",
       " 151: 'आइंथू',\n",
       " 152: 'आइटम्स',\n",
       " 153: 'आइडल',\n",
       " 154: 'आइपीएफ',\n",
       " 155: 'आइसीसी',\n",
       " 156: 'आईडिया',\n",
       " 157: 'आईरिस',\n",
       " 158: 'आकंड़ों',\n",
       " 159: 'आकाश',\n",
       " 160: 'आगमन',\n",
       " 161: 'आग़ा',\n",
       " 162: 'आगाशे',\n",
       " 163: 'आजमाना',\n",
       " 164: 'आटा',\n",
       " 165: 'आत्ममुग्ध',\n",
       " 166: 'आत्माएं',\n",
       " 167: 'आदान',\n",
       " 168: 'आदित्या',\n",
       " 169: 'आदिवादियों',\n",
       " 170: 'आदेशः',\n",
       " 171: 'आधीन',\n",
       " 172: 'आनंददायक',\n",
       " 173: 'आपका',\n",
       " 174: 'आपदाएं',\n",
       " 175: 'आफरीन',\n",
       " 176: 'आफॅ',\n",
       " 177: 'आबरू',\n",
       " 178: 'आबूरोड',\n",
       " 179: 'आमदनी',\n",
       " 180: 'आमदी',\n",
       " 181: 'आमरियापाड़ा',\n",
       " 182: 'आमोद',\n",
       " 183: 'आयुधनिर्माणी',\n",
       " 184: 'आरपी',\n",
       " 185: 'आराम',\n",
       " 186: 'आरुषि',\n",
       " 187: 'आरेखः',\n",
       " 188: 'आर्टेमिस',\n",
       " 189: 'आर्य',\n",
       " 190: 'आर्यनस',\n",
       " 191: 'आर्यम्',\n",
       " 192: 'आर्यिका',\n",
       " 193: 'आर्यो',\n",
       " 194: 'आर्यों',\n",
       " 195: 'आलसी',\n",
       " 196: 'आलोचक',\n",
       " 197: 'आलोचकों',\n",
       " 198: 'आल्हा',\n",
       " 199: 'आवाज़ें',\n",
       " 200: 'आवाज़ों',\n",
       " 201: 'आविष्कार',\n",
       " 202: 'आवृत्ति',\n",
       " 203: 'आवृत्तियों',\n",
       " 204: 'आशंका',\n",
       " 205: 'आश्रितों',\n",
       " 206: 'आसमती',\n",
       " 207: 'आसान',\n",
       " 208: 'आसापास',\n",
       " 209: 'आस्तिक',\n",
       " 210: 'आस्तीन',\n",
       " 211: 'आहूजा',\n",
       " 212: 'इंजन्स',\n",
       " 213: 'इंटरटेक्चुअलिटी',\n",
       " 214: 'इंटरव्यु',\n",
       " 215: 'इंटेलीजेंस',\n",
       " 216: 'इंट्रोडक्शन',\n",
       " 217: 'इंडस्ट्रियल',\n",
       " 218: 'इंडिपेंडेंस',\n",
       " 219: 'इंडिपेन्डेट',\n",
       " 220: 'इंदौरनगर',\n",
       " 221: 'इंश्योरेंस',\n",
       " 222: 'इंसानो',\n",
       " 223: 'इअर',\n",
       " 224: 'इकट्ठा',\n",
       " 225: 'इकठ्ठी',\n",
       " 226: 'इक़बाल',\n",
       " 227: 'इकाई',\n",
       " 228: 'इक्थियोसिस',\n",
       " 229: 'इक्वाडोर',\n",
       " 230: 'इक्विटीज',\n",
       " 231: 'इच्छाचारी',\n",
       " 232: 'इच्छी',\n",
       " 233: 'इजाजत',\n",
       " 234: 'इड्डुक्कि',\n",
       " 235: 'इतिभगवती',\n",
       " 236: 'इनसानी',\n",
       " 237: 'इनहेलेशन',\n",
       " 238: 'इन्द्रियोंके',\n",
       " 239: 'इन्फिबीम',\n",
       " 240: 'इबीजा',\n",
       " 241: 'इमानदारी',\n",
       " 242: 'इम्मैच्योरिटी',\n",
       " 243: 'इम्युन',\n",
       " 244: 'इलाइची',\n",
       " 245: 'इलाज़',\n",
       " 246: 'इलेक्ट्रॉनिक्स',\n",
       " 247: 'इलेक्ट्रोटेक्स',\n",
       " 248: 'इलेक्ट्रोमीटर',\n",
       " 249: 'इलेक्ट्रोमैजिक',\n",
       " 250: 'इलेक्ट्रोस्टील',\n",
       " 251: 'इवान्स्टन',\n",
       " 252: 'इशाक',\n",
       " 253: 'इशारा',\n",
       " 254: 'इसरानी',\n",
       " 255: 'इस्त्राइलियों',\n",
       " 256: 'इस्न्पेक्टोर',\n",
       " 257: 'ईआरजी',\n",
       " 258: 'ईए',\n",
       " 259: 'ईवनिंग',\n",
       " 260: 'ईष्ट',\n",
       " 261: 'ईसाइयों',\n",
       " 262: 'ईस्टवेल',\n",
       " 263: 'उखड',\n",
       " 264: 'उखड़कर',\n",
       " 265: 'उखरुल',\n",
       " 266: 'उच्चअधिकारीयो',\n",
       " 267: 'उच्छृंखलता',\n",
       " 268: 'उछालने',\n",
       " 269: 'उज़्बेक',\n",
       " 270: 'उज्जैन',\n",
       " 271: 'उठनी',\n",
       " 272: 'उठने',\n",
       " 273: 'उठनेवाले',\n",
       " 274: 'उठाएँगे',\n",
       " 275: 'उठाकर',\n",
       " 276: 'उठापटक',\n",
       " 277: 'उठ्ठक',\n",
       " 278: 'उड़ान',\n",
       " 279: 'उड़ाना',\n",
       " 280: 'उड़ानें',\n",
       " 281: 'उड़ानों',\n",
       " 282: 'उड़ेलकर',\n",
       " 283: 'उडाया',\n",
       " 284: 'उतने',\n",
       " 285: 'उतराधिकारी',\n",
       " 286: 'उत्तर',\n",
       " 287: 'उत्तरा',\n",
       " 288: 'उत्तरिया',\n",
       " 289: 'उत्पीडऩ',\n",
       " 290: 'उत्साहवर्द्धन',\n",
       " 291: 'उदंत',\n",
       " 292: 'उदघोष',\n",
       " 293: 'उदयगढ़ी',\n",
       " 294: 'उदयपुर',\n",
       " 295: 'उदर',\n",
       " 296: 'उदा',\n",
       " 297: 'उदाकिशुनगंज',\n",
       " 298: 'उद्धाटन',\n",
       " 299: 'उधमपुर',\n",
       " 300: 'उधारदाताओं',\n",
       " 301: 'उधेड़',\n",
       " 302: 'उन्नतियों',\n",
       " 303: 'उपकार्यालयों',\n",
       " 304: 'उपद्रवियों',\n",
       " 305: 'उपद्रवों',\n",
       " 306: 'उपनेता',\n",
       " 307: 'उपयोगितावादियों',\n",
       " 308: 'उपलक्ष्य',\n",
       " 309: 'उपलब्धियों',\n",
       " 310: 'उपस्थियों',\n",
       " 311: 'उपाख्यानों',\n",
       " 312: 'उप्पीड़न',\n",
       " 313: 'उबरकर',\n",
       " 314: 'उबाल',\n",
       " 315: 'उबाला',\n",
       " 316: 'उभरेगा',\n",
       " 317: 'उभारा',\n",
       " 318: 'उमड़ती',\n",
       " 319: 'उमानाथ',\n",
       " 320: 'उम्मीदवारी',\n",
       " 321: 'उम्मीदे',\n",
       " 322: 'उर्फ',\n",
       " 323: 'उर्वरकों',\n",
       " 324: 'उर्वरता',\n",
       " 325: 'उलझानों',\n",
       " 326: 'उलाहना',\n",
       " 327: 'उल्हासनगर',\n",
       " 328: 'उल्हासपुर',\n",
       " 329: 'उसक',\n",
       " 330: 'उसकी',\n",
       " 331: 'उसी',\n",
       " 332: 'उसेे',\n",
       " 333: 'उस्तरा',\n",
       " 334: 'ऊधामी',\n",
       " 335: 'ऋतुकांत',\n",
       " 336: 'ऋषिकुल',\n",
       " 337: 'ऋषिता',\n",
       " 338: 'ऋषिराज',\n",
       " 339: 'एंकेनी',\n",
       " 340: 'एंजेलिन',\n",
       " 341: 'एंजेलो',\n",
       " 342: 'एंटरप्राइज',\n",
       " 343: 'एंटोन',\n",
       " 344: 'एंटोनी',\n",
       " 345: 'एंट्रीक्स',\n",
       " 346: 'एएलओ',\n",
       " 347: 'एकसाथ',\n",
       " 348: 'एक्ज़ो',\n",
       " 349: 'एक्सक्लेशन',\n",
       " 350: 'एक्सटेक्टर',\n",
       " 351: 'एक्सेल',\n",
       " 352: 'एक्सेल्या',\n",
       " 353: 'एगमोर',\n",
       " 354: 'एचआर',\n",
       " 355: 'एजुकेशन',\n",
       " 356: 'एजूस्पर्मिया',\n",
       " 357: 'एजेंडे',\n",
       " 358: 'एडब्ल्यूपी',\n",
       " 359: 'एडेन',\n",
       " 360: 'एड्डी',\n",
       " 361: 'एनईयू',\n",
       " 362: 'एनएमडीसी',\n",
       " 363: 'एनएसआईयू',\n",
       " 364: 'एनएसीएल',\n",
       " 365: 'एनका',\n",
       " 366: 'एनबीसीसी',\n",
       " 367: 'एनसीआरडब्ल्यूसी',\n",
       " 368: 'एनिड',\n",
       " 369: 'एन्टीओक',\n",
       " 370: 'एपकोटेक्स',\n",
       " 371: 'एपीजे',\n",
       " 372: 'एपेक्स',\n",
       " 373: 'एपोक्लिप्स',\n",
       " 374: 'एफल',\n",
       " 375: 'एबज',\n",
       " 376: 'एबट',\n",
       " 377: 'एबोट',\n",
       " 378: 'एमटीए',\n",
       " 379: 'एमटेक',\n",
       " 380: 'एमडब्ल्यूपी',\n",
       " 381: 'एमडब्ल्यूपीएल',\n",
       " 382: 'एमरल्ड',\n",
       " 383: 'एमिल',\n",
       " 384: 'एमी',\n",
       " 385: 'एयरकंडीशनर',\n",
       " 386: 'एयरटेल',\n",
       " 387: 'एयरवे',\n",
       " 388: 'एरर',\n",
       " 389: 'एरिका',\n",
       " 390: 'एरोनॉटिक्स',\n",
       " 391: 'एलएंडटी',\n",
       " 392: 'एलएक्स',\n",
       " 393: 'एलिमिनेटर',\n",
       " 394: 'एलियंस',\n",
       " 395: 'एलेक्जेंड्रिया',\n",
       " 396: 'एल्टामोंटे',\n",
       " 397: 'एल्बाइनो',\n",
       " 398: 'एवरी',\n",
       " 399: 'एवरेस्ट',\n",
       " 400: 'एवव',\n",
       " 401: 'एशले',\n",
       " 402: 'एशियवन',\n",
       " 403: 'एसपीएफ',\n",
       " 404: 'एसेटल',\n",
       " 405: 'एस्थेटिक',\n",
       " 406: 'एस्फाल्ट',\n",
       " 407: 'एस्वेडो',\n",
       " 408: 'एस्सेल',\n",
       " 409: 'एहसास',\n",
       " 410: 'एेसा',\n",
       " 411: 'ऐंजल',\n",
       " 412: 'ऐंठ',\n",
       " 413: 'ऐंठे',\n",
       " 414: 'ऐक्टिवा',\n",
       " 415: 'ऐक्टिविटीज',\n",
       " 416: 'ऐजेंसियों',\n",
       " 417: 'ऐठन',\n",
       " 418: 'ऐतराज़',\n",
       " 419: 'ऐप्प',\n",
       " 420: 'ऐल',\n",
       " 421: 'ऐल्प्स',\n",
       " 422: 'ऐवीऐशन',\n",
       " 423: 'ऐसे',\n",
       " 424: 'ऑंखें',\n",
       " 425: 'ऑक्साइड',\n",
       " 426: 'ऑक्सीज',\n",
       " 427: 'ऑगस्टावेस्टलैंड',\n",
       " 428: 'ऑग्रेनाइज',\n",
       " 429: 'ऑडिटर',\n",
       " 430: 'ऑथोरिटी',\n",
       " 431: 'ऑफरः',\n",
       " 432: 'ऑफशोर',\n",
       " 433: 'ऑफिशियली',\n",
       " 434: 'ऑफिसरी',\n",
       " 435: 'ऑब्जर्वर',\n",
       " 436: 'ऑब्स्क्योरा',\n",
       " 437: 'ऑरोरा',\n",
       " 438: 'ऑर्डनेंस',\n",
       " 439: 'ऑलआउट',\n",
       " 440: 'ऑलकार्गो',\n",
       " 441: 'ऑलराउंडर',\n",
       " 442: 'ऑल्टो',\n",
       " 443: 'ऑस्टिन',\n",
       " 444: 'ओईएफ',\n",
       " 445: 'ओकलाहोमा',\n",
       " 446: 'ओकोआ',\n",
       " 447: 'ओकोई',\n",
       " 448: 'ओक्लाहोमा',\n",
       " 449: 'ओझा',\n",
       " 450: 'ओडिसा',\n",
       " 451: 'ओडोम',\n",
       " 452: 'ओढ़कर',\n",
       " 453: 'ओब्रायन',\n",
       " 454: 'ओमैक्स',\n",
       " 455: 'ओरछा',\n",
       " 456: 'ओरण',\n",
       " 457: 'ओर्टेगा',\n",
       " 458: 'ओवम',\n",
       " 459: 'ओवरऑल',\n",
       " 460: 'औटोमैटिकली',\n",
       " 461: 'औद्योगिकरण',\n",
       " 462: 'औरतो',\n",
       " 463: 'औरोरा',\n",
       " 464: 'कंगन',\n",
       " 465: 'कंघे',\n",
       " 466: 'कंचन',\n",
       " 467: 'कंजेंटेवाइटिस',\n",
       " 468: 'कंटिन्यू',\n",
       " 469: 'कंट्रोल',\n",
       " 470: 'कंठहार',\n",
       " 471: 'कंदरौर',\n",
       " 472: 'कंबलों',\n",
       " 473: 'कंसाई',\n",
       " 474: 'कईं',\n",
       " 475: 'कक्कड़',\n",
       " 476: 'कक्षांग',\n",
       " 477: 'कच्छे',\n",
       " 478: 'कटरा',\n",
       " 479: 'कटलरी',\n",
       " 480: 'कटिहार',\n",
       " 481: 'कठनाईयों',\n",
       " 482: 'कठफोड़वे',\n",
       " 483: 'कठुआ',\n",
       " 484: 'कताल',\n",
       " 485: 'कदमो',\n",
       " 486: 'कनलोग',\n",
       " 487: 'कनाल',\n",
       " 488: 'कनिंघम',\n",
       " 489: 'कन्याएं',\n",
       " 490: 'कन्वेंशन',\n",
       " 491: 'कन्वोकेशन',\n",
       " 492: 'कप',\n",
       " 493: 'कपड़ा',\n",
       " 494: 'कपिंग',\n",
       " 495: 'कपूर',\n",
       " 496: 'कपूरथला',\n",
       " 497: 'कपोलकल्पना',\n",
       " 498: 'कबड्डी',\n",
       " 499: 'कबहा',\n",
       " 500: 'कमज़ोर',\n",
       " 501: 'कमतर',\n",
       " 502: 'कमलजीत',\n",
       " 503: 'कमाऊ',\n",
       " 504: 'कमारहाटी',\n",
       " 505: 'कमेरे',\n",
       " 506: 'कम्युनिकेटर्स',\n",
       " 507: 'कम्यूनिकेशन्स',\n",
       " 508: 'कर',\n",
       " 509: 'करंज',\n",
       " 510: 'करखेले',\n",
       " 511: 'करघे',\n",
       " 512: 'करब',\n",
       " 513: 'करवायेगी',\n",
       " 514: 'कराईकल',\n",
       " 515: 'करावणौ',\n",
       " 516: 'कराहना',\n",
       " 517: 'कर्णेश्वरधाम',\n",
       " 518: 'कर्माचारी',\n",
       " 519: 'कर्वी',\n",
       " 520: 'कलमें',\n",
       " 521: 'कलसाना',\n",
       " 522: 'कवि',\n",
       " 523: 'कश्मीर',\n",
       " 524: 'कश्यप',\n",
       " 525: 'कसेगा',\n",
       " 526: 'कसेरा',\n",
       " 527: 'कहलाया',\n",
       " 528: 'कहावह',\n",
       " 529: 'क़ब्ज़ा',\n",
       " 530: 'क़रार',\n",
       " 531: 'क़ायल',\n",
       " 532: 'कांचीपुरम',\n",
       " 533: 'कांट',\n",
       " 534: 'कांतिपूर्ण',\n",
       " 535: 'कांस्टिंग',\n",
       " 536: 'काकीनाड़ा',\n",
       " 537: 'काकू',\n",
       " 538: 'काक्षीवती',\n",
       " 539: 'काजी',\n",
       " 540: 'काजू',\n",
       " 541: 'काठियावड़ी',\n",
       " 542: 'काथला',\n",
       " 543: 'काबिलेगौर',\n",
       " 544: 'काबिलेतारीफ',\n",
       " 545: 'कामानाएं',\n",
       " 546: 'कामोत्तेजना',\n",
       " 547: 'कायलाना',\n",
       " 548: 'कारगिल',\n",
       " 549: 'कारगुजारियां',\n",
       " 550: 'काराबोरियों',\n",
       " 551: 'कार्की',\n",
       " 552: 'कार्नियां',\n",
       " 553: 'कार्बोजेन',\n",
       " 554: 'कार्यकर्ताओं',\n",
       " 555: 'कार्यकर्त्रियों',\n",
       " 556: 'कार्यकार्यकर्ताओं',\n",
       " 557: 'कार्यभार',\n",
       " 558: 'कार्ययोजना',\n",
       " 559: 'कार्यावधि',\n",
       " 560: 'कार्वाई',\n",
       " 561: 'कार्सन',\n",
       " 562: 'कालाहान',\n",
       " 563: 'कालोनीवासियों',\n",
       " 564: 'काल्डवेल',\n",
       " 565: 'काव',\n",
       " 566: 'काव्यविधाओं',\n",
       " 567: 'काव्योक्तियां',\n",
       " 568: 'कासोवो',\n",
       " 569: 'कास्टानेडा',\n",
       " 570: 'काॅप्लेक्स',\n",
       " 571: 'किंगखान',\n",
       " 572: 'किकियाना',\n",
       " 573: 'किदवई',\n",
       " 574: 'किल्लत',\n",
       " 575: 'किशुन',\n",
       " 576: 'किसानी',\n",
       " 577: 'किसानों',\n",
       " 578: 'किस्सागोई',\n",
       " 579: 'कीड़े',\n",
       " 580: 'कीति',\n",
       " 581: 'कीरतपुर',\n",
       " 582: 'कुंडल',\n",
       " 583: 'कुंडलियाँ',\n",
       " 584: 'कुआलालंपूर',\n",
       " 585: 'कुएस',\n",
       " 586: 'कुकरेजा',\n",
       " 587: 'कुच्छ',\n",
       " 588: 'कुत्ता',\n",
       " 589: 'कुपोषित',\n",
       " 590: 'कुबुद्दीन',\n",
       " 591: 'कुमाऊ',\n",
       " 592: 'कुमार',\n",
       " 593: 'कुमारी',\n",
       " 594: 'कुमावत',\n",
       " 595: 'कुरआने',\n",
       " 596: 'कुरमी',\n",
       " 597: 'कुरुक्षेत्र',\n",
       " 598: 'कुर्मी',\n",
       " 599: 'कुर्वेती',\n",
       " 600: 'कुर्सियॉ',\n",
       " 601: 'कुर्सियों',\n",
       " 602: 'कुल्लवी',\n",
       " 603: 'कुश',\n",
       " 604: 'कुशवाहा',\n",
       " 605: 'कुषाण',\n",
       " 606: 'कूच',\n",
       " 607: 'कूत्ता',\n",
       " 608: 'कून',\n",
       " 609: 'कृत्या',\n",
       " 610: 'कृबरभ',\n",
       " 611: 'कृष्णानगर',\n",
       " 612: 'केपीओ',\n",
       " 613: 'केरला',\n",
       " 614: 'केली',\n",
       " 615: 'केशरी',\n",
       " 616: 'केस्टालॉय',\n",
       " 617: 'कैंटन',\n",
       " 618: 'कैंटरबरी',\n",
       " 619: 'कैंब्रिज',\n",
       " 620: 'कैटरीना',\n",
       " 621: 'कैटलिन',\n",
       " 622: 'कैडमियम',\n",
       " 623: 'कैथोलिकों',\n",
       " 624: 'कैनविज',\n",
       " 625: 'कैपधारी',\n",
       " 626: 'कैपलिन',\n",
       " 627: 'कैपेसिटर',\n",
       " 628: 'कैमस्टूडियो',\n",
       " 629: 'कैमेरिलो',\n",
       " 630: 'कैल्यूमेट',\n",
       " 631: 'कॉन्ट्रेक्टिंग',\n",
       " 632: 'कॉन्वे',\n",
       " 633: 'कॉमर्स',\n",
       " 634: 'कोचीन',\n",
       " 635: 'कोचेला',\n",
       " 636: 'कोच्चिः',\n",
       " 637: 'कोट्टयम',\n",
       " 638: 'कोयम्बटूर',\n",
       " 639: 'कोरापुट',\n",
       " 640: 'कोरियाः',\n",
       " 641: 'कोरोला',\n",
       " 642: 'कोलंबिया',\n",
       " 643: 'कोलन',\n",
       " 644: 'कोलिंग',\n",
       " 645: 'कोलोराडो',\n",
       " 646: 'कोल्हापुर',\n",
       " 647: 'कोविना',\n",
       " 648: 'कोषाधिकारी',\n",
       " 649: 'कौण्डल',\n",
       " 650: 'कौशल',\n",
       " 651: 'कौशलता',\n",
       " 652: 'कौशिक',\n",
       " 653: 'क्याः',\n",
       " 654: 'क्यूआईडब्ल्यूआई',\n",
       " 655: 'क्यूआईपीएस',\n",
       " 656: 'क्यूएसएस',\n",
       " 657: 'क्यूट',\n",
       " 658: 'क्यूडब्ल्यूवीजीए',\n",
       " 659: 'क्यूबेक',\n",
       " 660: 'क्यूसैक्स',\n",
       " 661: 'क्रांतिधरा',\n",
       " 662: 'क्रांतियों',\n",
       " 663: 'क्रान्फ्रेंसिंग',\n",
       " 664: 'क्रिकेट',\n",
       " 665: 'क्रिकेटिंग',\n",
       " 666: 'क्रिप्टोकरेंसियों',\n",
       " 667: 'क्रिस्टिस',\n",
       " 668: 'क्रुएगर',\n",
       " 669: 'क्रुसेस',\n",
       " 670: 'क्रेन',\n",
       " 671: 'क्रेन्द्रों',\n",
       " 672: 'क्रेमिस्ट्री',\n",
       " 673: 'क्रेस्ट',\n",
       " 674: 'क्रॉस',\n",
       " 675: 'क्रॉस्बी',\n",
       " 676: 'क्रोफोर्ड',\n",
       " 677: 'क्रोम',\n",
       " 678: 'क्लांइट',\n",
       " 679: 'क्लाक',\n",
       " 680: 'क्लासों',\n",
       " 681: 'क्लिफ्टन',\n",
       " 682: 'क्ले',\n",
       " 683: 'क्लेन',\n",
       " 684: 'क्लेयर',\n",
       " 685: 'क्लैरिएंट',\n",
       " 686: 'क्लोज़अप',\n",
       " 687: 'क्वॉरेनटाइन',\n",
       " 688: 'क्षत्रियादि',\n",
       " 689: 'क्षीण',\n",
       " 690: 'क्षेत्रद्वारा',\n",
       " 691: 'क्षेत्राें',\n",
       " 692: 'क्षेत्रें',\n",
       " 693: 'खंगाली',\n",
       " 694: 'खंडा',\n",
       " 695: 'खंडेलवाल',\n",
       " 696: 'खंभात',\n",
       " 697: 'खग्यार',\n",
       " 698: 'खटकती',\n",
       " 699: 'खटखटाएगी',\n",
       " 700: 'खटखटाकर',\n",
       " 701: 'खत्री',\n",
       " 702: 'खनिकर्म',\n",
       " 703: 'खनौदा',\n",
       " 704: 'खन्ना',\n",
       " 705: 'खम्मम',\n",
       " 706: 'खरिया',\n",
       " 707: 'खरुवार',\n",
       " 708: 'खरे',\n",
       " 709: 'खलती',\n",
       " 710: 'ख़ासकर',\n",
       " 711: 'ख़ासतौर',\n",
       " 712: 'ख़ैबर',\n",
       " 713: 'खाएँ',\n",
       " 714: 'खाताधारक',\n",
       " 715: 'खातूटोला',\n",
       " 716: 'खातेदार',\n",
       " 717: 'खान',\n",
       " 718: 'खिंचकर',\n",
       " 719: 'खिताबों',\n",
       " 720: 'खिलाना',\n",
       " 721: 'खिसकते',\n",
       " 722: 'खुरपका',\n",
       " 723: 'खुरासान',\n",
       " 724: 'खुल्लमखुल्ला',\n",
       " 725: 'खेड़ा',\n",
       " 726: 'खेमिक',\n",
       " 727: 'खेलमंत्री',\n",
       " 728: 'खेलाने',\n",
       " 729: 'खैराती',\n",
       " 730: 'खोमचे',\n",
       " 731: 'गंगटोक',\n",
       " 732: 'गंगाजल',\n",
       " 733: 'गंझू',\n",
       " 734: 'गंध',\n",
       " 735: 'गए',\n",
       " 736: 'गजरा',\n",
       " 737: 'गड़बड़बड़ी',\n",
       " 738: 'गणपति',\n",
       " 739: 'गणेशा',\n",
       " 740: 'गति',\n",
       " 741: 'गतिशीलता',\n",
       " 742: 'गबली',\n",
       " 743: 'गम्मत',\n",
       " 744: 'गरीबी',\n",
       " 745: 'गरुड़',\n",
       " 746: 'गर्जना',\n",
       " 747: 'गलगंड',\n",
       " 748: 'गलाएगा',\n",
       " 749: 'गल्फ',\n",
       " 750: 'गहलोत',\n",
       " 751: 'ग़रीबों',\n",
       " 752: 'ग़लतफ़हमी',\n",
       " 753: 'ग़ाज़ियाबाद',\n",
       " 754: 'ग़ैरकानूनी',\n",
       " 755: 'गांगनाम',\n",
       " 756: 'गांठ',\n",
       " 757: 'गांठे',\n",
       " 758: 'गांडचुभोनाचूसनाछोटे',\n",
       " 759: 'गांधीपुरा',\n",
       " 760: 'गाएं',\n",
       " 761: 'गाज़ी',\n",
       " 762: 'गाजीपुर',\n",
       " 763: 'गाड़ूँगा',\n",
       " 764: 'गानो',\n",
       " 765: 'गायत्री',\n",
       " 766: 'गायिकाओ',\n",
       " 767: 'गालीगलौज',\n",
       " 768: 'गिड़गिड़ाते',\n",
       " 769: 'गिनते',\n",
       " 770: 'गिरकर',\n",
       " 771: 'गिरजाघरों',\n",
       " 772: 'गिरिडीह',\n",
       " 773: 'गिरिवासियों',\n",
       " 774: 'गुजरात',\n",
       " 775: 'गुजार',\n",
       " 776: 'गुजारता',\n",
       " 777: 'गुजारना',\n",
       " 778: 'गुजारने',\n",
       " 779: 'गुजारा',\n",
       " 780: 'गुडगौंव',\n",
       " 781: 'गुडेपु',\n",
       " 782: 'गुदना',\n",
       " 783: 'गुदुरी',\n",
       " 784: 'गुना',\n",
       " 785: 'गुमशुदगी',\n",
       " 786: 'गुरदासपुर',\n",
       " 787: 'गुरुपदो',\n",
       " 788: 'गुर्जर',\n",
       " 789: 'गुर्दों',\n",
       " 790: 'गुलशन',\n",
       " 791: 'गुलाबाग',\n",
       " 792: 'गुल्लरवाला',\n",
       " 793: 'गृहनगर',\n",
       " 794: 'गेरीसन',\n",
       " 795: 'गेल',\n",
       " 796: 'गेवारा',\n",
       " 797: 'गैरइरादतन',\n",
       " 798: 'गैरराष्ट्रवादी',\n",
       " 799: 'गैलेक्सियों',\n",
       " 800: 'गैस्ट्रोलॉजी',\n",
       " 801: 'गॉंव',\n",
       " 802: 'गोंड',\n",
       " 803: 'गोंद',\n",
       " 804: 'गोंपो',\n",
       " 805: 'गोपालक',\n",
       " 806: 'गोलमुरी',\n",
       " 807: 'गोल्ड',\n",
       " 808: 'गौमुख',\n",
       " 809: 'गौमूत्र',\n",
       " 810: 'गौर',\n",
       " 811: 'ग्योंठ',\n",
       " 812: 'ग्रंथियां',\n",
       " 813: 'ग्रंथियों',\n",
       " 814: 'ग्रविटा',\n",
       " 815: 'ग्रहणकाल',\n",
       " 816: 'ग्राहकोंने',\n",
       " 817: 'ग्राहम',\n",
       " 818: 'ग्रीनविल',\n",
       " 819: 'ग्रीनवुड',\n",
       " 820: 'ग्रीर',\n",
       " 821: 'ग्रीष्मोत्सव',\n",
       " 822: 'ग्रे',\n",
       " 823: 'ग्रेग',\n",
       " 824: 'ग्रेनाइट',\n",
       " 825: 'ग्रोवर',\n",
       " 826: 'ग्लेंडल',\n",
       " 827: 'ग्लैक्सोस्मिथक्लीन',\n",
       " 828: 'घटबढ़',\n",
       " 829: 'घटाएगी',\n",
       " 830: 'घटाटोप',\n",
       " 831: 'घासी',\n",
       " 832: 'घिग्घी',\n",
       " 833: 'घिसे',\n",
       " 834: 'घुमक्कड़ी',\n",
       " 835: 'घुमक्कड़ों',\n",
       " 836: 'घुमाई',\n",
       " 837: 'घुमाण',\n",
       " 838: 'घूंसा',\n",
       " 839: 'घृतकुमारी',\n",
       " 840: 'घोंटना',\n",
       " 841: 'घोट',\n",
       " 842: 'घोटालेबाजों',\n",
       " 843: 'घोस्ट',\n",
       " 844: 'चंदन',\n",
       " 845: 'चंद्रपुर',\n",
       " 846: 'चंद्रबली',\n",
       " 847: 'चंद्रमाओं',\n",
       " 848: 'चंद्रेश्वरनगर',\n",
       " 849: 'चक्कर',\n",
       " 850: 'चक्षु',\n",
       " 851: 'चच्चा',\n",
       " 852: 'चटकाते',\n",
       " 853: 'चटगांव',\n",
       " 854: 'चढ़ने',\n",
       " 855: 'चढ़ें',\n",
       " 856: 'चढ़ेगा',\n",
       " 857: 'चता',\n",
       " 858: 'चतुष्कोणीय',\n",
       " 859: 'चन्द्रदास',\n",
       " 860: 'चबाते',\n",
       " 861: 'चबूतरे',\n",
       " 862: 'चमकना',\n",
       " 863: 'चमच',\n",
       " 864: 'चमचागिरी',\n",
       " 865: 'चम्बा',\n",
       " 866: 'चयनितों',\n",
       " 867: 'चरणबद्घ',\n",
       " 868: 'चरस',\n",
       " 869: 'चरित',\n",
       " 870: 'चर्चा',\n",
       " 871: 'चर्चाएँ',\n",
       " 872: 'चर्चामंच',\n",
       " 873: 'चलेंगे',\n",
       " 874: 'चष्मा',\n",
       " 875: 'चहुंमुखी',\n",
       " 876: 'चाचाजी',\n",
       " 877: 'चादरों',\n",
       " 878: 'चानन',\n",
       " 879: 'चापलूसी',\n",
       " 880: 'चायल',\n",
       " 881: 'चारों',\n",
       " 882: 'चार्ट',\n",
       " 883: 'चालित',\n",
       " 884: 'चिकित्साएवं',\n",
       " 885: 'चिको',\n",
       " 886: 'चिकोपी',\n",
       " 887: 'चिखली',\n",
       " 888: 'चिड़चिड़ापन',\n",
       " 889: 'चिढ़ते',\n",
       " 890: 'चित्रकथा',\n",
       " 891: 'चित्रांशी',\n",
       " 892: 'चिनमणि',\n",
       " 893: 'चिपकने',\n",
       " 894: 'चिमटी',\n",
       " 895: 'चिमाते',\n",
       " 896: 'ची',\n",
       " 897: 'चीखना',\n",
       " 898: 'चुंगियों',\n",
       " 899: 'चुटीले',\n",
       " 900: 'चुनीं',\n",
       " 901: 'चुने',\n",
       " 902: 'चूचियां',\n",
       " 903: 'चूड़े',\n",
       " 904: 'चूरू',\n",
       " 905: 'चेंज्ड',\n",
       " 906: 'चेन्नई',\n",
       " 907: 'चेलानी',\n",
       " 908: 'चेस्ट',\n",
       " 909: 'चैंपियनशिप',\n",
       " 910: 'चैपल',\n",
       " 911: 'चौंकाते',\n",
       " 912: 'चौक',\n",
       " 913: 'चौका',\n",
       " 914: 'चौकियां',\n",
       " 915: 'चौकी',\n",
       " 916: 'चौखटे',\n",
       " 917: 'चौड़ा',\n",
       " 918: 'चौदहवां',\n",
       " 919: 'चौधरी',\n",
       " 920: 'चौरसिया',\n",
       " 921: 'चौसिंगा',\n",
       " 922: 'चौहान',\n",
       " 923: 'छतेनी',\n",
       " 924: 'छरहरी',\n",
       " 925: 'छल्ला',\n",
       " 926: 'छविंद्र',\n",
       " 927: 'छह',\n",
       " 928: 'छहों',\n",
       " 929: 'छांयसा',\n",
       " 930: 'छापेमार',\n",
       " 931: 'छींक',\n",
       " 932: 'छींके',\n",
       " 933: 'छीजत',\n",
       " 934: 'छुड़वाया',\n",
       " 935: 'छुपकर',\n",
       " 936: 'छुपता',\n",
       " 937: 'छुरे',\n",
       " 938: 'छूटने',\n",
       " 939: 'छेड़ना',\n",
       " 940: 'छेत्र',\n",
       " 941: 'छेत्री',\n",
       " 942: 'छेलै',\n",
       " 943: 'छोडिये',\n",
       " 944: 'जंक्शन',\n",
       " 945: 'जकिंटो',\n",
       " 946: 'जगताप',\n",
       " 947: 'जगदलपुर',\n",
       " 948: 'जगदीशचंद्र',\n",
       " 949: 'जगाएगा',\n",
       " 950: 'जगारागल्लू',\n",
       " 951: 'जटिला',\n",
       " 952: 'जड़',\n",
       " 953: 'जड़ित',\n",
       " 954: 'जड़ें',\n",
       " 955: 'जताती',\n",
       " 956: 'जनगणना',\n",
       " 957: 'जनगन',\n",
       " 958: 'जनजागरण',\n",
       " 959: 'जनभावना',\n",
       " 960: 'जनशिक्षा',\n",
       " 961: 'जनहानि',\n",
       " 962: 'जनेऊधारी',\n",
       " 963: 'जबलपुर',\n",
       " 964: 'जबाबी',\n",
       " 965: 'जमलोकी',\n",
       " 966: 'जमशेदपुर',\n",
       " 967: 'जमाती',\n",
       " 968: 'जमाया',\n",
       " 969: 'जयकारा',\n",
       " 970: 'जयपुर',\n",
       " 971: 'जयबाण',\n",
       " 972: 'जयललिता',\n",
       " 973: 'जरख',\n",
       " 974: 'जरूरीः',\n",
       " 975: 'जर्दा',\n",
       " 976: 'जलगति',\n",
       " 977: 'जलपोत',\n",
       " 978: 'जलभराव',\n",
       " 979: 'जलवायु',\n",
       " 980: 'जलसंसाधन',\n",
       " 981: 'जवाबः',\n",
       " 982: 'जस्ट',\n",
       " 983: 'जस्सी',\n",
       " 984: 'ज़बर्दस्त',\n",
       " 985: 'ज़मातें',\n",
       " 986: 'ज़माना',\n",
       " 987: 'ज़यादा',\n",
       " 988: 'ज़लज़ले',\n",
       " 989: 'ज़वाला',\n",
       " 990: 'ज़ाइडस',\n",
       " 991: 'ज़िलाधिकारी',\n",
       " 992: 'ज़ुन्हेबोटो',\n",
       " 993: 'ज़ुबान',\n",
       " 994: 'जांचकर्ता',\n",
       " 995: 'जांचना',\n",
       " 996: 'जागृति',\n",
       " 997: 'जाजमऊ',\n",
       " 998: 'जातक',\n",
       " 999: 'जातकों',\n",
       " ...}"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# hin_int2word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "de7e7cf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Batch 0, Loss: 8.1529\n",
      "Epoch 1, Batch 0, Loss: 4.0655\n",
      "Epoch 2, Batch 0, Loss: 4.0559\n",
      "Epoch 3, Batch 0, Loss: 4.0297\n",
      "Epoch 4, Batch 0, Loss: 4.0109\n",
      "Epoch 5, Batch 0, Loss: 3.9487\n",
      "Epoch 6, Batch 0, Loss: 3.8222\n",
      "Epoch 7, Batch 0, Loss: 3.5956\n",
      "Epoch 8, Batch 0, Loss: 3.4109\n",
      "Epoch 9, Batch 0, Loss: 3.0385\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import random\n",
    "DEVICE=device\n",
    "\n",
    "# Loss Function (exclude padding)\n",
    "loss_fn = nn.CrossEntropyLoss(ignore_index=eng_word2int[PAD_TOKEN])\n",
    "\n",
    "# Optimizers\n",
    "encoder_optimizer = optim.AdamW(encoder.parameters())\n",
    "decoder_optimizer = optim.AdamW(decoder.parameters())\n",
    "\n",
    "# Number of epochs\n",
    "num_epochs = 10\n",
    "\n",
    "# Training Loop\n",
    "encoder.train()\n",
    "decoder.train()\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (input_tensor, target_tensor) in enumerate(translation_dataloader):\n",
    "        input_tensor, target_tensor = input_tensor.to(DEVICE), target_tensor.to(DEVICE)\n",
    "\n",
    "        # Zero gradients of both optimizers\n",
    "        encoder_optimizer.zero_grad()\n",
    "        decoder_optimizer.zero_grad()\n",
    "\n",
    "        target_length = target_tensor.size(1)\n",
    "\n",
    "        # Encoder\n",
    "        _, encoder_hidden, encoder_cell = encoder(input_tensor)\n",
    "\n",
    "        # Decoder\n",
    "        decoder_input = torch.full((batch_size, 1), eng_word2int[SOS_TOKEN], dtype=torch.long).to(DEVICE)\n",
    "        # tensor.size(1) --> no of column\n",
    "        decoder_hidden = encoder_hidden\n",
    "        decoder_cell = encoder_cell\n",
    "\n",
    "        # Randomly select a word index from the target sequence\n",
    "        random_word_index = random.randint(0, target_length - 1) ## why this is being done? okay.\n",
    "\n",
    "        loss = 0\n",
    "\n",
    "        for di in range(target_length):\n",
    "            logits, decoder_hidden, decoder_cell  = decoder(decoder_input, decoder_hidden, decoder_cell)\n",
    "            #if di == random_word_index:\n",
    "            #    loss = loss_fn(logits, target_tensor[:, di])\n",
    "            #    break  # Only compute loss for the randomly selected word\n",
    "            loss += loss_fn(logits, target_tensor[:,di])\n",
    "            decoder_input = target_tensor[:, di].reshape(batch_size, 1)  # Teacher forcing\n",
    "\n",
    "\n",
    "        # Backpropagation\n",
    "        loss.backward()\n",
    "\n",
    "        encoder_optimizer.step()\n",
    "        decoder_optimizer.step()\n",
    "\n",
    "        if i % 100 == 0:  # Print loss every 10 batches\n",
    "            print(f'Epoch {epoch}, Batch {i}, Loss: {loss.item() / target_length:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "80e347f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# import torch.nn as nn\n",
    "# import torch.optim as optim\n",
    "# import torch.nn.functional as F\n",
    "\n",
    "# class Encoder(nn.Module):\n",
    "#     def __init__(self, vocab_size, embed_size, hidden_size, num_layers=1):\n",
    "#         super().__init__()\n",
    "#         self.hidden_size = hidden_size\n",
    "#         self.embedding = nn.Embedding(vocab_size, embed_size)\n",
    "#         self.lstm = nn.LSTM(embed_size, hidden_size, num_layers=num_layers,\n",
    "#                             batch_first=True, bidirectional=True)\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         embedded = self.embedding(x)\n",
    "#         outputs, (hidden, cell) = self.lstm(embedded)\n",
    "\n",
    "#         # concatenate hidden states of the bi-directional RNN layer\n",
    "#         hidden = torch.cat((hidden[0,:,:], hidden[1,:,:]), dim=1).unsqueeze(0)\n",
    "#         cell = torch.cat((cell[0,:,:], cell[1,:,:]), dim=1).unsqueeze(0)\n",
    "\n",
    "#         return outputs, hidden, cell\n",
    "\n",
    "# class Decoder(nn.Module):\n",
    "#     def __init__(self, vocab_size, embed_size, hidden_size, num_layers=1):\n",
    "#         super().__init__()\n",
    "#         self.hidden_size = hidden_size\n",
    "#         self.embedding = nn.Embedding(vocab_size, embed_size)\n",
    "#         self.lstm = nn.LSTM(embed_size, hidden_size, num_layers=num_layers, batch_first=True)\n",
    "#         self.fc = nn.Linear(hidden_size, vocab_size)\n",
    "\n",
    "#     def forward(self, x, hidden, cell):\n",
    "#         out = self.embedding(x)\n",
    "#         out, (hidden, cell) = self.lstm(out, (hidden, cell))\n",
    "#         out = self.fc(out).reshape(out.size(0), -1)\n",
    "#         return out, hidden, cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "4ee5f9db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Hyperparameters\n",
    "# eng_vocab_size = len(eng_word2int)\n",
    "# ita_vocab_size = len(hin_word2int)\n",
    "# embed_size = 256\n",
    "# hidden_size = 512\n",
    "# num_layers = 1\n",
    "\n",
    "# # Initialize the models\n",
    "# encoder = Encoder(eng_vocab_size, embed_size, hidden_size, num_layers).to(DEVICE)\n",
    "# decoder = Decoder(hin_vocab_size, embed_size, hidden_size*2, num_layers).to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9da24408",
   "metadata": {},
   "outputs": [],
   "source": [
    "############ RNN based encode decoder ###########"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46c7bb28",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9b98049",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01e09b3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "############ GRU based encoder decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "a594973a",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (1080490500.py, line 23)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn [121], line 23\u001b[1;36m\u001b[0m\n\u001b[1;33m    self.gru = nn.GRU(embd_dim, , num_layers=num_layers,\u001b[0m\n\u001b[1;37m                                ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "class encoder_GRU(nn.Module):\n",
    "    def __init__(self, vocab_size, hidden_size,embd_dim,num_layer=1):\n",
    "        super(encoder_GRU, self).__init__()\n",
    "#         self.hidden_size=hidden_size\n",
    "        self.embd=nn.Embedding(vocab_size,embd_dim)\n",
    "        self.gru = nn.GRU(embd_dim, hidden_size)\n",
    "#         self.fc = nn.Linear(hidden_size, output_size)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x=self.embd(x) # batch_size, embd_size\n",
    "        out, hidden = self.gru(x)\n",
    "        print(f\"hidden state shape of gru is {hidden.shape}\")\n",
    "        print(f\"output of gru is {out.shape}\")\n",
    "#         out = self.fc(out[-1])\n",
    "        return out,hidden\n",
    "\n",
    "\n",
    "# Define the GRU-based model\n",
    "class decoder_GRU(nn.Module):\n",
    "    def __init__(self, vocab_size, hidden_size, embd_dim, num_layer=1):\n",
    "        super(decoder_GRU, self).__init__()\n",
    "        self.embd=nn.Embedding(vocab_size,embd_dim)\n",
    "        self.gru = nn.GRU(embd_dim, , num_layers=num_layers,\n",
    "                            batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "    \n",
    "    def forward(self, x, hidden):\n",
    "        x=self.embd(x)\n",
    "        out, hidden = self.gru(x,hidden)\n",
    "        print(f\"hidden state shape of gru is {hidden.shape}\")\n",
    "        print(f\"output of gru is {out.shape}\")\n",
    "        out = self.fc(out).reshape(out.size(0), -1)#??\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "31f17d7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "embed_size = 256\n",
    "hidden_size = 512\n",
    "num_layers = 1\n",
    "# Initialize the models\n",
    "encoder_gru_test = encoder_GRU(eng_vocab_size, embed_size, hidden_size, num_layers).to(device)\n",
    "decoder_gru_test = decoder_GRU(hin_vocab_size, embed_size, hidden_size, num_layers).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "28831326",
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate_gru(encoder, decoder, sentence, eng_word2int, ita_int2word, max_length=15):\n",
    "    encoder.eval()\n",
    "    decoder.eval()\n",
    "    with torch.inference_mode():\n",
    "        # Tokenize and encode the sentence\n",
    "        input_tensor = torch.tensor([eng_word2int[word] for word in tokenize(sentence)]\n",
    "                                    + [eng_word2int[EOS_TOKEN]], dtype=torch.long)\n",
    "        print(f\"shape of input tensor is {input_tensor.shape}\")\n",
    "        input_tensor = input_tensor.view(1, -1).to(DEVICE)  # batch_first=True\n",
    "\n",
    "        # Pass the input through the encoder\n",
    "        _, encoder_hidden = encoder(input_tensor)\n",
    "        print(f\"encoder hidden shape {encoder_hidden.shape}\")\n",
    "        # encoder output\n",
    "\n",
    "        # Initialize the decoder input with the SOS token\n",
    "        decoder_input = torch.tensor([[eng_word2int[SOS_TOKEN]]], dtype=torch.long)  # SOS\n",
    "        print(f\"decoder input first {decoder_input}\")\n",
    "        # Initialize the hidden state of the decoder with the encoder's hidden state\n",
    "        decoder_hidden = encoder_hidden\n",
    "\n",
    "        # Decoding the sentence\n",
    "        decoded_words = []\n",
    "        last_word = torch.tensor([[eng_word2int[SOS_TOKEN]]]).to(DEVICE)\n",
    "        print(f\"last word {last_word}\")\n",
    "        for di in range(max_length):\n",
    "            logits, decoder_hidden = decoder(last_word, decoder_hidden)\n",
    "            print(f\"logits shape is (should be equal to hidni vocab 3373ish) {logits.shape}\")\n",
    "            next_token = logits.argmax(dim=1) # greedy #\n",
    "            print(f\"next token index is (expecting it to be scalar) {next_token}\")\n",
    "            last_word = torch.tensor([[next_token]]).to(DEVICE)\n",
    "            if next_token.item() == hin_word2int[EOS_TOKEN]:\n",
    "                break\n",
    "            else:\n",
    "                decoded_words.append(ita_int2word.get(next_token.item()))\n",
    "\n",
    "        return ' '.join(decoded_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "8ad11e17",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of input tensor is torch.Size([3])\n",
      "hidden state shape of gru is torch.Size([1, 3, 256])\n",
      "output of gru is torch.Size([1, 3, 256])\n",
      "encoder hidden shape torch.Size([1, 3, 256])\n",
      "decoder input first tensor([[1]])\n",
      "last word tensor([[1]])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Expected hidden size (1, 1, 256), got [1, 3, 256]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [123], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m eng_example \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlearn independence\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m----> 2\u001b[0m \u001b[43mtranslate_gru\u001b[49m\u001b[43m(\u001b[49m\u001b[43mencoder_gru_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43mdecoder_gru_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43meng_example\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meng_word2int\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhin_int2word\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn [122], line 27\u001b[0m, in \u001b[0;36mtranslate_gru\u001b[1;34m(encoder, decoder, sentence, eng_word2int, ita_int2word, max_length)\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlast word \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlast_word\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m di \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(max_length):\n\u001b[1;32m---> 27\u001b[0m     logits, decoder_hidden \u001b[38;5;241m=\u001b[39m \u001b[43mdecoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlast_word\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdecoder_hidden\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     28\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlogits shape is (should be equal to hidni vocab 3373ish) \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlogits\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     29\u001b[0m     next_token \u001b[38;5;241m=\u001b[39m logits\u001b[38;5;241m.\u001b[39margmax(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m) \u001b[38;5;66;03m# greedy #\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "Cell \u001b[1;32mIn [113], line 28\u001b[0m, in \u001b[0;36mdecoder_GRU.forward\u001b[1;34m(self, x, hidden)\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, hidden):\n\u001b[0;32m     27\u001b[0m     x\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membd(x)\n\u001b[1;32m---> 28\u001b[0m     out, hidden \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgru\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43mhidden\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     29\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhidden state shape of gru is \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhidden\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     30\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput of gru is \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mout\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:1391\u001b[0m, in \u001b[0;36mGRU.forward\u001b[1;34m(self, input, hx)\u001b[0m\n\u001b[0;32m   1386\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1387\u001b[0m         \u001b[38;5;66;03m# Each batch of the hidden state should match the input sequence that\u001b[39;00m\n\u001b[0;32m   1388\u001b[0m         \u001b[38;5;66;03m# the user believes he/she is passing in.\u001b[39;00m\n\u001b[0;32m   1389\u001b[0m         hx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpermute_hidden(hx, sorted_indices)\n\u001b[1;32m-> 1391\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheck_forward_args\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_sizes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1392\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m batch_sizes \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1393\u001b[0m     result \u001b[38;5;241m=\u001b[39m _VF\u001b[38;5;241m.\u001b[39mgru(\n\u001b[0;32m   1394\u001b[0m         \u001b[38;5;28minput\u001b[39m,\n\u001b[0;32m   1395\u001b[0m         hx,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1402\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_first,\n\u001b[0;32m   1403\u001b[0m     )\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:366\u001b[0m, in \u001b[0;36mRNNBase.check_forward_args\u001b[1;34m(self, input, hidden, batch_sizes)\u001b[0m\n\u001b[0;32m    363\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheck_input(\u001b[38;5;28minput\u001b[39m, batch_sizes)\n\u001b[0;32m    364\u001b[0m expected_hidden_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_expected_hidden_size(\u001b[38;5;28minput\u001b[39m, batch_sizes)\n\u001b[1;32m--> 366\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheck_hidden_size\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexpected_hidden_size\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:347\u001b[0m, in \u001b[0;36mRNNBase.check_hidden_size\u001b[1;34m(self, hx, expected_hidden_size, msg)\u001b[0m\n\u001b[0;32m    340\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcheck_hidden_size\u001b[39m(\n\u001b[0;32m    341\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    342\u001b[0m     hx: Tensor,\n\u001b[0;32m    343\u001b[0m     expected_hidden_size: Tuple[\u001b[38;5;28mint\u001b[39m, \u001b[38;5;28mint\u001b[39m, \u001b[38;5;28mint\u001b[39m],\n\u001b[0;32m    344\u001b[0m     msg: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected hidden size \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m, got \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    345\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    346\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m hx\u001b[38;5;241m.\u001b[39msize() \u001b[38;5;241m!=\u001b[39m expected_hidden_size:\n\u001b[1;32m--> 347\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(msg\u001b[38;5;241m.\u001b[39mformat(expected_hidden_size, \u001b[38;5;28mlist\u001b[39m(hx\u001b[38;5;241m.\u001b[39msize())))\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Expected hidden size (1, 1, 256), got [1, 3, 256]"
     ]
    }
   ],
   "source": [
    "eng_example = \"learn independence\"\n",
    "translate_gru(encoder_gru_test,decoder_gru_test,eng_example, eng_word2int, hin_int2word)\n",
    "# eng_word2int, eng_int2word = create_mappings(english_vocab)\n",
    "# hin_word2int, hin_int2word = create_mappings(hindi_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62707648",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ac0b603",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "d2d711e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class encoder_RNN(nn.Module):\n",
    "    def __init__(self, vocab_size, hidden_size, output_size,embd_dim):\n",
    "        super(encoder_RNN, self).__init__()\n",
    "#         self.hidden_size=hidden_size\n",
    "        self.embd=nn.Embedding(vocab_size,embd_dim)\n",
    "        self.rnn = nn.RNN(embd_dim, hidden_size)\n",
    "#         self.fc = nn.Linear(hidden_size, output_size)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x=self.embd(x) # batch_size, embd_size\n",
    "        out, hidden = self.rnn(x)\n",
    "        print(f\"hidden state shape of rnn is {hidden.shape}\")\n",
    "        print(f\"output of rnn is {out.shape}\")\n",
    "#         out = self.fc(out[-1])\n",
    "        return out,hidden\n",
    "\n",
    "\n",
    "# Define the RNN-based model\n",
    "class decoder_RNN(nn.Module):\n",
    "    def __init__(self, vocab_size, hidden_size, output_size,embd_dim):\n",
    "        super(decoder_RNN, self).__init__()\n",
    "        self.embd=nn.Embedding(vocab_size,embd_dim)\n",
    "        self.rnn = nn.RNN(input_size, hidden_size)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "    \n",
    "    def forward(self, x,hidden):\n",
    "        x=self.embd(x)\n",
    "        out, hidden = self.rnn(x,hidden)\n",
    "        print(f\"hidden state shape of RNN is {hidden.shape}\")\n",
    "        print(f\"output of RNN is {out.shape}\")\n",
    "        out = self.fc(out).reshape(out.size(0), -1)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "374a0a60",
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_size = 256\n",
    "hidden_size = 512\n",
    "num_layers = 1\n",
    "# Initialize the models\n",
    "encoder_rnn_test = encoder_RNN(eng_vocab_size, embed_size, hidden_size, num_layers).to(device)\n",
    "decoder_rnn_test = decoder_RNN(hin_vocab_size, embed_size, hidden_size, num_layers).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "a6beb6a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate_rnn(encoder, decoder, sentence, eng_word2int, ita_int2word, max_length=15):\n",
    "    encoder.eval()\n",
    "    decoder.eval()\n",
    "    with torch.inference_mode():\n",
    "        # Tokenize and encode the sentence\n",
    "        input_tensor = torch.tensor([eng_word2int[word] for word in tokenize(sentence)]\n",
    "                                    + [eng_word2int[EOS_TOKEN]], dtype=torch.long)\n",
    "        print(f\"shape of input tensor is {input_tensor.shape}\")\n",
    "        input_tensor = input_tensor.view(1, -1).to(DEVICE)  # batch_first=True\n",
    "\n",
    "        # Pass the input through the encoder\n",
    "        _, encoder_hidden = encoder(input_tensor)\n",
    "        print(f\"encoder hidden shape {encoder_hidden.shape}\")\n",
    "        # encoder output\n",
    "\n",
    "        # Initialize the decoder input with the SOS token\n",
    "        decoder_input = torch.tensor([[eng_word2int[SOS_TOKEN]]], dtype=torch.long)  # SOS\n",
    "        print(f\"decoder input first {decoder_input}\")\n",
    "        # Initialize the hidden state of the decoder with the encoder's hidden state\n",
    "        decoder_hidden = encoder_hidden\n",
    "\n",
    "        # Decoding the sentence\n",
    "        decoded_words = []\n",
    "        last_word = torch.tensor([[eng_word2int[SOS_TOKEN]]]).to(DEVICE)\n",
    "        print(f\"last word {last_word}\")\n",
    "        for di in range(max_length):\n",
    "            logits, decoder_hidden = decoder(last_word, decoder_hidden)\n",
    "            print(f\"logits shape is (should be equal to hidni vocab 3373ish) {logits.shape}\")\n",
    "            next_token = logits.argmax(dim=1) # greedy #\n",
    "            print(f\"next token index is (expecting it to be scalar) {next_token}\")\n",
    "            last_word = torch.tensor([[next_token]]).to(DEVICE)\n",
    "            if next_token.item() == hin_word2int[EOS_TOKEN]:\n",
    "                break\n",
    "            else:\n",
    "                decoded_words.append(ita_int2word.get(next_token.item()))\n",
    "\n",
    "        return ' '.join(decoded_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "f82e6cda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of input tensor is torch.Size([3])\n",
      "hidden state shape of rnn is torch.Size([1, 3, 256])\n",
      "output of rnn is torch.Size([1, 3, 256])\n",
      "encoder hidden shape torch.Size([1, 3, 256])\n",
      "decoder input first tensor([[1]])\n",
      "last word tensor([[1]])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Expected hidden size (1, 1, 256), got [1, 3, 256]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [127], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m eng_example \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlearn independence\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m----> 2\u001b[0m \u001b[43mtranslate_rnn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mencoder_rnn_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43mdecoder_rnn_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43meng_example\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meng_word2int\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhin_int2word\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn [126], line 27\u001b[0m, in \u001b[0;36mtranslate_rnn\u001b[1;34m(encoder, decoder, sentence, eng_word2int, ita_int2word, max_length)\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlast word \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlast_word\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m di \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(max_length):\n\u001b[1;32m---> 27\u001b[0m     logits, decoder_hidden \u001b[38;5;241m=\u001b[39m \u001b[43mdecoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlast_word\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdecoder_hidden\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     28\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlogits shape is (should be equal to hidni vocab 3373ish) \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlogits\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     29\u001b[0m     next_token \u001b[38;5;241m=\u001b[39m logits\u001b[38;5;241m.\u001b[39margmax(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m) \u001b[38;5;66;03m# greedy #\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "Cell \u001b[1;32mIn [124], line 28\u001b[0m, in \u001b[0;36mdecoder_RNN.forward\u001b[1;34m(self, x, hidden)\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x,hidden):\n\u001b[0;32m     27\u001b[0m     x\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membd(x)\n\u001b[1;32m---> 28\u001b[0m     out, hidden \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrnn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43mhidden\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     29\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhidden state shape of RNN is \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhidden\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     30\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput of RNN is \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mout\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:712\u001b[0m, in \u001b[0;36mRNN.forward\u001b[1;34m(self, input, hx)\u001b[0m\n\u001b[0;32m    709\u001b[0m         hx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpermute_hidden(hx, sorted_indices)\n\u001b[0;32m    711\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m hx \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m--> 712\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheck_forward_args\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_sizes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    713\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRNN_TANH\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRNN_RELU\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    714\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m batch_sizes \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:366\u001b[0m, in \u001b[0;36mRNNBase.check_forward_args\u001b[1;34m(self, input, hidden, batch_sizes)\u001b[0m\n\u001b[0;32m    363\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheck_input(\u001b[38;5;28minput\u001b[39m, batch_sizes)\n\u001b[0;32m    364\u001b[0m expected_hidden_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_expected_hidden_size(\u001b[38;5;28minput\u001b[39m, batch_sizes)\n\u001b[1;32m--> 366\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheck_hidden_size\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexpected_hidden_size\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:347\u001b[0m, in \u001b[0;36mRNNBase.check_hidden_size\u001b[1;34m(self, hx, expected_hidden_size, msg)\u001b[0m\n\u001b[0;32m    340\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcheck_hidden_size\u001b[39m(\n\u001b[0;32m    341\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    342\u001b[0m     hx: Tensor,\n\u001b[0;32m    343\u001b[0m     expected_hidden_size: Tuple[\u001b[38;5;28mint\u001b[39m, \u001b[38;5;28mint\u001b[39m, \u001b[38;5;28mint\u001b[39m],\n\u001b[0;32m    344\u001b[0m     msg: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected hidden size \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m, got \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    345\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    346\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m hx\u001b[38;5;241m.\u001b[39msize() \u001b[38;5;241m!=\u001b[39m expected_hidden_size:\n\u001b[1;32m--> 347\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(msg\u001b[38;5;241m.\u001b[39mformat(expected_hidden_size, \u001b[38;5;28mlist\u001b[39m(hx\u001b[38;5;241m.\u001b[39msize())))\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Expected hidden size (1, 1, 256), got [1, 3, 256]"
     ]
    }
   ],
   "source": [
    "eng_example = \"learn independence\"\n",
    "translate_rnn(encoder_rnn_test,decoder_rnn_test,eng_example, eng_word2int, hin_int2word)\n",
    "# eng_word2int, eng_int2word = create_mappings(english_vocab)\n",
    "# hin_word2int, hin_int2word = create_mappings(hindi_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3687db46",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
