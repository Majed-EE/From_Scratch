{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f02a06d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e7146913",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "device= \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "571f1bee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# i) learn how to model sequence-to-sequence learning problems using Recurrent Neural Networks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "48df5c9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ii) compare different cells such as vanilla RNN, LSTM and GRU.\n",
    "\n",
    "# The goal of this assignment is fourfold: \n",
    "# (i) learn how to model sequence to sequence learning problems using Recurrent Neural Networks\n",
    "# (ii) compare different cells such as vanilla RNN, LSTM and GRU\n",
    "# (iii) understand how attention networks overcome the limitations of vanilla seq2seq models\n",
    "# (iv) visualise the interactions between different components in a RNN based model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2d7f482e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1000, 50]) torch.Size([1000, 50])\n"
     ]
    }
   ],
   "source": [
    "# Generate sine wave data\n",
    "def generate_data(seq_length, num_samples):\n",
    "    X = []\n",
    "    y = []\n",
    "    for i in range(num_samples):\n",
    "        x = np.linspace(i * 2 * np.pi, (i + 1) * 2 * np.pi, seq_length + 1)\n",
    "#         print(x.shape)\n",
    "        sine_wave = np.sin(x)\n",
    "        X.append(sine_wave[:-1])  # input sequence\n",
    "        y.append(sine_wave[1:])   # target sequence\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "seq_length = 50\n",
    "num_samples = 1000 # is this the batch size?\n",
    "X, y = generate_data(seq_length, num_samples)\n",
    "\n",
    "# Convert to PyTorch tensors\n",
    "X = torch.tensor(X, dtype=torch.float32)\n",
    "y = torch.tensor(y, dtype=torch.float32)\n",
    "\n",
    "print(X.shape, y.shape)  # Output: (1000, 50), (1000, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "79582ac1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.0000, 0.1253, 0.2487, 0.3681, 0.4818, 0.5878, 0.6845, 0.7705, 0.8443,\n",
      "        0.9048])\n",
      "tensor([0.1253, 0.2487, 0.3681, 0.4818, 0.5878, 0.6845, 0.7705, 0.8443, 0.9048,\n",
      "        0.9511])\n"
     ]
    }
   ],
   "source": [
    "x_rnn=X.clone()\n",
    "y_rnn=y.clone()\n",
    "print(X[0,:10])\n",
    "\n",
    "print(y[0,:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cb6bcefb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([50])\n",
      "torch.Size([1000, 50])\n"
     ]
    }
   ],
   "source": [
    "print(X[0].shape)\n",
    "print(X.unsqueeze(2).squeeze(2).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cdc0093a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x2c348e83670>]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot results\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(X[0].numpy(), label='True')\n",
    "plt.plot(y[0].numpy(), label='True')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "01263750",
   "metadata": {},
   "outputs": [],
   "source": [
    "# vanella flavour\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "\n",
    "    \n",
    "# Define model hyperparameters\n",
    "\n",
    "# vocab_size = 50    # Size of the character vocabulary\n",
    "# embedding_dim = 64 # Dimension of character embeddings\n",
    "hidden_dim = 128   # Dimension of RNN hidden state\n",
    "output_dim = 1    # Dimension of the output\n",
    "input_size=1 # number of expected features in x\n",
    "\n",
    "class SimpleRNN(nn.Module):\n",
    "    def __init__(self,input_size, hidden_dim, output_dim):\n",
    "        super(SimpleRNN,self).__init__()\n",
    "#         self.embedding=nn.Embedding(vocab_size,embedding_dim)\n",
    "        self.rnn=nn.RNN(input_size, hidden_size=hidden_dim)\n",
    "        self.fc=nn.Linear(hidden_dim,output_dim)\n",
    "        \n",
    "     \n",
    "    def forward(self,x):\n",
    "        encoder_output, hidden_state=self.rnn(x)\n",
    "        print(\"hidden state is \")\n",
    "        print(hidden_state.shape)\n",
    "        print(\"encoder output\")\n",
    "        print(encoder_output.shape)\n",
    "        output=self.fc(encoder_output)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fa84e6f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SimpleRNN(\n",
      "  (rnn): RNN(1, 128)\n",
      "  (fc): Linear(in_features=128, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model = SimpleRNN(input_size, hidden_dim, output_dim)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "96b560c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([50, 1000, 128])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # X= 1000,50\n",
    "# j=torch.randn(2,3)\n",
    "# print(j)\n",
    "# j[-1]\n",
    "temp=torch.randn(1000,128)\n",
    "out=[]\n",
    "for x in range(50):\n",
    "    out.append(temp)\n",
    "# print(len)\n",
    "out=torch.stack(out)\n",
    "out.transpose(0,1)\n",
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "458fc8bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hidden state is \n",
      "torch.Size([1, 50, 128])\n",
      "encoder output\n",
      "torch.Size([1000, 50, 128])\n",
      "prediction (after passing through linear layer) shape is \n",
      "torch.Size([1000, 50, 1])\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    predictions = model(X.unsqueeze(2)) # x 1000,50,1--> input size, hidden size, output size\n",
    "    # why are we adding dimensions- Understood- this has only one input feature\n",
    "    print(\"prediction (after passing through linear layer) shape is \")\n",
    "    print(predictions.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2195015d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hidden state is \n",
      "torch.Size([1, 50, 128])\n",
      "encoder output\n",
      "torch.Size([1000, 50, 128])\n",
      "hidden state is \n",
      "torch.Size([1, 50, 128])\n",
      "encoder output\n",
      "torch.Size([1000, 50, 128])\n",
      "hidden state is \n",
      "torch.Size([1, 50, 128])\n",
      "encoder output\n",
      "torch.Size([1000, 50, 128])\n",
      "hidden state is \n",
      "torch.Size([1, 50, 128])\n",
      "encoder output\n",
      "torch.Size([1000, 50, 128])\n",
      "hidden state is \n",
      "torch.Size([1, 50, 128])\n",
      "encoder output\n",
      "torch.Size([1000, 50, 128])\n",
      "hidden state is \n",
      "torch.Size([1, 50, 128])\n",
      "encoder output\n",
      "torch.Size([1000, 50, 128])\n",
      "hidden state is \n",
      "torch.Size([1, 50, 128])\n",
      "encoder output\n",
      "torch.Size([1000, 50, 128])\n",
      "hidden state is \n",
      "torch.Size([1, 50, 128])\n",
      "encoder output\n",
      "torch.Size([1000, 50, 128])\n",
      "hidden state is \n",
      "torch.Size([1, 50, 128])\n",
      "encoder output\n",
      "torch.Size([1000, 50, 128])\n",
      "hidden state is \n",
      "torch.Size([1, 50, 128])\n",
      "encoder output\n",
      "torch.Size([1000, 50, 128])\n",
      "Epoch [10/100], Loss: 0.1644\n",
      "hidden state is \n",
      "torch.Size([1, 50, 128])\n",
      "encoder output\n",
      "torch.Size([1000, 50, 128])\n",
      "hidden state is \n",
      "torch.Size([1, 50, 128])\n",
      "encoder output\n",
      "torch.Size([1000, 50, 128])\n",
      "hidden state is \n",
      "torch.Size([1, 50, 128])\n",
      "encoder output\n",
      "torch.Size([1000, 50, 128])\n",
      "hidden state is \n",
      "torch.Size([1, 50, 128])\n",
      "encoder output\n",
      "torch.Size([1000, 50, 128])\n",
      "hidden state is \n",
      "torch.Size([1, 50, 128])\n",
      "encoder output\n",
      "torch.Size([1000, 50, 128])\n",
      "hidden state is \n",
      "torch.Size([1, 50, 128])\n",
      "encoder output\n",
      "torch.Size([1000, 50, 128])\n",
      "hidden state is \n",
      "torch.Size([1, 50, 128])\n",
      "encoder output\n",
      "torch.Size([1000, 50, 128])\n",
      "hidden state is \n",
      "torch.Size([1, 50, 128])\n",
      "encoder output\n",
      "torch.Size([1000, 50, 128])\n",
      "hidden state is \n",
      "torch.Size([1, 50, 128])\n",
      "encoder output\n",
      "torch.Size([1000, 50, 128])\n",
      "hidden state is \n",
      "torch.Size([1, 50, 128])\n",
      "encoder output\n",
      "torch.Size([1000, 50, 128])\n",
      "Epoch [20/100], Loss: 0.0293\n",
      "hidden state is \n",
      "torch.Size([1, 50, 128])\n",
      "encoder output\n",
      "torch.Size([1000, 50, 128])\n",
      "hidden state is \n",
      "torch.Size([1, 50, 128])\n",
      "encoder output\n",
      "torch.Size([1000, 50, 128])\n",
      "hidden state is \n",
      "torch.Size([1, 50, 128])\n",
      "encoder output\n",
      "torch.Size([1000, 50, 128])\n",
      "hidden state is \n",
      "torch.Size([1, 50, 128])\n",
      "encoder output\n",
      "torch.Size([1000, 50, 128])\n",
      "hidden state is \n",
      "torch.Size([1, 50, 128])\n",
      "encoder output\n",
      "torch.Size([1000, 50, 128])\n",
      "hidden state is \n",
      "torch.Size([1, 50, 128])\n",
      "encoder output\n",
      "torch.Size([1000, 50, 128])\n",
      "hidden state is \n",
      "torch.Size([1, 50, 128])\n",
      "encoder output\n",
      "torch.Size([1000, 50, 128])\n",
      "hidden state is \n",
      "torch.Size([1, 50, 128])\n",
      "encoder output\n",
      "torch.Size([1000, 50, 128])\n",
      "hidden state is \n",
      "torch.Size([1, 50, 128])\n",
      "encoder output\n",
      "torch.Size([1000, 50, 128])\n",
      "hidden state is \n",
      "torch.Size([1, 50, 128])\n",
      "encoder output\n",
      "torch.Size([1000, 50, 128])\n",
      "Epoch [30/100], Loss: 0.0124\n",
      "hidden state is \n",
      "torch.Size([1, 50, 128])\n",
      "encoder output\n",
      "torch.Size([1000, 50, 128])\n",
      "hidden state is \n",
      "torch.Size([1, 50, 128])\n",
      "encoder output\n",
      "torch.Size([1000, 50, 128])\n",
      "hidden state is \n",
      "torch.Size([1, 50, 128])\n",
      "encoder output\n",
      "torch.Size([1000, 50, 128])\n",
      "hidden state is \n",
      "torch.Size([1, 50, 128])\n",
      "encoder output\n",
      "torch.Size([1000, 50, 128])\n",
      "hidden state is \n",
      "torch.Size([1, 50, 128])\n",
      "encoder output\n",
      "torch.Size([1000, 50, 128])\n",
      "hidden state is \n",
      "torch.Size([1, 50, 128])\n",
      "encoder output\n",
      "torch.Size([1000, 50, 128])\n",
      "hidden state is \n",
      "torch.Size([1, 50, 128])\n",
      "encoder output\n",
      "torch.Size([1000, 50, 128])\n",
      "hidden state is \n",
      "torch.Size([1, 50, 128])\n",
      "encoder output\n",
      "torch.Size([1000, 50, 128])\n",
      "hidden state is \n",
      "torch.Size([1, 50, 128])\n",
      "encoder output\n",
      "torch.Size([1000, 50, 128])\n",
      "hidden state is \n",
      "torch.Size([1, 50, 128])\n",
      "encoder output\n",
      "torch.Size([1000, 50, 128])\n",
      "Epoch [40/100], Loss: 0.0122\n",
      "hidden state is \n",
      "torch.Size([1, 50, 128])\n",
      "encoder output\n",
      "torch.Size([1000, 50, 128])\n",
      "hidden state is \n",
      "torch.Size([1, 50, 128])\n",
      "encoder output\n",
      "torch.Size([1000, 50, 128])\n",
      "hidden state is \n",
      "torch.Size([1, 50, 128])\n",
      "encoder output\n",
      "torch.Size([1000, 50, 128])\n",
      "hidden state is \n",
      "torch.Size([1, 50, 128])\n",
      "encoder output\n",
      "torch.Size([1000, 50, 128])\n",
      "hidden state is \n",
      "torch.Size([1, 50, 128])\n",
      "encoder output\n",
      "torch.Size([1000, 50, 128])\n",
      "hidden state is \n",
      "torch.Size([1, 50, 128])\n",
      "encoder output\n",
      "torch.Size([1000, 50, 128])\n",
      "hidden state is \n",
      "torch.Size([1, 50, 128])\n",
      "encoder output\n",
      "torch.Size([1000, 50, 128])\n",
      "hidden state is \n",
      "torch.Size([1, 50, 128])\n",
      "encoder output\n",
      "torch.Size([1000, 50, 128])\n",
      "hidden state is \n",
      "torch.Size([1, 50, 128])\n",
      "encoder output\n",
      "torch.Size([1000, 50, 128])\n",
      "hidden state is \n",
      "torch.Size([1, 50, 128])\n",
      "encoder output\n",
      "torch.Size([1000, 50, 128])\n",
      "Epoch [50/100], Loss: 0.0104\n",
      "hidden state is \n",
      "torch.Size([1, 50, 128])\n",
      "encoder output\n",
      "torch.Size([1000, 50, 128])\n",
      "hidden state is \n",
      "torch.Size([1, 50, 128])\n",
      "encoder output\n",
      "torch.Size([1000, 50, 128])\n",
      "hidden state is \n",
      "torch.Size([1, 50, 128])\n",
      "encoder output\n",
      "torch.Size([1000, 50, 128])\n",
      "hidden state is \n",
      "torch.Size([1, 50, 128])\n",
      "encoder output\n",
      "torch.Size([1000, 50, 128])\n",
      "hidden state is \n",
      "torch.Size([1, 50, 128])\n",
      "encoder output\n",
      "torch.Size([1000, 50, 128])\n",
      "hidden state is \n",
      "torch.Size([1, 50, 128])\n",
      "encoder output\n",
      "torch.Size([1000, 50, 128])\n",
      "hidden state is \n",
      "torch.Size([1, 50, 128])\n",
      "encoder output\n",
      "torch.Size([1000, 50, 128])\n",
      "hidden state is \n",
      "torch.Size([1, 50, 128])\n",
      "encoder output\n",
      "torch.Size([1000, 50, 128])\n",
      "hidden state is \n",
      "torch.Size([1, 50, 128])\n",
      "encoder output\n",
      "torch.Size([1000, 50, 128])\n",
      "hidden state is \n",
      "torch.Size([1, 50, 128])\n",
      "encoder output\n",
      "torch.Size([1000, 50, 128])\n",
      "Epoch [60/100], Loss: 0.0089\n",
      "hidden state is \n",
      "torch.Size([1, 50, 128])\n",
      "encoder output\n",
      "torch.Size([1000, 50, 128])\n",
      "hidden state is \n",
      "torch.Size([1, 50, 128])\n",
      "encoder output\n",
      "torch.Size([1000, 50, 128])\n",
      "hidden state is \n",
      "torch.Size([1, 50, 128])\n",
      "encoder output\n",
      "torch.Size([1000, 50, 128])\n",
      "hidden state is \n",
      "torch.Size([1, 50, 128])\n",
      "encoder output\n",
      "torch.Size([1000, 50, 128])\n",
      "hidden state is \n",
      "torch.Size([1, 50, 128])\n",
      "encoder output\n",
      "torch.Size([1000, 50, 128])\n",
      "hidden state is \n",
      "torch.Size([1, 50, 128])\n",
      "encoder output\n",
      "torch.Size([1000, 50, 128])\n",
      "hidden state is \n",
      "torch.Size([1, 50, 128])\n",
      "encoder output\n",
      "torch.Size([1000, 50, 128])\n",
      "hidden state is \n",
      "torch.Size([1, 50, 128])\n",
      "encoder output\n",
      "torch.Size([1000, 50, 128])\n",
      "hidden state is \n",
      "torch.Size([1, 50, 128])\n",
      "encoder output\n",
      "torch.Size([1000, 50, 128])\n",
      "hidden state is \n",
      "torch.Size([1, 50, 128])\n",
      "encoder output\n",
      "torch.Size([1000, 50, 128])\n",
      "Epoch [70/100], Loss: 0.0090\n",
      "hidden state is \n",
      "torch.Size([1, 50, 128])\n",
      "encoder output\n",
      "torch.Size([1000, 50, 128])\n",
      "hidden state is \n",
      "torch.Size([1, 50, 128])\n",
      "encoder output\n",
      "torch.Size([1000, 50, 128])\n",
      "hidden state is \n",
      "torch.Size([1, 50, 128])\n",
      "encoder output\n",
      "torch.Size([1000, 50, 128])\n",
      "hidden state is \n",
      "torch.Size([1, 50, 128])\n",
      "encoder output\n",
      "torch.Size([1000, 50, 128])\n",
      "hidden state is \n",
      "torch.Size([1, 50, 128])\n",
      "encoder output\n",
      "torch.Size([1000, 50, 128])\n",
      "hidden state is \n",
      "torch.Size([1, 50, 128])\n",
      "encoder output\n",
      "torch.Size([1000, 50, 128])\n",
      "hidden state is \n",
      "torch.Size([1, 50, 128])\n",
      "encoder output\n",
      "torch.Size([1000, 50, 128])\n",
      "hidden state is \n",
      "torch.Size([1, 50, 128])\n",
      "encoder output\n",
      "torch.Size([1000, 50, 128])\n",
      "hidden state is \n",
      "torch.Size([1, 50, 128])\n",
      "encoder output\n",
      "torch.Size([1000, 50, 128])\n",
      "hidden state is \n",
      "torch.Size([1, 50, 128])\n",
      "encoder output\n",
      "torch.Size([1000, 50, 128])\n",
      "Epoch [80/100], Loss: 0.0089\n",
      "hidden state is \n",
      "torch.Size([1, 50, 128])\n",
      "encoder output\n",
      "torch.Size([1000, 50, 128])\n",
      "hidden state is \n",
      "torch.Size([1, 50, 128])\n",
      "encoder output\n",
      "torch.Size([1000, 50, 128])\n",
      "hidden state is \n",
      "torch.Size([1, 50, 128])\n",
      "encoder output\n",
      "torch.Size([1000, 50, 128])\n",
      "hidden state is \n",
      "torch.Size([1, 50, 128])\n",
      "encoder output\n",
      "torch.Size([1000, 50, 128])\n",
      "hidden state is \n",
      "torch.Size([1, 50, 128])\n",
      "encoder output\n",
      "torch.Size([1000, 50, 128])\n",
      "hidden state is \n",
      "torch.Size([1, 50, 128])\n",
      "encoder output\n",
      "torch.Size([1000, 50, 128])\n",
      "hidden state is \n",
      "torch.Size([1, 50, 128])\n",
      "encoder output\n",
      "torch.Size([1000, 50, 128])\n",
      "hidden state is \n",
      "torch.Size([1, 50, 128])\n",
      "encoder output\n",
      "torch.Size([1000, 50, 128])\n",
      "hidden state is \n",
      "torch.Size([1, 50, 128])\n",
      "encoder output\n",
      "torch.Size([1000, 50, 128])\n",
      "hidden state is \n",
      "torch.Size([1, 50, 128])\n",
      "encoder output\n",
      "torch.Size([1000, 50, 128])\n",
      "Epoch [90/100], Loss: 0.0088\n",
      "hidden state is \n",
      "torch.Size([1, 50, 128])\n",
      "encoder output\n",
      "torch.Size([1000, 50, 128])\n",
      "hidden state is \n",
      "torch.Size([1, 50, 128])\n",
      "encoder output\n",
      "torch.Size([1000, 50, 128])\n",
      "hidden state is \n",
      "torch.Size([1, 50, 128])\n",
      "encoder output\n",
      "torch.Size([1000, 50, 128])\n",
      "hidden state is \n",
      "torch.Size([1, 50, 128])\n",
      "encoder output\n",
      "torch.Size([1000, 50, 128])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hidden state is \n",
      "torch.Size([1, 50, 128])\n",
      "encoder output\n",
      "torch.Size([1000, 50, 128])\n",
      "hidden state is \n",
      "torch.Size([1, 50, 128])\n",
      "encoder output\n",
      "torch.Size([1000, 50, 128])\n",
      "hidden state is \n",
      "torch.Size([1, 50, 128])\n",
      "encoder output\n",
      "torch.Size([1000, 50, 128])\n",
      "hidden state is \n",
      "torch.Size([1, 50, 128])\n",
      "encoder output\n",
      "torch.Size([1000, 50, 128])\n",
      "hidden state is \n",
      "torch.Size([1, 50, 128])\n",
      "encoder output\n",
      "torch.Size([1000, 50, 128])\n",
      "hidden state is \n",
      "torch.Size([1, 50, 128])\n",
      "encoder output\n",
      "torch.Size([1000, 50, 128])\n",
      "Epoch [100/100], Loss: 0.0087\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 100\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    outputs = model(X.unsqueeze(2))  # Add a dimension for input size\n",
    "    loss = criterion(outputs, y.unsqueeze(2))\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step() # what does optimizer.step do- okay update the weight\n",
    "    \n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "923faeb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-1.3496, -0.3068],\n",
      "        [-0.0726,  0.3495]])\n",
      "tensor([[[-1.3496, -0.3068]],\n",
      "\n",
      "        [[-0.0726,  0.3495]]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 1, 2])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k=torch.randn(2,2)\n",
    "print(k)\n",
    "j=k.unsqueeze(1)\n",
    "# print(k.shape)\n",
    "print(j)\n",
    "j.shape # 2,3,4,1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ac0c92ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\syedm\\AppData\\Local\\Temp\\ipykernel_31316\\2686005245.py:52: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x_rnn = torch.tensor(x_rnn, dtype=torch.float32).unsqueeze(2)  # (batch_size, timesteps, input_size)\n",
      "C:\\Users\\syedm\\AppData\\Local\\Temp\\ipykernel_31316\\2686005245.py:54: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_rnn = torch.tensor(y_rnn, dtype=torch.float32).unsqueeze(2)  # (batch_size, output_size)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape is torch.Size([1000, 50, 1])\n",
      "y shape is torch.Size([1000, 50, 1])\n",
      "hidden state shape of gru is torch.Size([1, 50, 128])\n",
      "output of gru is torch.Size([1000, 50, 128])\n",
      "shape of model outout torch.Size([50, 1])\n"
     ]
    }
   ],
   "source": [
    "# vanilla GRU\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Generate sine wave data\n",
    "def generate_sine_wave(timesteps, steps_per_cycle=50, num_cycles=10):\n",
    "    x = np.linspace(0, num_cycles * 2 * np.pi, steps_per_cycle * num_cycles)\n",
    "    y = np.sin(x)\n",
    "    return y\n",
    "\n",
    "# Prepare the dataset for the GRU model\n",
    "def prepare_dataset(data, timesteps):\n",
    "    X, y = [], []\n",
    "    for i in range(len(data) - timesteps):\n",
    "        X.append(data[i:i + timesteps])\n",
    "        y.append(data[i + timesteps])\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "# Define the GRU-based model\n",
    "class GRUModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(GRUModel, self).__init__()\n",
    "        self.gru = nn.GRU(input_size, hidden_size)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out, hidden = self.gru(x)\n",
    "        print(f\"hidden state shape of gru is {hidden.shape}\")\n",
    "        print(f\"output of gru is {out.shape}\")\n",
    "        out = self.fc(out[-1])\n",
    "        return out\n",
    "\n",
    "# Parameters\n",
    "timesteps = 50\n",
    "steps_per_cycle = 50\n",
    "num_cycles = 10\n",
    "hidden_size = 64\n",
    "output_size = 1\n",
    "learning_rate = 0.001\n",
    "num_epochs = 200\n",
    "input_shape=1\n",
    "output_shape=1\n",
    "hidden_shape=128\n",
    "# Generate and prepare the data\n",
    "y = generate_sine_wave(timesteps, steps_per_cycle, num_cycles)\n",
    "X, y = prepare_dataset(y, timesteps)\n",
    "\n",
    "# Convert to PyTorch tensors\n",
    "x_rnn = torch.tensor(x_rnn, dtype=torch.float32).unsqueeze(2)  # (batch_size, timesteps, input_size) \n",
    "# add the output dimension\n",
    "y_rnn = torch.tensor(y_rnn, dtype=torch.float32).unsqueeze(2)  # (batch_size, output_size)\n",
    "\n",
    "print(f\"X shape is {x_rnn.shape}\")\n",
    "print(f\"y shape is {y_rnn.shape}\")\n",
    "model=GRUModel(input_shape,hidden_shape,output_shape)\n",
    "\n",
    "k=model(x_rnn)\n",
    "print(f\"shape of model outout {k.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2e69e66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the model, loss function, and optimizer\n",
    "model = GRUModel(input_size=1, hidden_size=hidden_size, output_size=output_size)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    outputs = model(X.transpose(0, 1))  # (timesteps, batch_size, input_size)\n",
    "    loss = criterion(outputs, y)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if (epoch + 1) % 20 == 0:\n",
    "        print(f'Epoch [{epoch + 1}/{num_epochs}], Loss: {loss.item():.4f}')\n",
    "\n",
    "# Predict and plot the results\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    predictions = model(X.transpose(0, 1)).numpy()\n",
    "\n",
    "plt.plot(y.numpy(), label='True Sine Wave')\n",
    "plt.plot(predictions, label='Predicted Sine Wave')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6135b20c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleLSTM(nn.Module):\n",
    "    def __init__(self,input_dim,hidden_dim, layer_dim,output_dim):\n",
    "        super(SimpleLSTM, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.layer_dim = layer_dim # what is layer dim\n",
    "        self.lstm = nn.LSTM(input_dim, hidden_dim, layer_dim, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, x, h0=None, c0=None):\n",
    "        # If hidden and cell states are not provided, initialize them as zeros\n",
    "        if h0 is None or c0 is None:\n",
    "            h0 = torch.zeros(self.layer_dim, x.size(0), self.hidden_dim).to(x.device)\n",
    "            c0 = torch.zeros(self.layer_dim, x.size(0), self.hidden_dim).to(x.device)\n",
    "        \n",
    "        # Forward pass through LSTM\n",
    "        out, (hn, cn) = self.lstm(x, (h0, c0))\n",
    "        out = self.fc(out[:, -1, :])  # Selecting the last output\n",
    "        return out, hn, cn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3713e294",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Initialize model, loss, and optimizer\n",
    "model = SimpleLSTM(input_dim=1, hidden_dim=100, layer_dim=1, output_dim=1)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3450edf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/100], Loss: 0.2368\n",
      "Epoch [20/100], Loss: 0.0177\n",
      "Epoch [30/100], Loss: 0.0065\n",
      "Epoch [40/100], Loss: 0.0007\n",
      "Epoch [50/100], Loss: 0.0003\n",
      "Epoch [60/100], Loss: 0.0001\n",
      "Epoch [70/100], Loss: 0.0000\n",
      "Epoch [80/100], Loss: 0.0000\n",
      "Epoch [90/100], Loss: 0.0000\n",
      "Epoch [100/100], Loss: 0.0000\n"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "num_epochs = 100\n",
    "h0, c0 = None, None  # Initialize hidden and cell states\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # Forward pass\n",
    "    outputs, h0, c0 = model(X, h0, c0)\n",
    "\n",
    "    # Compute loss\n",
    "    loss = criterion(outputs, y)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    # Detach hidden and cell states to prevent backpropagation through the entire sequence\n",
    "    h0 = h0.detach()\n",
    "    c0 = c0.detach()\n",
    "\n",
    "    if (epoch+1) % 10 == 0:\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "7121aa9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# import torch.nn as nn\n",
    "\n",
    "# # Define model hyperparameters\n",
    "\n",
    "# vocab_size = 50    # Size of the character vocabulary\n",
    "# embedding_dim = 64 # Dimension of character embeddings\n",
    "# hidden_dim = 128   # Dimension of RNN hidden state\n",
    "# output_dim = 10    # Dimension of the output\n",
    "\n",
    "# # Create the model instance\n",
    "\n",
    "\n",
    "# # Print the model architecture\n",
    "# print(model)\n",
    "\n",
    "# # Example input sequence (batch of sequences of character indices)\n",
    "# example_input = torch.tensor([[1, 2, 3, 4], [4, 3, 2, 1]])  # Batch size = 2, sequence length = 4\n",
    "# output = model(example_input)\n",
    "\n",
    "# print(\"Output shape:\", output.shape)  # Output shape: [batch_size, output_dim]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2ac49fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a7be7b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "######### encoder decoder model ########### attempt 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f02afd94",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "f64246fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.6.0+cpu\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(torch.__version__)\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "945ef3f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['heart.csv', 'hin_test.csv']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "csv_list=[x for x in os.listdir('.') if x.endswith(\".csv\")]\n",
    "print(csv_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "5a230219",
   "metadata": {},
   "outputs": [],
   "source": [
    "######## pre prossing dataset #########\n",
    "import csv\n",
    "csv\n",
    "with open(csv_list[1], 'r',encoding='utf-8') as file:\n",
    "  reader = csv.reader(file) # gets every row--> what do to to get every line? is it necessary?\n",
    "  next(reader)  # Skip the header row if it exists\n",
    "  pairs=[row for row in reader]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "606dbbef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>thermax</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sikhaaega</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>learn</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>twitters</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tirunelveli</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>independence</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>jivan</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>reddy</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>pehni</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>tanu</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>deepika</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows  2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          thermax      \n",
       "0       sikhaaega      \n",
       "1           learn         \n",
       "2        twitters     \n",
       "3     tirunelveli  \n",
       "4    independence  \n",
       "..            ...          ...\n",
       "495         jivan         \n",
       "496         reddy       \n",
       "497         pehni         \n",
       "498          tanu          \n",
       "499       deepika       \n",
       "\n",
       "[500 rows x 2 columns]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# do the above with pandas\n",
    "\n",
    "import pandas as pd\n",
    "csv_data=pd.read_csv(csv_list[1])\n",
    "csv_data.iloc[0:500,:] # english\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "34e3914e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['sikhaaega', ''], ['learn', ''], ['twitters', ''], ['tirunelveli', ''], ['independence', ''], ['speshiyon', ''], ['shurooh', ''], ['kolhapur', ''], ['ajhar', ''], ['karaar', '']]\n",
      "4095\n"
     ]
    }
   ],
   "source": [
    "print(pairs[:10])\n",
    "print(len(pairs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "4a193ba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Path to text file\n",
    "# file_path = 'eng_ita_v2.txt'\n",
    "\n",
    "# # Process the data\n",
    "# pairs = read_data(file_path)\n",
    "# len(pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "a87d5972",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating the vocabulary\n",
    "def tokenize(sentence):\n",
    "#     print(sentence)\n",
    "    return sentence.lower().split()\n",
    "\n",
    "\n",
    "## tokenize and build vocabularies\n",
    "\n",
    "def build_vocab(pairs):\n",
    "    eng_vocab=set()\n",
    "    hin_vocab=set()\n",
    "#     i=0\n",
    "    for eng,hin in pairs:\n",
    "        eng_vocab.update(tokenize(eng)) # |= update\n",
    "        hin_vocab.update(tokenize(hin))\n",
    "    return eng_vocab,hin_vocab\n",
    "\n",
    "english_vocab,hindi_vocab= build_vocab(pairs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "9fb3664d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4070\n",
      "3373\n"
     ]
    }
   ],
   "source": [
    "# # Creating word to integer mapping\n",
    "# eng_word2int = {word: i for i, word in enumerate(english_vocab)}\n",
    "# hin_word2int = {word: i for i, word in enumerate(hindi_vocab)}\n",
    "\n",
    "# # Creating integer to word mapping\n",
    "# eng_int2word = {i: word for word, i in eng_word2int.items()} # dict.itam()- iterate over dict and returns item and key pair\n",
    "# hin_int2word = {i: word for word, i in hin_word2int.items()}\n",
    "\n",
    "\n",
    "print(len(english_vocab))\n",
    "print(len(hindi_vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b1100bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "english_vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "fa19348d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Special tokens\n",
    "PAD_TOKEN = \"<PAD>\"\n",
    "EOS_TOKEN = \"<EOS>\"\n",
    "SOS_TOKEN = \"<SOS>\"\n",
    "UNK_TOKEN = \"<UNK>\"\n",
    "# Update the function to create mappings to include the special tokens\n",
    "def create_mappings(vocab):\n",
    "    vocab = [PAD_TOKEN, SOS_TOKEN, EOS_TOKEN, UNK_TOKEN] + sorted(vocab)\n",
    "    word2int = {word: i for i, word in enumerate(vocab)}\n",
    "    int2word = {i: word for word, i in word2int.items()}\n",
    "    return word2int, int2word\n",
    "\n",
    "# Update the vocabularies\n",
    "eng_word2int, eng_int2word = create_mappings(english_vocab)\n",
    "hin_word2int, hin_int2word = create_mappings(hindi_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "04670b55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eng_word2int[\"<PAD>\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "b9326aed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "English text encoded: [2022 1508]\n",
      "Decoded English: learn independence\n"
     ]
    }
   ],
   "source": [
    "eng_example = \"learn independence\"\n",
    "# hind_sentence=pairs[0][1]\n",
    "# print(tokenize(eng_example))\n",
    "# Encoding\n",
    "eng_encoded = np.array([eng_word2int[word] for word in tokenize(eng_example)], dtype=np.int32)\n",
    "# tokenize lower case and split the test based on spaces\n",
    "# ita_encoded = np.array([ita_word2int[word] for word in tokenize(ita_example)], dtype=np.int32)\n",
    "\n",
    "print('English text encoded:', eng_encoded)\n",
    "# print('Italian text encoded:', ita_encoded)\n",
    "\n",
    "# Decoding\n",
    "print('Decoded English:', ' '.join([eng_int2word[i] for i in eng_encoded]))\n",
    "# print('Decoded Italian:', ' '.join([ita_int2word[i] for i in ita_encoded]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "af45b3e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TranslationDataset(Dataset):\n",
    "    def __init__(self, pairs, eng_word2int, hin_word2int):\n",
    "        self.pairs = pairs\n",
    "        self.eng_word2int = eng_word2int\n",
    "        self.hin_word2int = hin_word2int\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.pairs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        eng, hin = self.pairs[idx]\n",
    "        eng_tensor = torch.tensor([self.eng_word2int[word] for word in tokenize(eng)]\n",
    "                                  + [self.eng_word2int[EOS_TOKEN]], dtype=torch.long)\n",
    "        hin_tensor = torch.tensor([self.hin_word2int[word] for word in tokenize(hin)]\n",
    "                                  + [self.hin_word2int[EOS_TOKEN]], dtype=torch.long)\n",
    "        return eng_tensor, hin_tensor\n",
    "\n",
    "# Custom collate function to handle padding # what does it do ?-> fill the extra space to complete the sentence\n",
    "def collate_fn(batch):\n",
    "    eng_batch, hin_batch = zip(*batch)\n",
    "    eng_batch_padded = pad_sequence(eng_batch, batch_first=True, padding_value=eng_word2int[PAD_TOKEN])\n",
    "    hin_batch_padded = pad_sequence(hin_batch, batch_first=True, padding_value=hin_word2int[PAD_TOKEN])\n",
    "    return eng_batch_padded, hin_batch_padded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "2855e1eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Translation samples:  4095\n",
      "Translation batches:  63\n"
     ]
    }
   ],
   "source": [
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "# Create the dataset and DataLoader\n",
    "translation_dataset = TranslationDataset(pairs, eng_word2int, hin_word2int)\n",
    "batch_size = 64\n",
    "translation_dataloader = DataLoader(translation_dataset, batch_size=batch_size,\n",
    "                                    shuffle=True,  drop_last=True, collate_fn=collate_fn) \n",
    "# The dataset will transform the sentence pairs into sequences of integers (tokenized form) \n",
    "# so they can be used as input to a machine learning model.\n",
    "\n",
    "# is it specially for translation, how does it know about word2vec \n",
    "print(\"Translation samples: \", len(translation_dataset)) ## does what\n",
    "print(\"Translation batches: \", len(translation_dataloader)) ## does what"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "a96c255d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63.984375\n",
      "tensor([[ 3,  2,  5,  2],\n",
      "        [ 1,  2,  3, -1]])\n",
      "torch.Size([2, 4])\n"
     ]
    }
   ],
   "source": [
    "print(len(pairs)/64)\n",
    "k=torch.tensor([[1,2,3,-1],[3,2,5,2]])\n",
    "z=torch.flip(k,[0])\n",
    "print(z)\n",
    "print(z.shape)\n",
    "# Example: iterating over the DataLoader\n",
    "# for eng, hin in translation_dataloader:\n",
    "#     print(\"English batch:\", eng)\n",
    "#     print(\"Hindi batch:\", hin)\n",
    "#     break # remove this to iterate over the whole dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "5b9ae837",
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoder/decoder RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "b0968344",
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoder \n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_size, hidden_size, num_layers=1):\n",
    "        super().__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_size)\n",
    "        self.lstm = nn.LSTM(embed_size, hidden_size, num_layers=num_layers,\n",
    "                            batch_first=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Reversing the sequence of indices\n",
    "        x = torch.flip(x, [1]) # flip column wise row seq --> [1,2,3,4] --> [4,3,2,1]\n",
    "        print(f\"x shape {x.size()}\")\n",
    "        embedded = self.embedding(x)\n",
    "        print(f\"embedded size {embedded.shape} \")\n",
    "        outputs, (hidden, cell) = self.lstm(embedded)\n",
    "        print(f\"outsize {outputs.shape}\")\n",
    "        return outputs, hidden, cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "83055192",
   "metadata": {},
   "outputs": [],
   "source": [
    "# decoder \n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_size, hidden_size, num_layers=1):\n",
    "        super().__init__()\n",
    "#         self.hidden_size = hidden_size\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_size)\n",
    "        self.lstm = nn.LSTM(embed_size, hidden_size, num_layers=num_layers,\n",
    "                            batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, vocab_size)\n",
    "\n",
    "    def forward(self, x, hidden, cell):\n",
    "        out = self.embedding(x)\n",
    "        out, (hidden, cell) = self.lstm(out, (hidden, cell))\n",
    "        out = self.fc(out).reshape(out.size(0), -1)\n",
    "        return out, hidden, cell\n",
    "# lstm output is out, h_n (hidden), c_n. (cell)\n",
    "    \n",
    "#output-> shape --> (N,L,DH_{out}) when batch_first=True\n",
    "# h_n -> (Dnum_layers,N,H_{out})\n",
    "# c_n -> (Dnum_layers,N,H_{out})"
   ]
  },
  {
   "attachments": {
    "dim_lstm.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "id": "d2b3ca8a",
   "metadata": {},
   "source": [
    "![dim_lstm.png](attachment:dim_lstm.png) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "1d42f0f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# what is the total number of computations done by the network-\n",
    "# A)\n",
    "# embd_size=m\n",
    "# hiden_state=k\n",
    "# lenght of input and out sequence T\n",
    "# lenght of vocab V (same for both source and target)\n",
    "\n",
    "\n",
    "\n",
    "# B)\n",
    "# total number of parameters in the network\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "10fa441d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "eng_vocab_size = len(eng_word2int)\n",
    "hin_vocab_size = len(hin_word2int)\n",
    "embed_size = 256\n",
    "hidden_size = 512\n",
    "num_layers = 1\n",
    "\n",
    "# Initialize the models\n",
    "encoder_lstm = Encoder(eng_vocab_size, embed_size, hidden_size, num_layers).to(device)\n",
    "decoder_lstm = Decoder(hin_vocab_size, embed_size, hidden_size, num_layers).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "ec970e48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoder summary\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "=================================================================\n",
       "Layer (type:depth-idx)                   Param #\n",
       "=================================================================\n",
       "Encoder                                  --\n",
       "Embedding: 1-1                         1,042,944\n",
       "LSTM: 1-2                              3,153,920\n",
       "=================================================================\n",
       "Total params: 4,196,864\n",
       "Trainable params: 4,196,864\n",
       "Non-trainable params: 0\n",
       "================================================================="
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import torchinfo\n",
    "from torchinfo import summary\n",
    "print(\"Encoder summary\")\n",
    "summary(encoder) # do a test pass through of an example input size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "d0313a9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dencoder summary\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "=================================================================\n",
       "Layer (type:depth-idx)                   Param #\n",
       "=================================================================\n",
       "Decoder                                  --\n",
       "Embedding: 1-1                         864,512\n",
       "LSTM: 1-2                              5,251,072\n",
       "Linear: 1-3                            3,461,425\n",
       "=================================================================\n",
       "Total params: 9,577,009\n",
       "Trainable params: 9,577,009\n",
       "Non-trainable params: 0\n",
       "================================================================="
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Dencoder summary\")\n",
    "summary(decoder) # do a test pass through of an example input size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7c7c181",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "ee2020db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate(encoder, decoder, sentence, eng_word2int, ita_int2word, max_length=15):\n",
    "    encoder.eval()\n",
    "    decoder.eval()\n",
    "    with torch.inference_mode():\n",
    "        # Tokenize and encode the sentence\n",
    "        input_tensor = torch.tensor([eng_word2int[word] for word in tokenize(sentence)]\n",
    "                                    + [eng_word2int[EOS_TOKEN]], dtype=torch.long)\n",
    "#         print(f\"shape of input tensor is {input_tensor.shape}\")\n",
    "        input_tensor = input_tensor.view(1, -1).to(DEVICE)  # batch_first=True\n",
    "\n",
    "        # Pass the input through the encoder\n",
    "        _, encoder_hidden, encoder_cell = encoder(input_tensor)\n",
    "#         print(f\"encoder hidden shape, cell shape {encoder_hidden.shape, encoder_cell.shape}\")\n",
    "        # encoder output\n",
    "\n",
    "        # Initialize the decoder input with the SOS token\n",
    "        decoder_input = torch.tensor([[eng_word2int[SOS_TOKEN]]], dtype=torch.long)  # SOS\n",
    "#         print(f\"decoder input first {decoder_input}\")\n",
    "        # Initialize the hidden state of the decoder with the encoder's hidden state\n",
    "        decoder_hidden, decoder_cell = encoder_hidden, encoder_cell\n",
    "\n",
    "        # Decoding the sentence\n",
    "        decoded_words = []\n",
    "        last_word = torch.tensor([[eng_word2int[SOS_TOKEN]]]).to(DEVICE)\n",
    "        print(f\"last word {last_word}\")\n",
    "        for di in range(max_length):\n",
    "            logits, decoder_hidden, decoder_cell = decoder(last_word, decoder_hidden, decoder_cell)\n",
    "#             print(f\"logits shape is (should be equal to hidni vocab 3373ish) {logits.shape}\")\n",
    "            next_token = logits.argmax(dim=1) # greedy #\n",
    "#             print(f\"next token index is (expecting it to be scalar) {next_token}\")\n",
    "            last_word = torch.tensor([[next_token]]).to(DEVICE)\n",
    "            if next_token.item() == hin_word2int[EOS_TOKEN]:\n",
    "                break\n",
    "            else:\n",
    "                decoded_words.append(ita_int2word.get(next_token.item()))\n",
    "\n",
    "        return ' '.join(decoded_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "8539321e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of input tensor is torch.Size([3])\n",
      "x shape torch.Size([1, 3])\n",
      "embedded size torch.Size([1, 3, 256]) \n",
      "outsize torch.Size([1, 3, 512])\n",
      "encoder hidden shape, cell shape (torch.Size([1, 1, 512]), torch.Size([1, 1, 512]))\n",
      "decoder input first tensor([[1]])\n",
      "last word tensor([[1]])\n",
      "logits shape is (should be equal to hidni vocab 3373ish) torch.Size([1, 3377])\n",
      "next token index is (expecting it to be scalar) tensor([1489])\n",
      "logits shape is (should be equal to hidni vocab 3373ish) torch.Size([1, 3377])\n",
      "next token index is (expecting it to be scalar) tensor([2627])\n",
      "logits shape is (should be equal to hidni vocab 3373ish) torch.Size([1, 3377])\n",
      "next token index is (expecting it to be scalar) tensor([932])\n",
      "logits shape is (should be equal to hidni vocab 3373ish) torch.Size([1, 3377])\n",
      "next token index is (expecting it to be scalar) tensor([1142])\n",
      "logits shape is (should be equal to hidni vocab 3373ish) torch.Size([1, 3377])\n",
      "next token index is (expecting it to be scalar) tensor([62])\n",
      "logits shape is (should be equal to hidni vocab 3373ish) torch.Size([1, 3377])\n",
      "next token index is (expecting it to be scalar) tensor([1142])\n",
      "logits shape is (should be equal to hidni vocab 3373ish) torch.Size([1, 3377])\n",
      "next token index is (expecting it to be scalar) tensor([62])\n",
      "logits shape is (should be equal to hidni vocab 3373ish) torch.Size([1, 3377])\n",
      "next token index is (expecting it to be scalar) tensor([62])\n",
      "logits shape is (should be equal to hidni vocab 3373ish) torch.Size([1, 3377])\n",
      "next token index is (expecting it to be scalar) tensor([62])\n",
      "logits shape is (should be equal to hidni vocab 3373ish) torch.Size([1, 3377])\n",
      "next token index is (expecting it to be scalar) tensor([2315])\n",
      "logits shape is (should be equal to hidni vocab 3373ish) torch.Size([1, 3377])\n",
      "next token index is (expecting it to be scalar) tensor([3088])\n",
      "logits shape is (should be equal to hidni vocab 3373ish) torch.Size([1, 3377])\n",
      "next token index is (expecting it to be scalar) tensor([2392])\n",
      "logits shape is (should be equal to hidni vocab 3373ish) torch.Size([1, 3377])\n",
      "next token index is (expecting it to be scalar) tensor([1981])\n",
      "logits shape is (should be equal to hidni vocab 3373ish) torch.Size([1, 3377])\n",
      "next token index is (expecting it to be scalar) tensor([2084])\n",
      "logits shape is (should be equal to hidni vocab 3373ish) torch.Size([1, 3377])\n",
      "next token index is (expecting it to be scalar) tensor([29])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'              '"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eng_example = \"learn independence\"\n",
    "translate(encoder_lstm,decoder_lstm,eng_example, eng_word2int, hin_int2word)\n",
    "# eng_word2int, eng_int2word = create_mappings(english_vocab)\n",
    "# hin_word2int, hin_int2word = create_mappings(hindi_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "7bec3244",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: '<PAD>',\n",
       " 1: '<SOS>',\n",
       " 2: '<EOS>',\n",
       " 3: '<UNK>',\n",
       " 4: '',\n",
       " 5: '',\n",
       " 6: '',\n",
       " 7: '',\n",
       " 8: '',\n",
       " 9: '',\n",
       " 10: '',\n",
       " 11: '',\n",
       " 12: '',\n",
       " 13: '',\n",
       " 14: '',\n",
       " 15: '',\n",
       " 16: '',\n",
       " 17: '',\n",
       " 18: '',\n",
       " 19: '',\n",
       " 20: '',\n",
       " 21: '',\n",
       " 22: '',\n",
       " 23: '',\n",
       " 24: '',\n",
       " 25: '',\n",
       " 26: '',\n",
       " 27: '',\n",
       " 28: '',\n",
       " 29: '',\n",
       " 30: '',\n",
       " 31: '',\n",
       " 32: '',\n",
       " 33: '',\n",
       " 34: '',\n",
       " 35: '',\n",
       " 36: '',\n",
       " 37: '',\n",
       " 38: '',\n",
       " 39: '',\n",
       " 40: '',\n",
       " 41: '',\n",
       " 42: '',\n",
       " 43: '',\n",
       " 44: '',\n",
       " 45: '',\n",
       " 46: '',\n",
       " 47: '',\n",
       " 48: '',\n",
       " 49: '',\n",
       " 50: '',\n",
       " 51: '',\n",
       " 52: '',\n",
       " 53: '',\n",
       " 54: '',\n",
       " 55: '',\n",
       " 56: '',\n",
       " 57: '',\n",
       " 58: '',\n",
       " 59: '',\n",
       " 60: '',\n",
       " 61: '',\n",
       " 62: '',\n",
       " 63: '',\n",
       " 64: '',\n",
       " 65: '',\n",
       " 66: '',\n",
       " 67: '',\n",
       " 68: '',\n",
       " 69: '',\n",
       " 70: '',\n",
       " 71: '',\n",
       " 72: '',\n",
       " 73: '',\n",
       " 74: '',\n",
       " 75: '',\n",
       " 76: '',\n",
       " 77: '',\n",
       " 78: '',\n",
       " 79: '',\n",
       " 80: '',\n",
       " 81: '',\n",
       " 82: '',\n",
       " 83: '',\n",
       " 84: '',\n",
       " 85: '',\n",
       " 86: '',\n",
       " 87: '',\n",
       " 88: '',\n",
       " 89: '',\n",
       " 90: '',\n",
       " 91: '',\n",
       " 92: '',\n",
       " 93: '',\n",
       " 94: '',\n",
       " 95: '',\n",
       " 96: '',\n",
       " 97: '',\n",
       " 98: '',\n",
       " 99: '',\n",
       " 100: '',\n",
       " 101: '',\n",
       " 102: '',\n",
       " 103: '',\n",
       " 104: '',\n",
       " 105: '',\n",
       " 106: '',\n",
       " 107: '',\n",
       " 108: '',\n",
       " 109: '',\n",
       " 110: '',\n",
       " 111: '',\n",
       " 112: '',\n",
       " 113: '',\n",
       " 114: '',\n",
       " 115: '',\n",
       " 116: '',\n",
       " 117: '',\n",
       " 118: '',\n",
       " 119: '',\n",
       " 120: '',\n",
       " 121: '',\n",
       " 122: '',\n",
       " 123: '',\n",
       " 124: '',\n",
       " 125: '',\n",
       " 126: '',\n",
       " 127: '',\n",
       " 128: '',\n",
       " 129: '',\n",
       " 130: '',\n",
       " 131: '',\n",
       " 132: '',\n",
       " 133: '',\n",
       " 134: '',\n",
       " 135: '',\n",
       " 136: '',\n",
       " 137: '',\n",
       " 138: '',\n",
       " 139: '',\n",
       " 140: '',\n",
       " 141: '',\n",
       " 142: '',\n",
       " 143: '',\n",
       " 144: '',\n",
       " 145: '',\n",
       " 146: '',\n",
       " 147: '',\n",
       " 148: '',\n",
       " 149: '',\n",
       " 150: '',\n",
       " 151: '',\n",
       " 152: '',\n",
       " 153: '',\n",
       " 154: '',\n",
       " 155: '',\n",
       " 156: '',\n",
       " 157: '',\n",
       " 158: '',\n",
       " 159: '',\n",
       " 160: '',\n",
       " 161: '',\n",
       " 162: '',\n",
       " 163: '',\n",
       " 164: '',\n",
       " 165: '',\n",
       " 166: '',\n",
       " 167: '',\n",
       " 168: '',\n",
       " 169: '',\n",
       " 170: '',\n",
       " 171: '',\n",
       " 172: '',\n",
       " 173: '',\n",
       " 174: '',\n",
       " 175: '',\n",
       " 176: '',\n",
       " 177: '',\n",
       " 178: '',\n",
       " 179: '',\n",
       " 180: '',\n",
       " 181: '',\n",
       " 182: '',\n",
       " 183: '',\n",
       " 184: '',\n",
       " 185: '',\n",
       " 186: '',\n",
       " 187: '',\n",
       " 188: '',\n",
       " 189: '',\n",
       " 190: '',\n",
       " 191: '',\n",
       " 192: '',\n",
       " 193: '',\n",
       " 194: '',\n",
       " 195: '',\n",
       " 196: '',\n",
       " 197: '',\n",
       " 198: '',\n",
       " 199: '',\n",
       " 200: '',\n",
       " 201: '',\n",
       " 202: '',\n",
       " 203: '',\n",
       " 204: '',\n",
       " 205: '',\n",
       " 206: '',\n",
       " 207: '',\n",
       " 208: '',\n",
       " 209: '',\n",
       " 210: '',\n",
       " 211: '',\n",
       " 212: '',\n",
       " 213: '',\n",
       " 214: '',\n",
       " 215: '',\n",
       " 216: '',\n",
       " 217: '',\n",
       " 218: '',\n",
       " 219: '',\n",
       " 220: '',\n",
       " 221: '',\n",
       " 222: '',\n",
       " 223: '',\n",
       " 224: '',\n",
       " 225: '',\n",
       " 226: '',\n",
       " 227: '',\n",
       " 228: '',\n",
       " 229: '',\n",
       " 230: '',\n",
       " 231: '',\n",
       " 232: '',\n",
       " 233: '',\n",
       " 234: '',\n",
       " 235: '',\n",
       " 236: '',\n",
       " 237: '',\n",
       " 238: '',\n",
       " 239: '',\n",
       " 240: '',\n",
       " 241: '',\n",
       " 242: '',\n",
       " 243: '',\n",
       " 244: '',\n",
       " 245: '',\n",
       " 246: '',\n",
       " 247: '',\n",
       " 248: '',\n",
       " 249: '',\n",
       " 250: '',\n",
       " 251: '',\n",
       " 252: '',\n",
       " 253: '',\n",
       " 254: '',\n",
       " 255: '',\n",
       " 256: '',\n",
       " 257: '',\n",
       " 258: '',\n",
       " 259: '',\n",
       " 260: '',\n",
       " 261: '',\n",
       " 262: '',\n",
       " 263: '',\n",
       " 264: '',\n",
       " 265: '',\n",
       " 266: '',\n",
       " 267: '',\n",
       " 268: '',\n",
       " 269: '',\n",
       " 270: '',\n",
       " 271: '',\n",
       " 272: '',\n",
       " 273: '',\n",
       " 274: '',\n",
       " 275: '',\n",
       " 276: '',\n",
       " 277: '',\n",
       " 278: '',\n",
       " 279: '',\n",
       " 280: '',\n",
       " 281: '',\n",
       " 282: '',\n",
       " 283: '',\n",
       " 284: '',\n",
       " 285: '',\n",
       " 286: '',\n",
       " 287: '',\n",
       " 288: '',\n",
       " 289: '',\n",
       " 290: '',\n",
       " 291: '',\n",
       " 292: '',\n",
       " 293: '',\n",
       " 294: '',\n",
       " 295: '',\n",
       " 296: '',\n",
       " 297: '',\n",
       " 298: '',\n",
       " 299: '',\n",
       " 300: '',\n",
       " 301: '',\n",
       " 302: '',\n",
       " 303: '',\n",
       " 304: '',\n",
       " 305: '',\n",
       " 306: '',\n",
       " 307: '',\n",
       " 308: '',\n",
       " 309: '',\n",
       " 310: '',\n",
       " 311: '',\n",
       " 312: '',\n",
       " 313: '',\n",
       " 314: '',\n",
       " 315: '',\n",
       " 316: '',\n",
       " 317: '',\n",
       " 318: '',\n",
       " 319: '',\n",
       " 320: '',\n",
       " 321: '',\n",
       " 322: '',\n",
       " 323: '',\n",
       " 324: '',\n",
       " 325: '',\n",
       " 326: '',\n",
       " 327: '',\n",
       " 328: '',\n",
       " 329: '',\n",
       " 330: '',\n",
       " 331: '',\n",
       " 332: '',\n",
       " 333: '',\n",
       " 334: '',\n",
       " 335: '',\n",
       " 336: '',\n",
       " 337: '',\n",
       " 338: '',\n",
       " 339: '',\n",
       " 340: '',\n",
       " 341: '',\n",
       " 342: '',\n",
       " 343: '',\n",
       " 344: '',\n",
       " 345: '',\n",
       " 346: '',\n",
       " 347: '',\n",
       " 348: '',\n",
       " 349: '',\n",
       " 350: '',\n",
       " 351: '',\n",
       " 352: '',\n",
       " 353: '',\n",
       " 354: '',\n",
       " 355: '',\n",
       " 356: '',\n",
       " 357: '',\n",
       " 358: '',\n",
       " 359: '',\n",
       " 360: '',\n",
       " 361: '',\n",
       " 362: '',\n",
       " 363: '',\n",
       " 364: '',\n",
       " 365: '',\n",
       " 366: '',\n",
       " 367: '',\n",
       " 368: '',\n",
       " 369: '',\n",
       " 370: '',\n",
       " 371: '',\n",
       " 372: '',\n",
       " 373: '',\n",
       " 374: '',\n",
       " 375: '',\n",
       " 376: '',\n",
       " 377: '',\n",
       " 378: '',\n",
       " 379: '',\n",
       " 380: '',\n",
       " 381: '',\n",
       " 382: '',\n",
       " 383: '',\n",
       " 384: '',\n",
       " 385: '',\n",
       " 386: '',\n",
       " 387: '',\n",
       " 388: '',\n",
       " 389: '',\n",
       " 390: '',\n",
       " 391: '',\n",
       " 392: '',\n",
       " 393: '',\n",
       " 394: '',\n",
       " 395: '',\n",
       " 396: '',\n",
       " 397: '',\n",
       " 398: '',\n",
       " 399: '',\n",
       " 400: '',\n",
       " 401: '',\n",
       " 402: '',\n",
       " 403: '',\n",
       " 404: '',\n",
       " 405: '',\n",
       " 406: '',\n",
       " 407: '',\n",
       " 408: '',\n",
       " 409: '',\n",
       " 410: '',\n",
       " 411: '',\n",
       " 412: '',\n",
       " 413: '',\n",
       " 414: '',\n",
       " 415: '',\n",
       " 416: '',\n",
       " 417: '',\n",
       " 418: '',\n",
       " 419: '',\n",
       " 420: '',\n",
       " 421: '',\n",
       " 422: '',\n",
       " 423: '',\n",
       " 424: '',\n",
       " 425: '',\n",
       " 426: '',\n",
       " 427: '',\n",
       " 428: '',\n",
       " 429: '',\n",
       " 430: '',\n",
       " 431: '',\n",
       " 432: '',\n",
       " 433: '',\n",
       " 434: '',\n",
       " 435: '',\n",
       " 436: '',\n",
       " 437: '',\n",
       " 438: '',\n",
       " 439: '',\n",
       " 440: '',\n",
       " 441: '',\n",
       " 442: '',\n",
       " 443: '',\n",
       " 444: '',\n",
       " 445: '',\n",
       " 446: '',\n",
       " 447: '',\n",
       " 448: '',\n",
       " 449: '',\n",
       " 450: '',\n",
       " 451: '',\n",
       " 452: '',\n",
       " 453: '',\n",
       " 454: '',\n",
       " 455: '',\n",
       " 456: '',\n",
       " 457: '',\n",
       " 458: '',\n",
       " 459: '',\n",
       " 460: '',\n",
       " 461: '',\n",
       " 462: '',\n",
       " 463: '',\n",
       " 464: '',\n",
       " 465: '',\n",
       " 466: '',\n",
       " 467: '',\n",
       " 468: '',\n",
       " 469: '',\n",
       " 470: '',\n",
       " 471: '',\n",
       " 472: '',\n",
       " 473: '',\n",
       " 474: '',\n",
       " 475: '',\n",
       " 476: '',\n",
       " 477: '',\n",
       " 478: '',\n",
       " 479: '',\n",
       " 480: '',\n",
       " 481: '',\n",
       " 482: '',\n",
       " 483: '',\n",
       " 484: '',\n",
       " 485: '',\n",
       " 486: '',\n",
       " 487: '',\n",
       " 488: '',\n",
       " 489: '',\n",
       " 490: '',\n",
       " 491: '',\n",
       " 492: '',\n",
       " 493: '',\n",
       " 494: '',\n",
       " 495: '',\n",
       " 496: '',\n",
       " 497: '',\n",
       " 498: '',\n",
       " 499: '',\n",
       " 500: '',\n",
       " 501: '',\n",
       " 502: '',\n",
       " 503: '',\n",
       " 504: '',\n",
       " 505: '',\n",
       " 506: '',\n",
       " 507: '',\n",
       " 508: '',\n",
       " 509: '',\n",
       " 510: '',\n",
       " 511: '',\n",
       " 512: '',\n",
       " 513: '',\n",
       " 514: '',\n",
       " 515: '',\n",
       " 516: '',\n",
       " 517: '',\n",
       " 518: '',\n",
       " 519: '',\n",
       " 520: '',\n",
       " 521: '',\n",
       " 522: '',\n",
       " 523: '',\n",
       " 524: '',\n",
       " 525: '',\n",
       " 526: '',\n",
       " 527: '',\n",
       " 528: '',\n",
       " 529: '',\n",
       " 530: '',\n",
       " 531: '',\n",
       " 532: '',\n",
       " 533: '',\n",
       " 534: '',\n",
       " 535: '',\n",
       " 536: '',\n",
       " 537: '',\n",
       " 538: '',\n",
       " 539: '',\n",
       " 540: '',\n",
       " 541: '',\n",
       " 542: '',\n",
       " 543: '',\n",
       " 544: '',\n",
       " 545: '',\n",
       " 546: '',\n",
       " 547: '',\n",
       " 548: '',\n",
       " 549: '',\n",
       " 550: '',\n",
       " 551: '',\n",
       " 552: '',\n",
       " 553: '',\n",
       " 554: '',\n",
       " 555: '',\n",
       " 556: '',\n",
       " 557: '',\n",
       " 558: '',\n",
       " 559: '',\n",
       " 560: '',\n",
       " 561: '',\n",
       " 562: '',\n",
       " 563: '',\n",
       " 564: '',\n",
       " 565: '',\n",
       " 566: '',\n",
       " 567: '',\n",
       " 568: '',\n",
       " 569: '',\n",
       " 570: '',\n",
       " 571: '',\n",
       " 572: '',\n",
       " 573: '',\n",
       " 574: '',\n",
       " 575: '',\n",
       " 576: '',\n",
       " 577: '',\n",
       " 578: '',\n",
       " 579: '',\n",
       " 580: '',\n",
       " 581: '',\n",
       " 582: '',\n",
       " 583: '',\n",
       " 584: '',\n",
       " 585: '',\n",
       " 586: '',\n",
       " 587: '',\n",
       " 588: '',\n",
       " 589: '',\n",
       " 590: '',\n",
       " 591: '',\n",
       " 592: '',\n",
       " 593: '',\n",
       " 594: '',\n",
       " 595: '',\n",
       " 596: '',\n",
       " 597: '',\n",
       " 598: '',\n",
       " 599: '',\n",
       " 600: '',\n",
       " 601: '',\n",
       " 602: '',\n",
       " 603: '',\n",
       " 604: '',\n",
       " 605: '',\n",
       " 606: '',\n",
       " 607: '',\n",
       " 608: '',\n",
       " 609: '',\n",
       " 610: '',\n",
       " 611: '',\n",
       " 612: '',\n",
       " 613: '',\n",
       " 614: '',\n",
       " 615: '',\n",
       " 616: '',\n",
       " 617: '',\n",
       " 618: '',\n",
       " 619: '',\n",
       " 620: '',\n",
       " 621: '',\n",
       " 622: '',\n",
       " 623: '',\n",
       " 624: '',\n",
       " 625: '',\n",
       " 626: '',\n",
       " 627: '',\n",
       " 628: '',\n",
       " 629: '',\n",
       " 630: '',\n",
       " 631: '',\n",
       " 632: '',\n",
       " 633: '',\n",
       " 634: '',\n",
       " 635: '',\n",
       " 636: '',\n",
       " 637: '',\n",
       " 638: '',\n",
       " 639: '',\n",
       " 640: '',\n",
       " 641: '',\n",
       " 642: '',\n",
       " 643: '',\n",
       " 644: '',\n",
       " 645: '',\n",
       " 646: '',\n",
       " 647: '',\n",
       " 648: '',\n",
       " 649: '',\n",
       " 650: '',\n",
       " 651: '',\n",
       " 652: '',\n",
       " 653: '',\n",
       " 654: '',\n",
       " 655: '',\n",
       " 656: '',\n",
       " 657: '',\n",
       " 658: '',\n",
       " 659: '',\n",
       " 660: '',\n",
       " 661: '',\n",
       " 662: '',\n",
       " 663: '',\n",
       " 664: '',\n",
       " 665: '',\n",
       " 666: '',\n",
       " 667: '',\n",
       " 668: '',\n",
       " 669: '',\n",
       " 670: '',\n",
       " 671: '',\n",
       " 672: '',\n",
       " 673: '',\n",
       " 674: '',\n",
       " 675: '',\n",
       " 676: '',\n",
       " 677: '',\n",
       " 678: '',\n",
       " 679: '',\n",
       " 680: '',\n",
       " 681: '',\n",
       " 682: '',\n",
       " 683: '',\n",
       " 684: '',\n",
       " 685: '',\n",
       " 686: '',\n",
       " 687: '',\n",
       " 688: '',\n",
       " 689: '',\n",
       " 690: '',\n",
       " 691: '',\n",
       " 692: '',\n",
       " 693: '',\n",
       " 694: '',\n",
       " 695: '',\n",
       " 696: '',\n",
       " 697: '',\n",
       " 698: '',\n",
       " 699: '',\n",
       " 700: '',\n",
       " 701: '',\n",
       " 702: '',\n",
       " 703: '',\n",
       " 704: '',\n",
       " 705: '',\n",
       " 706: '',\n",
       " 707: '',\n",
       " 708: '',\n",
       " 709: '',\n",
       " 710: '',\n",
       " 711: '',\n",
       " 712: '',\n",
       " 713: '',\n",
       " 714: '',\n",
       " 715: '',\n",
       " 716: '',\n",
       " 717: '',\n",
       " 718: '',\n",
       " 719: '',\n",
       " 720: '',\n",
       " 721: '',\n",
       " 722: '',\n",
       " 723: '',\n",
       " 724: '',\n",
       " 725: '',\n",
       " 726: '',\n",
       " 727: '',\n",
       " 728: '',\n",
       " 729: '',\n",
       " 730: '',\n",
       " 731: '',\n",
       " 732: '',\n",
       " 733: '',\n",
       " 734: '',\n",
       " 735: '',\n",
       " 736: '',\n",
       " 737: '',\n",
       " 738: '',\n",
       " 739: '',\n",
       " 740: '',\n",
       " 741: '',\n",
       " 742: '',\n",
       " 743: '',\n",
       " 744: '',\n",
       " 745: '',\n",
       " 746: '',\n",
       " 747: '',\n",
       " 748: '',\n",
       " 749: '',\n",
       " 750: '',\n",
       " 751: '',\n",
       " 752: '',\n",
       " 753: '',\n",
       " 754: '',\n",
       " 755: '',\n",
       " 756: '',\n",
       " 757: '',\n",
       " 758: '',\n",
       " 759: '',\n",
       " 760: '',\n",
       " 761: '',\n",
       " 762: '',\n",
       " 763: '',\n",
       " 764: '',\n",
       " 765: '',\n",
       " 766: '',\n",
       " 767: '',\n",
       " 768: '',\n",
       " 769: '',\n",
       " 770: '',\n",
       " 771: '',\n",
       " 772: '',\n",
       " 773: '',\n",
       " 774: '',\n",
       " 775: '',\n",
       " 776: '',\n",
       " 777: '',\n",
       " 778: '',\n",
       " 779: '',\n",
       " 780: '',\n",
       " 781: '',\n",
       " 782: '',\n",
       " 783: '',\n",
       " 784: '',\n",
       " 785: '',\n",
       " 786: '',\n",
       " 787: '',\n",
       " 788: '',\n",
       " 789: '',\n",
       " 790: '',\n",
       " 791: '',\n",
       " 792: '',\n",
       " 793: '',\n",
       " 794: '',\n",
       " 795: '',\n",
       " 796: '',\n",
       " 797: '',\n",
       " 798: '',\n",
       " 799: '',\n",
       " 800: '',\n",
       " 801: '',\n",
       " 802: '',\n",
       " 803: '',\n",
       " 804: '',\n",
       " 805: '',\n",
       " 806: '',\n",
       " 807: '',\n",
       " 808: '',\n",
       " 809: '',\n",
       " 810: '',\n",
       " 811: '',\n",
       " 812: '',\n",
       " 813: '',\n",
       " 814: '',\n",
       " 815: '',\n",
       " 816: '',\n",
       " 817: '',\n",
       " 818: '',\n",
       " 819: '',\n",
       " 820: '',\n",
       " 821: '',\n",
       " 822: '',\n",
       " 823: '',\n",
       " 824: '',\n",
       " 825: '',\n",
       " 826: '',\n",
       " 827: '',\n",
       " 828: '',\n",
       " 829: '',\n",
       " 830: '',\n",
       " 831: '',\n",
       " 832: '',\n",
       " 833: '',\n",
       " 834: '',\n",
       " 835: '',\n",
       " 836: '',\n",
       " 837: '',\n",
       " 838: '',\n",
       " 839: '',\n",
       " 840: '',\n",
       " 841: '',\n",
       " 842: '',\n",
       " 843: '',\n",
       " 844: '',\n",
       " 845: '',\n",
       " 846: '',\n",
       " 847: '',\n",
       " 848: '',\n",
       " 849: '',\n",
       " 850: '',\n",
       " 851: '',\n",
       " 852: '',\n",
       " 853: '',\n",
       " 854: '',\n",
       " 855: '',\n",
       " 856: '',\n",
       " 857: '',\n",
       " 858: '',\n",
       " 859: '',\n",
       " 860: '',\n",
       " 861: '',\n",
       " 862: '',\n",
       " 863: '',\n",
       " 864: '',\n",
       " 865: '',\n",
       " 866: '',\n",
       " 867: '',\n",
       " 868: '',\n",
       " 869: '',\n",
       " 870: '',\n",
       " 871: '',\n",
       " 872: '',\n",
       " 873: '',\n",
       " 874: '',\n",
       " 875: '',\n",
       " 876: '',\n",
       " 877: '',\n",
       " 878: '',\n",
       " 879: '',\n",
       " 880: '',\n",
       " 881: '',\n",
       " 882: '',\n",
       " 883: '',\n",
       " 884: '',\n",
       " 885: '',\n",
       " 886: '',\n",
       " 887: '',\n",
       " 888: '',\n",
       " 889: '',\n",
       " 890: '',\n",
       " 891: '',\n",
       " 892: '',\n",
       " 893: '',\n",
       " 894: '',\n",
       " 895: '',\n",
       " 896: '',\n",
       " 897: '',\n",
       " 898: '',\n",
       " 899: '',\n",
       " 900: '',\n",
       " 901: '',\n",
       " 902: '',\n",
       " 903: '',\n",
       " 904: '',\n",
       " 905: '',\n",
       " 906: '',\n",
       " 907: '',\n",
       " 908: '',\n",
       " 909: '',\n",
       " 910: '',\n",
       " 911: '',\n",
       " 912: '',\n",
       " 913: '',\n",
       " 914: '',\n",
       " 915: '',\n",
       " 916: '',\n",
       " 917: '',\n",
       " 918: '',\n",
       " 919: '',\n",
       " 920: '',\n",
       " 921: '',\n",
       " 922: '',\n",
       " 923: '',\n",
       " 924: '',\n",
       " 925: '',\n",
       " 926: '',\n",
       " 927: '',\n",
       " 928: '',\n",
       " 929: '',\n",
       " 930: '',\n",
       " 931: '',\n",
       " 932: '',\n",
       " 933: '',\n",
       " 934: '',\n",
       " 935: '',\n",
       " 936: '',\n",
       " 937: '',\n",
       " 938: '',\n",
       " 939: '',\n",
       " 940: '',\n",
       " 941: '',\n",
       " 942: '',\n",
       " 943: '',\n",
       " 944: '',\n",
       " 945: '',\n",
       " 946: '',\n",
       " 947: '',\n",
       " 948: '',\n",
       " 949: '',\n",
       " 950: '',\n",
       " 951: '',\n",
       " 952: '',\n",
       " 953: '',\n",
       " 954: '',\n",
       " 955: '',\n",
       " 956: '',\n",
       " 957: '',\n",
       " 958: '',\n",
       " 959: '',\n",
       " 960: '',\n",
       " 961: '',\n",
       " 962: '',\n",
       " 963: '',\n",
       " 964: '',\n",
       " 965: '',\n",
       " 966: '',\n",
       " 967: '',\n",
       " 968: '',\n",
       " 969: '',\n",
       " 970: '',\n",
       " 971: '',\n",
       " 972: '',\n",
       " 973: '',\n",
       " 974: '',\n",
       " 975: '',\n",
       " 976: '',\n",
       " 977: '',\n",
       " 978: '',\n",
       " 979: '',\n",
       " 980: '',\n",
       " 981: '',\n",
       " 982: '',\n",
       " 983: '',\n",
       " 984: '',\n",
       " 985: '',\n",
       " 986: '',\n",
       " 987: '',\n",
       " 988: '',\n",
       " 989: '',\n",
       " 990: '',\n",
       " 991: '',\n",
       " 992: '',\n",
       " 993: '',\n",
       " 994: '',\n",
       " 995: '',\n",
       " 996: '',\n",
       " 997: '',\n",
       " 998: '',\n",
       " 999: '',\n",
       " ...}"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# hin_int2word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "de7e7cf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Batch 0, Loss: 8.1529\n",
      "Epoch 1, Batch 0, Loss: 4.0655\n",
      "Epoch 2, Batch 0, Loss: 4.0559\n",
      "Epoch 3, Batch 0, Loss: 4.0297\n",
      "Epoch 4, Batch 0, Loss: 4.0109\n",
      "Epoch 5, Batch 0, Loss: 3.9487\n",
      "Epoch 6, Batch 0, Loss: 3.8222\n",
      "Epoch 7, Batch 0, Loss: 3.5956\n",
      "Epoch 8, Batch 0, Loss: 3.4109\n",
      "Epoch 9, Batch 0, Loss: 3.0385\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import random\n",
    "DEVICE=device\n",
    "\n",
    "# Loss Function (exclude padding)\n",
    "loss_fn = nn.CrossEntropyLoss(ignore_index=eng_word2int[PAD_TOKEN])\n",
    "\n",
    "# Optimizers\n",
    "encoder_optimizer = optim.AdamW(encoder.parameters())\n",
    "decoder_optimizer = optim.AdamW(decoder.parameters())\n",
    "\n",
    "# Number of epochs\n",
    "num_epochs = 10\n",
    "\n",
    "# Training Loop\n",
    "encoder.train()\n",
    "decoder.train()\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (input_tensor, target_tensor) in enumerate(translation_dataloader):\n",
    "        input_tensor, target_tensor = input_tensor.to(DEVICE), target_tensor.to(DEVICE)\n",
    "\n",
    "        # Zero gradients of both optimizers\n",
    "        encoder_optimizer.zero_grad()\n",
    "        decoder_optimizer.zero_grad()\n",
    "\n",
    "        target_length = target_tensor.size(1)\n",
    "\n",
    "        # Encoder\n",
    "        _, encoder_hidden, encoder_cell = encoder(input_tensor)\n",
    "\n",
    "        # Decoder\n",
    "        decoder_input = torch.full((batch_size, 1), eng_word2int[SOS_TOKEN], dtype=torch.long).to(DEVICE)\n",
    "        # tensor.size(1) --> no of column\n",
    "        decoder_hidden = encoder_hidden\n",
    "        decoder_cell = encoder_cell\n",
    "\n",
    "        # Randomly select a word index from the target sequence\n",
    "        random_word_index = random.randint(0, target_length - 1) ## why this is being done? okay.\n",
    "\n",
    "        loss = 0\n",
    "\n",
    "        for di in range(target_length):\n",
    "            logits, decoder_hidden, decoder_cell  = decoder(decoder_input, decoder_hidden, decoder_cell)\n",
    "            #if di == random_word_index:\n",
    "            #    loss = loss_fn(logits, target_tensor[:, di])\n",
    "            #    break  # Only compute loss for the randomly selected word\n",
    "            loss += loss_fn(logits, target_tensor[:,di])\n",
    "            decoder_input = target_tensor[:, di].reshape(batch_size, 1)  # Teacher forcing\n",
    "\n",
    "\n",
    "        # Backpropagation\n",
    "        loss.backward()\n",
    "\n",
    "        encoder_optimizer.step()\n",
    "        decoder_optimizer.step()\n",
    "\n",
    "        if i % 100 == 0:  # Print loss every 10 batches\n",
    "            print(f'Epoch {epoch}, Batch {i}, Loss: {loss.item() / target_length:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "80e347f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# import torch.nn as nn\n",
    "# import torch.optim as optim\n",
    "# import torch.nn.functional as F\n",
    "\n",
    "# class Encoder(nn.Module):\n",
    "#     def __init__(self, vocab_size, embed_size, hidden_size, num_layers=1):\n",
    "#         super().__init__()\n",
    "#         self.hidden_size = hidden_size\n",
    "#         self.embedding = nn.Embedding(vocab_size, embed_size)\n",
    "#         self.lstm = nn.LSTM(embed_size, hidden_size, num_layers=num_layers,\n",
    "#                             batch_first=True, bidirectional=True)\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         embedded = self.embedding(x)\n",
    "#         outputs, (hidden, cell) = self.lstm(embedded)\n",
    "\n",
    "#         # concatenate hidden states of the bi-directional RNN layer\n",
    "#         hidden = torch.cat((hidden[0,:,:], hidden[1,:,:]), dim=1).unsqueeze(0)\n",
    "#         cell = torch.cat((cell[0,:,:], cell[1,:,:]), dim=1).unsqueeze(0)\n",
    "\n",
    "#         return outputs, hidden, cell\n",
    "\n",
    "# class Decoder(nn.Module):\n",
    "#     def __init__(self, vocab_size, embed_size, hidden_size, num_layers=1):\n",
    "#         super().__init__()\n",
    "#         self.hidden_size = hidden_size\n",
    "#         self.embedding = nn.Embedding(vocab_size, embed_size)\n",
    "#         self.lstm = nn.LSTM(embed_size, hidden_size, num_layers=num_layers, batch_first=True)\n",
    "#         self.fc = nn.Linear(hidden_size, vocab_size)\n",
    "\n",
    "#     def forward(self, x, hidden, cell):\n",
    "#         out = self.embedding(x)\n",
    "#         out, (hidden, cell) = self.lstm(out, (hidden, cell))\n",
    "#         out = self.fc(out).reshape(out.size(0), -1)\n",
    "#         return out, hidden, cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "4ee5f9db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Hyperparameters\n",
    "# eng_vocab_size = len(eng_word2int)\n",
    "# ita_vocab_size = len(hin_word2int)\n",
    "# embed_size = 256\n",
    "# hidden_size = 512\n",
    "# num_layers = 1\n",
    "\n",
    "# # Initialize the models\n",
    "# encoder = Encoder(eng_vocab_size, embed_size, hidden_size, num_layers).to(DEVICE)\n",
    "# decoder = Decoder(hin_vocab_size, embed_size, hidden_size*2, num_layers).to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9da24408",
   "metadata": {},
   "outputs": [],
   "source": [
    "############ RNN based encode decoder ###########"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46c7bb28",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9b98049",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01e09b3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "############ GRU based encoder decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "a594973a",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (1080490500.py, line 23)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn [121], line 23\u001b[1;36m\u001b[0m\n\u001b[1;33m    self.gru = nn.GRU(embd_dim, , num_layers=num_layers,\u001b[0m\n\u001b[1;37m                                ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "class encoder_GRU(nn.Module):\n",
    "    def __init__(self, vocab_size, hidden_size,embd_dim,num_layer=1):\n",
    "        super(encoder_GRU, self).__init__()\n",
    "#         self.hidden_size=hidden_size\n",
    "        self.embd=nn.Embedding(vocab_size,embd_dim)\n",
    "        self.gru = nn.GRU(embd_dim, hidden_size)\n",
    "#         self.fc = nn.Linear(hidden_size, output_size)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x=self.embd(x) # batch_size, embd_size\n",
    "        out, hidden = self.gru(x)\n",
    "        print(f\"hidden state shape of gru is {hidden.shape}\")\n",
    "        print(f\"output of gru is {out.shape}\")\n",
    "#         out = self.fc(out[-1])\n",
    "        return out,hidden\n",
    "\n",
    "\n",
    "# Define the GRU-based model\n",
    "class decoder_GRU(nn.Module):\n",
    "    def __init__(self, vocab_size, hidden_size, embd_dim, num_layer=1):\n",
    "        super(decoder_GRU, self).__init__()\n",
    "        self.embd=nn.Embedding(vocab_size,embd_dim)\n",
    "        self.gru = nn.GRU(embd_dim, , num_layers=num_layers,\n",
    "                            batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "    \n",
    "    def forward(self, x, hidden):\n",
    "        x=self.embd(x)\n",
    "        out, hidden = self.gru(x,hidden)\n",
    "        print(f\"hidden state shape of gru is {hidden.shape}\")\n",
    "        print(f\"output of gru is {out.shape}\")\n",
    "        out = self.fc(out).reshape(out.size(0), -1)#??\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "31f17d7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "embed_size = 256\n",
    "hidden_size = 512\n",
    "num_layers = 1\n",
    "# Initialize the models\n",
    "encoder_gru_test = encoder_GRU(eng_vocab_size, embed_size, hidden_size, num_layers).to(device)\n",
    "decoder_gru_test = decoder_GRU(hin_vocab_size, embed_size, hidden_size, num_layers).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "28831326",
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate_gru(encoder, decoder, sentence, eng_word2int, ita_int2word, max_length=15):\n",
    "    encoder.eval()\n",
    "    decoder.eval()\n",
    "    with torch.inference_mode():\n",
    "        # Tokenize and encode the sentence\n",
    "        input_tensor = torch.tensor([eng_word2int[word] for word in tokenize(sentence)]\n",
    "                                    + [eng_word2int[EOS_TOKEN]], dtype=torch.long)\n",
    "        print(f\"shape of input tensor is {input_tensor.shape}\")\n",
    "        input_tensor = input_tensor.view(1, -1).to(DEVICE)  # batch_first=True\n",
    "\n",
    "        # Pass the input through the encoder\n",
    "        _, encoder_hidden = encoder(input_tensor)\n",
    "        print(f\"encoder hidden shape {encoder_hidden.shape}\")\n",
    "        # encoder output\n",
    "\n",
    "        # Initialize the decoder input with the SOS token\n",
    "        decoder_input = torch.tensor([[eng_word2int[SOS_TOKEN]]], dtype=torch.long)  # SOS\n",
    "        print(f\"decoder input first {decoder_input}\")\n",
    "        # Initialize the hidden state of the decoder with the encoder's hidden state\n",
    "        decoder_hidden = encoder_hidden\n",
    "\n",
    "        # Decoding the sentence\n",
    "        decoded_words = []\n",
    "        last_word = torch.tensor([[eng_word2int[SOS_TOKEN]]]).to(DEVICE)\n",
    "        print(f\"last word {last_word}\")\n",
    "        for di in range(max_length):\n",
    "            logits, decoder_hidden = decoder(last_word, decoder_hidden)\n",
    "            print(f\"logits shape is (should be equal to hidni vocab 3373ish) {logits.shape}\")\n",
    "            next_token = logits.argmax(dim=1) # greedy #\n",
    "            print(f\"next token index is (expecting it to be scalar) {next_token}\")\n",
    "            last_word = torch.tensor([[next_token]]).to(DEVICE)\n",
    "            if next_token.item() == hin_word2int[EOS_TOKEN]:\n",
    "                break\n",
    "            else:\n",
    "                decoded_words.append(ita_int2word.get(next_token.item()))\n",
    "\n",
    "        return ' '.join(decoded_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "8ad11e17",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of input tensor is torch.Size([3])\n",
      "hidden state shape of gru is torch.Size([1, 3, 256])\n",
      "output of gru is torch.Size([1, 3, 256])\n",
      "encoder hidden shape torch.Size([1, 3, 256])\n",
      "decoder input first tensor([[1]])\n",
      "last word tensor([[1]])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Expected hidden size (1, 1, 256), got [1, 3, 256]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [123], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m eng_example \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlearn independence\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m----> 2\u001b[0m \u001b[43mtranslate_gru\u001b[49m\u001b[43m(\u001b[49m\u001b[43mencoder_gru_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43mdecoder_gru_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43meng_example\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meng_word2int\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhin_int2word\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn [122], line 27\u001b[0m, in \u001b[0;36mtranslate_gru\u001b[1;34m(encoder, decoder, sentence, eng_word2int, ita_int2word, max_length)\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlast word \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlast_word\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m di \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(max_length):\n\u001b[1;32m---> 27\u001b[0m     logits, decoder_hidden \u001b[38;5;241m=\u001b[39m \u001b[43mdecoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlast_word\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdecoder_hidden\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     28\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlogits shape is (should be equal to hidni vocab 3373ish) \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlogits\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     29\u001b[0m     next_token \u001b[38;5;241m=\u001b[39m logits\u001b[38;5;241m.\u001b[39margmax(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m) \u001b[38;5;66;03m# greedy #\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "Cell \u001b[1;32mIn [113], line 28\u001b[0m, in \u001b[0;36mdecoder_GRU.forward\u001b[1;34m(self, x, hidden)\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, hidden):\n\u001b[0;32m     27\u001b[0m     x\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membd(x)\n\u001b[1;32m---> 28\u001b[0m     out, hidden \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgru\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43mhidden\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     29\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhidden state shape of gru is \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhidden\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     30\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput of gru is \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mout\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:1391\u001b[0m, in \u001b[0;36mGRU.forward\u001b[1;34m(self, input, hx)\u001b[0m\n\u001b[0;32m   1386\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1387\u001b[0m         \u001b[38;5;66;03m# Each batch of the hidden state should match the input sequence that\u001b[39;00m\n\u001b[0;32m   1388\u001b[0m         \u001b[38;5;66;03m# the user believes he/she is passing in.\u001b[39;00m\n\u001b[0;32m   1389\u001b[0m         hx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpermute_hidden(hx, sorted_indices)\n\u001b[1;32m-> 1391\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheck_forward_args\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_sizes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1392\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m batch_sizes \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1393\u001b[0m     result \u001b[38;5;241m=\u001b[39m _VF\u001b[38;5;241m.\u001b[39mgru(\n\u001b[0;32m   1394\u001b[0m         \u001b[38;5;28minput\u001b[39m,\n\u001b[0;32m   1395\u001b[0m         hx,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1402\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_first,\n\u001b[0;32m   1403\u001b[0m     )\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:366\u001b[0m, in \u001b[0;36mRNNBase.check_forward_args\u001b[1;34m(self, input, hidden, batch_sizes)\u001b[0m\n\u001b[0;32m    363\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheck_input(\u001b[38;5;28minput\u001b[39m, batch_sizes)\n\u001b[0;32m    364\u001b[0m expected_hidden_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_expected_hidden_size(\u001b[38;5;28minput\u001b[39m, batch_sizes)\n\u001b[1;32m--> 366\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheck_hidden_size\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexpected_hidden_size\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:347\u001b[0m, in \u001b[0;36mRNNBase.check_hidden_size\u001b[1;34m(self, hx, expected_hidden_size, msg)\u001b[0m\n\u001b[0;32m    340\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcheck_hidden_size\u001b[39m(\n\u001b[0;32m    341\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    342\u001b[0m     hx: Tensor,\n\u001b[0;32m    343\u001b[0m     expected_hidden_size: Tuple[\u001b[38;5;28mint\u001b[39m, \u001b[38;5;28mint\u001b[39m, \u001b[38;5;28mint\u001b[39m],\n\u001b[0;32m    344\u001b[0m     msg: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected hidden size \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m, got \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    345\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    346\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m hx\u001b[38;5;241m.\u001b[39msize() \u001b[38;5;241m!=\u001b[39m expected_hidden_size:\n\u001b[1;32m--> 347\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(msg\u001b[38;5;241m.\u001b[39mformat(expected_hidden_size, \u001b[38;5;28mlist\u001b[39m(hx\u001b[38;5;241m.\u001b[39msize())))\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Expected hidden size (1, 1, 256), got [1, 3, 256]"
     ]
    }
   ],
   "source": [
    "eng_example = \"learn independence\"\n",
    "translate_gru(encoder_gru_test,decoder_gru_test,eng_example, eng_word2int, hin_int2word)\n",
    "# eng_word2int, eng_int2word = create_mappings(english_vocab)\n",
    "# hin_word2int, hin_int2word = create_mappings(hindi_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62707648",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ac0b603",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "d2d711e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class encoder_RNN(nn.Module):\n",
    "    def __init__(self, vocab_size, hidden_size, output_size,embd_dim):\n",
    "        super(encoder_RNN, self).__init__()\n",
    "#         self.hidden_size=hidden_size\n",
    "        self.embd=nn.Embedding(vocab_size,embd_dim)\n",
    "        self.rnn = nn.RNN(embd_dim, hidden_size)\n",
    "#         self.fc = nn.Linear(hidden_size, output_size)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x=self.embd(x) # batch_size, embd_size\n",
    "        out, hidden = self.rnn(x)\n",
    "        print(f\"hidden state shape of rnn is {hidden.shape}\")\n",
    "        print(f\"output of rnn is {out.shape}\")\n",
    "#         out = self.fc(out[-1])\n",
    "        return out,hidden\n",
    "\n",
    "\n",
    "# Define the RNN-based model\n",
    "class decoder_RNN(nn.Module):\n",
    "    def __init__(self, vocab_size, hidden_size, output_size,embd_dim):\n",
    "        super(decoder_RNN, self).__init__()\n",
    "        self.embd=nn.Embedding(vocab_size,embd_dim)\n",
    "        self.rnn = nn.RNN(input_size, hidden_size)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "    \n",
    "    def forward(self, x,hidden):\n",
    "        x=self.embd(x)\n",
    "        out, hidden = self.rnn(x,hidden)\n",
    "        print(f\"hidden state shape of RNN is {hidden.shape}\")\n",
    "        print(f\"output of RNN is {out.shape}\")\n",
    "        out = self.fc(out).reshape(out.size(0), -1)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "374a0a60",
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_size = 256\n",
    "hidden_size = 512\n",
    "num_layers = 1\n",
    "# Initialize the models\n",
    "encoder_rnn_test = encoder_RNN(eng_vocab_size, embed_size, hidden_size, num_layers).to(device)\n",
    "decoder_rnn_test = decoder_RNN(hin_vocab_size, embed_size, hidden_size, num_layers).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "a6beb6a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate_rnn(encoder, decoder, sentence, eng_word2int, ita_int2word, max_length=15):\n",
    "    encoder.eval()\n",
    "    decoder.eval()\n",
    "    with torch.inference_mode():\n",
    "        # Tokenize and encode the sentence\n",
    "        input_tensor = torch.tensor([eng_word2int[word] for word in tokenize(sentence)]\n",
    "                                    + [eng_word2int[EOS_TOKEN]], dtype=torch.long)\n",
    "        print(f\"shape of input tensor is {input_tensor.shape}\")\n",
    "        input_tensor = input_tensor.view(1, -1).to(DEVICE)  # batch_first=True\n",
    "\n",
    "        # Pass the input through the encoder\n",
    "        _, encoder_hidden = encoder(input_tensor)\n",
    "        print(f\"encoder hidden shape {encoder_hidden.shape}\")\n",
    "        # encoder output\n",
    "\n",
    "        # Initialize the decoder input with the SOS token\n",
    "        decoder_input = torch.tensor([[eng_word2int[SOS_TOKEN]]], dtype=torch.long)  # SOS\n",
    "        print(f\"decoder input first {decoder_input}\")\n",
    "        # Initialize the hidden state of the decoder with the encoder's hidden state\n",
    "        decoder_hidden = encoder_hidden\n",
    "\n",
    "        # Decoding the sentence\n",
    "        decoded_words = []\n",
    "        last_word = torch.tensor([[eng_word2int[SOS_TOKEN]]]).to(DEVICE)\n",
    "        print(f\"last word {last_word}\")\n",
    "        for di in range(max_length):\n",
    "            logits, decoder_hidden = decoder(last_word, decoder_hidden)\n",
    "            print(f\"logits shape is (should be equal to hidni vocab 3373ish) {logits.shape}\")\n",
    "            next_token = logits.argmax(dim=1) # greedy #\n",
    "            print(f\"next token index is (expecting it to be scalar) {next_token}\")\n",
    "            last_word = torch.tensor([[next_token]]).to(DEVICE)\n",
    "            if next_token.item() == hin_word2int[EOS_TOKEN]:\n",
    "                break\n",
    "            else:\n",
    "                decoded_words.append(ita_int2word.get(next_token.item()))\n",
    "\n",
    "        return ' '.join(decoded_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "f82e6cda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of input tensor is torch.Size([3])\n",
      "hidden state shape of rnn is torch.Size([1, 3, 256])\n",
      "output of rnn is torch.Size([1, 3, 256])\n",
      "encoder hidden shape torch.Size([1, 3, 256])\n",
      "decoder input first tensor([[1]])\n",
      "last word tensor([[1]])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Expected hidden size (1, 1, 256), got [1, 3, 256]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [127], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m eng_example \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlearn independence\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m----> 2\u001b[0m \u001b[43mtranslate_rnn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mencoder_rnn_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43mdecoder_rnn_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43meng_example\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meng_word2int\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhin_int2word\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn [126], line 27\u001b[0m, in \u001b[0;36mtranslate_rnn\u001b[1;34m(encoder, decoder, sentence, eng_word2int, ita_int2word, max_length)\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlast word \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlast_word\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m di \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(max_length):\n\u001b[1;32m---> 27\u001b[0m     logits, decoder_hidden \u001b[38;5;241m=\u001b[39m \u001b[43mdecoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlast_word\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdecoder_hidden\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     28\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlogits shape is (should be equal to hidni vocab 3373ish) \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlogits\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     29\u001b[0m     next_token \u001b[38;5;241m=\u001b[39m logits\u001b[38;5;241m.\u001b[39margmax(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m) \u001b[38;5;66;03m# greedy #\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "Cell \u001b[1;32mIn [124], line 28\u001b[0m, in \u001b[0;36mdecoder_RNN.forward\u001b[1;34m(self, x, hidden)\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x,hidden):\n\u001b[0;32m     27\u001b[0m     x\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membd(x)\n\u001b[1;32m---> 28\u001b[0m     out, hidden \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrnn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43mhidden\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     29\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhidden state shape of RNN is \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhidden\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     30\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput of RNN is \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mout\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:712\u001b[0m, in \u001b[0;36mRNN.forward\u001b[1;34m(self, input, hx)\u001b[0m\n\u001b[0;32m    709\u001b[0m         hx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpermute_hidden(hx, sorted_indices)\n\u001b[0;32m    711\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m hx \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m--> 712\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheck_forward_args\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_sizes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    713\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRNN_TANH\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRNN_RELU\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    714\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m batch_sizes \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:366\u001b[0m, in \u001b[0;36mRNNBase.check_forward_args\u001b[1;34m(self, input, hidden, batch_sizes)\u001b[0m\n\u001b[0;32m    363\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheck_input(\u001b[38;5;28minput\u001b[39m, batch_sizes)\n\u001b[0;32m    364\u001b[0m expected_hidden_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_expected_hidden_size(\u001b[38;5;28minput\u001b[39m, batch_sizes)\n\u001b[1;32m--> 366\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheck_hidden_size\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexpected_hidden_size\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:347\u001b[0m, in \u001b[0;36mRNNBase.check_hidden_size\u001b[1;34m(self, hx, expected_hidden_size, msg)\u001b[0m\n\u001b[0;32m    340\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcheck_hidden_size\u001b[39m(\n\u001b[0;32m    341\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    342\u001b[0m     hx: Tensor,\n\u001b[0;32m    343\u001b[0m     expected_hidden_size: Tuple[\u001b[38;5;28mint\u001b[39m, \u001b[38;5;28mint\u001b[39m, \u001b[38;5;28mint\u001b[39m],\n\u001b[0;32m    344\u001b[0m     msg: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected hidden size \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m, got \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    345\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    346\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m hx\u001b[38;5;241m.\u001b[39msize() \u001b[38;5;241m!=\u001b[39m expected_hidden_size:\n\u001b[1;32m--> 347\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(msg\u001b[38;5;241m.\u001b[39mformat(expected_hidden_size, \u001b[38;5;28mlist\u001b[39m(hx\u001b[38;5;241m.\u001b[39msize())))\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Expected hidden size (1, 1, 256), got [1, 3, 256]"
     ]
    }
   ],
   "source": [
    "eng_example = \"learn independence\"\n",
    "translate_rnn(encoder_rnn_test,decoder_rnn_test,eng_example, eng_word2int, hin_int2word)\n",
    "# eng_word2int, eng_int2word = create_mappings(english_vocab)\n",
    "# hin_word2int, hin_int2word = create_mappings(hindi_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3687db46",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
